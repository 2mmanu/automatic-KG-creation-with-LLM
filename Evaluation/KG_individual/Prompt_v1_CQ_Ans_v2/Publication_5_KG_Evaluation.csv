Publication No.,CQ No.,CQ,CQ LLM Answer,Ontology Concept,KG Individual,KG Individual Label
5,1,What data formats are used in the deep learning pipeline?,"The data formats used in the deep learning pipeline include multitemporal remote sensing data, such as MODIS-derived NDVI and LAI images collected in 2009, and plant species richness data from South Korea. The remote sensing data are co-registered and resampled to 30-arcseconds from 15-arcseconds of the original sources. The plant species richness data from South Korea are used to estimate potential plant species richness patterns for North Korea using a state-of-the-art DL approach. ",DataFormat,https://w3id.org/dlprovenance#DataFormat_1,multitemporal remote sensing data
5,1,What data formats are used in the deep learning pipeline?,"The data formats used in the deep learning pipeline include multitemporal remote sensing data, such as MODIS-derived NDVI and LAI images collected in 2009, and plant species richness data from South Korea. The remote sensing data are co-registered and resampled to 30-arcseconds from 15-arcseconds of the original sources. The plant species richness data from South Korea are used to estimate potential plant species richness patterns for North Korea using a state-of-the-art DL approach. ",DataFormat,https://w3id.org/dlprovenance#DataFormat_2,plant species richness data from South Korea
5,2,What are the sources of input data for the deep learning pipeline?,"The sources of input data for the deep learning pipeline are MODIS products, including the normalized difference vegetation index (NDVI) and leaf area index (LAI). ",Source,https://w3id.org/dlprovenance#Source_1,MODIS products
5,2,What are the sources of input data for the deep learning pipeline?,"The sources of input data for the deep learning pipeline are MODIS products, including the normalized difference vegetation index (NDVI) and leaf area index (LAI). ",InputData,https://w3id.org/dlprovenance#InputData_1,Normalized Difference Vegetation Index (NDVI)
5,2,What are the sources of input data for the deep learning pipeline?,"The sources of input data for the deep learning pipeline are MODIS products, including the normalized difference vegetation index (NDVI) and leaf area index (LAI). ",InputData,https://w3id.org/dlprovenance#InputData_2,Leaf Area Index (LAI)
5,3,How was raw data collected in terms of methods and tools?,"The raw data for this study was collected using remote sensing data and plant species occurrence records. The remote sensing data was collected using multitemporal Landsat 8 images, which were preprocessed using the Google Earth Engine platform. The plant species occurrence records were collected from the Korea National Arboretum, the National Institute of Biological Resources, and the Korea Forest Service. These records were used to estimate the potential plant species richness for the Korean Peninsula, including North Korea, which has limited survey data. Additional Information: The study used remote sensing data from Landsat 8, which was collected using the Google Earth Engine platform. The study used remote sensing data from Landsat 8, which was collected using the Google Earth Engine platform. The study used remote sensing",Method,https://w3id.org/dlprovenance#Method_1,remote sensing data
5,3,How was raw data collected in terms of methods and tools?,"The raw data for this study was collected using remote sensing data and plant species occurrence records. The remote sensing data was collected using multitemporal Landsat 8 images, which were preprocessed using the Google Earth Engine platform. The plant species occurrence records were collected from the Korea National Arboretum, the National Institute of Biological Resources, and the Korea Forest Service. These records were used to estimate the potential plant species richness for the Korean Peninsula, including North Korea, which has limited survey data. Additional Information: The study used remote sensing data from Landsat 8, which was collected using the Google Earth Engine platform. The study used remote sensing data from Landsat 8, which was collected using the Google Earth Engine platform. The study used remote sensing",Method,https://w3id.org/dlprovenance#Method_2,not specified
5,3,How was raw data collected in terms of methods and tools?,"The raw data for this study was collected using remote sensing data and plant species occurrence records. The remote sensing data was collected using multitemporal Landsat 8 images, which were preprocessed using the Google Earth Engine platform. The plant species occurrence records were collected from the Korea National Arboretum, the National Institute of Biological Resources, and the Korea Forest Service. These records were used to estimate the potential plant species richness for the Korean Peninsula, including North Korea, which has limited survey data. Additional Information: The study used remote sensing data from Landsat 8, which was collected using the Google Earth Engine platform. The study used remote sensing data from Landsat 8, which was collected using the Google Earth Engine platform. The study used remote sensing",Tool,https://w3id.org/dlprovenance#Tool_1,Google Earth Engine platform
5,4,"Is the source code openly accessible, and if so, what is the repository link?",The source code is not openly accessible in the given article. The authors did not provide a repository link for the source code. ,RepositoryLink,https://w3id.org/dlprovenance#RepositoryLink_1,not openly accessible
5,5,What preprocessing steps are involved before training the deep learning model?,"Before training the deep learning model, the following preprocessing steps were involved: 1. The MODIS-derived NDVI and LAI images collected in 2009 were co-registered. 2. Pixel-wise MLP was used to estimate species richness. 3. The missing values at different pixel locations and times due to high cloud cover were handled by using multilayer perception, which comprises more than one perceptron, which consists of an input layer to receive the signal, an output layer that makes a decision, and one in between those two. Reference(s): 65. Chollet, F. Deep Learning with R; Manning Publications: Shelter Island, NY, USA, 2018. 66. Srivastava, N. ; Hinton, G. ; Krizhevsky, A. ; Sutskever, I. ; Salakhutdinov, R. Dropout: A simple way to prevent neural networks from overﬁtting. J. Mach. Learn. Res. 2014, 15, 1929–1958. 67. Bhatnagar, S. ; Gill, L. ; Ghosh, B. Drone image segmentation using machine and deep learning for mapping raised bog vegetation communities. Remote Sens. 2020, 12, 2602. [CrossRef] 68. Kim, Y. ; Kim, H. -C. ; Han, D. ; Lee, S. ; Im, J. Prediction of monthly Arctic sea ice concentrations using satellite and reanalysis data based on convolutional neural networks. Cryosphere 2020, 14, 1083–1104. [CrossRef] 69. Korotcov, A. ; Tkachenko, V. ; Russo, D. P. ; Ekins, S. Comparison of deep learning with multiple machine learning methods and metrics using diverse drug discovery data sets. Mol. Pharm. 2017, 14, 4462–4475. [CrossRef] Joharestani, M. Z. ; Cao, C. ; Ni, X. ; Bashir, B. ; Talebiesfandarani, S. PM2. 5 prediction based on random forest, XGBoost, and deep learning using multisource remote sensing data. Atmosphere 2019, 10, 373. [CrossRef] Fernández-Delgado, M. ; Cernadas, E. ; Barro, S. ; Amorim, D. Do we need hundreds of classiﬁers to solve real world classiﬁ-cation problems? J. 2014, 15, 3133–3181. 70. 72. Korea Forest Service. The 6th National Forest Inventory and Monitoring; Korea Forest Service: Daejeon, Korea, 2016. 73. Choe, H. ; Thorne, J. H. ; Huber, P. R. ; Lee, D. ; Quinn, J. F. Assessing shortfalls and complementary conservation areas for national plant biodiversity in South Korea. PLoS ONE 2018, 13, e0190754. [CrossRef] 74. Malhi, Y. ; Franklin, J. ; Seddon, N. ; Solan, M. ; Turner, M. G. ; Field, C. B. ; Knowlton, N. Climate change and ecosystems: Threats, opportunities and solutions. Philos. Trans. Soc. B Biol. Sci. 2020, 375, 20190104. [CrossRef] Before training the deep learning model, the following preprocessing steps were involved: 1. Do we need hundreds of classiﬁers to solve real world classiﬁ- cation problems? J. [CrossRef] 10 of 20 Remote Sens. 2021, 13, 2490 Remote Sens. 2021, 13, x FOR PEER REVIEW 11 of 20 ",PreprocessingStep,https://w3id.org/dlprovenance#PreprocessingStep_1,co-registered and resampled to 30-arcseconds
5,5,What preprocessing steps are involved before training the deep learning model?,"Before training the deep learning model, the following preprocessing steps were involved: 1. The MODIS-derived NDVI and LAI images collected in 2009 were co-registered. 2. Pixel-wise MLP was used to estimate species richness. 3. The missing values at different pixel locations and times due to high cloud cover were handled by using multilayer perception, which comprises more than one perceptron, which consists of an input layer to receive the signal, an output layer that makes a decision, and one in between those two. Reference(s): 65. Chollet, F. Deep Learning with R; Manning Publications: Shelter Island, NY, USA, 2018. 66. Srivastava, N. ; Hinton, G. ; Krizhevsky, A. ; Sutskever, I. ; Salakhutdinov, R. Dropout: A simple way to prevent neural networks from overﬁtting. J. Mach. Learn. Res. 2014, 15, 1929–1958. 67. Bhatnagar, S. ; Gill, L. ; Ghosh, B. Drone image segmentation using machine and deep learning for mapping raised bog vegetation communities. Remote Sens. 2020, 12, 2602. [CrossRef] 68. Kim, Y. ; Kim, H. -C. ; Han, D. ; Lee, S. ; Im, J. Prediction of monthly Arctic sea ice concentrations using satellite and reanalysis data based on convolutional neural networks. Cryosphere 2020, 14, 1083–1104. [CrossRef] 69. Korotcov, A. ; Tkachenko, V. ; Russo, D. P. ; Ekins, S. Comparison of deep learning with multiple machine learning methods and metrics using diverse drug discovery data sets. Mol. Pharm. 2017, 14, 4462–4475. [CrossRef] Joharestani, M. Z. ; Cao, C. ; Ni, X. ; Bashir, B. ; Talebiesfandarani, S. PM2. 5 prediction based on random forest, XGBoost, and deep learning using multisource remote sensing data. Atmosphere 2019, 10, 373. [CrossRef] Fernández-Delgado, M. ; Cernadas, E. ; Barro, S. ; Amorim, D. Do we need hundreds of classiﬁers to solve real world classiﬁ-cation problems? J. 2014, 15, 3133–3181. 70. 72. Korea Forest Service. The 6th National Forest Inventory and Monitoring; Korea Forest Service: Daejeon, Korea, 2016. 73. Choe, H. ; Thorne, J. H. ; Huber, P. R. ; Lee, D. ; Quinn, J. F. Assessing shortfalls and complementary conservation areas for national plant biodiversity in South Korea. PLoS ONE 2018, 13, e0190754. [CrossRef] 74. Malhi, Y. ; Franklin, J. ; Seddon, N. ; Solan, M. ; Turner, M. G. ; Field, C. B. ; Knowlton, N. Climate change and ecosystems: Threats, opportunities and solutions. Philos. Trans. Soc. B Biol. Sci. 2020, 375, 20190104. [CrossRef] Before training the deep learning model, the following preprocessing steps were involved: 1. Do we need hundreds of classiﬁers to solve real world classiﬁ- cation problems? J. [CrossRef] 10 of 20 Remote Sens. 2021, 13, 2490 Remote Sens. 2021, 13, x FOR PEER REVIEW 11 of 20 ",PreprocessingStep,https://w3id.org/dlprovenance#PreprocessingStep_2,estimated potential plant species richness patterns for North Korea using a state-of-the-art DL approach
5,5,What preprocessing steps are involved before training the deep learning model?,"Before training the deep learning model, the following preprocessing steps were involved: 1. The MODIS-derived NDVI and LAI images collected in 2009 were co-registered. 2. Pixel-wise MLP was used to estimate species richness. 3. The missing values at different pixel locations and times due to high cloud cover were handled by using multilayer perception, which comprises more than one perceptron, which consists of an input layer to receive the signal, an output layer that makes a decision, and one in between those two. Reference(s): 65. Chollet, F. Deep Learning with R; Manning Publications: Shelter Island, NY, USA, 2018. 66. Srivastava, N. ; Hinton, G. ; Krizhevsky, A. ; Sutskever, I. ; Salakhutdinov, R. Dropout: A simple way to prevent neural networks from overﬁtting. J. Mach. Learn. Res. 2014, 15, 1929–1958. 67. Bhatnagar, S. ; Gill, L. ; Ghosh, B. Drone image segmentation using machine and deep learning for mapping raised bog vegetation communities. Remote Sens. 2020, 12, 2602. [CrossRef] 68. Kim, Y. ; Kim, H. -C. ; Han, D. ; Lee, S. ; Im, J. Prediction of monthly Arctic sea ice concentrations using satellite and reanalysis data based on convolutional neural networks. Cryosphere 2020, 14, 1083–1104. [CrossRef] 69. Korotcov, A. ; Tkachenko, V. ; Russo, D. P. ; Ekins, S. Comparison of deep learning with multiple machine learning methods and metrics using diverse drug discovery data sets. Mol. Pharm. 2017, 14, 4462–4475. [CrossRef] Joharestani, M. Z. ; Cao, C. ; Ni, X. ; Bashir, B. ; Talebiesfandarani, S. PM2. 5 prediction based on random forest, XGBoost, and deep learning using multisource remote sensing data. Atmosphere 2019, 10, 373. [CrossRef] Fernández-Delgado, M. ; Cernadas, E. ; Barro, S. ; Amorim, D. Do we need hundreds of classiﬁers to solve real world classiﬁ-cation problems? J. 2014, 15, 3133–3181. 70. 72. Korea Forest Service. The 6th National Forest Inventory and Monitoring; Korea Forest Service: Daejeon, Korea, 2016. 73. Choe, H. ; Thorne, J. H. ; Huber, P. R. ; Lee, D. ; Quinn, J. F. Assessing shortfalls and complementary conservation areas for national plant biodiversity in South Korea. PLoS ONE 2018, 13, e0190754. [CrossRef] 74. Malhi, Y. ; Franklin, J. ; Seddon, N. ; Solan, M. ; Turner, M. G. ; Field, C. B. ; Knowlton, N. Climate change and ecosystems: Threats, opportunities and solutions. Philos. Trans. Soc. B Biol. Sci. 2020, 375, 20190104. [CrossRef] Before training the deep learning model, the following preprocessing steps were involved: 1. Do we need hundreds of classiﬁers to solve real world classiﬁ- cation problems? J. [CrossRef] 10 of 20 Remote Sens. 2021, 13, 2490 Remote Sens. 2021, 13, x FOR PEER REVIEW 11 of 20 ",PreprocessingStep,https://w3id.org/dlprovenance#PreprocessingStep_3,"estimated the potential plant species richness for the Korean Peninsula, including North Korea, which has limited survey data"
5,7,Does the paper discuss data bias or ethical implications?,"No, the paper does not discuss data bias or ethical implications. ",Bias,https://w3id.org/dlprovenance#Bias_1,not discussed
5,7,Does the paper discuss data bias or ethical implications?,"No, the paper does not discuss data bias or ethical implications. ",EthicalImplication,https://w3id.org/dlprovenance#EthicalImplication_1,not discussed
5,8,What is the architecture of the deep learning model in the pipeline?,"The deep learning model used in the pipeline is a multilayer perceptron (MLP) architecture. It is a type of feedforward neural network that is effective for solving regression problems. It comprises an input layer, an output layer, and one or more hidden layers in between. The network architecture of MLP used in this study is illustrated in Figure 3 of the document. ",Architecture,https://w3id.org/dlprovenance#Architecture_1,multilayer perception (MLP)
5,8,What is the architecture of the deep learning model in the pipeline?,"The deep learning model used in the pipeline is a multilayer perceptron (MLP) architecture. It is a type of feedforward neural network that is effective for solving regression problems. It comprises an input layer, an output layer, and one or more hidden layers in between. The network architecture of MLP used in this study is illustrated in Figure 3 of the document. ",Model,https://w3id.org/dlprovenance#Model_1,multilayer perceptron (MLP)
5,9,How was the model selected for a specific task?,"The model was selected based on the root mean square error (RMSE) as the performance metric. The feature importance shows the extent to which the model performance decreased with random shuffling. The feature with the greatest significance in the species richness retrievals was determined using a statistical feature importance test (SFIT). The SFIT involved randomly shuffling a single feature while keeping all the other features constant, and iterating this process by changing the test variable. The feature importance was then calculated based on the decrease in model performance. ",ModelSelectionProcess,https://w3id.org/dlprovenance#ModelSelectionProcess_1,"Random Forest, Support Vector Machine, and Deep Learning models"
5,9,How was the model selected for a specific task?,"The model was selected based on the root mean square error (RMSE) as the performance metric. The feature importance shows the extent to which the model performance decreased with random shuffling. The feature with the greatest significance in the species richness retrievals was determined using a statistical feature importance test (SFIT). The SFIT involved randomly shuffling a single feature while keeping all the other features constant, and iterating this process by changing the test variable. The feature importance was then calculated based on the decrease in model performance. ",Model,https://w3id.org/dlprovenance#Model_1,multilayer perceptron (MLP)
5,10,What were the considerations in the model selection process?,"The model selection process considered the use of macro-ecological models and stacking species distribution models (S-SDMs) to estimate species richness. The S-SDMs approach was chosen because it combines the predictions of each species’ SDM to estimate species richness, and probability-based stacking produced unbiased richness that is closer to the true species richness. The model was then validated using independent tree plot datasets from the Korea Forest Service. ",Consideration,https://w3id.org/dlprovenance#Consideration_1,macro-ecological models and stacking species distribution models (S-SDMs) to estimate species richness
5,10,What were the considerations in the model selection process?,"The model selection process considered the use of macro-ecological models and stacking species distribution models (S-SDMs) to estimate species richness. The S-SDMs approach was chosen because it combines the predictions of each species’ SDM to estimate species richness, and probability-based stacking produced unbiased richness that is closer to the true species richness. The model was then validated using independent tree plot datasets from the Korea Forest Service. ",Consideration,https://w3id.org/dlprovenance#Consideration_2,probability-based stacking produced unbiased richness that is closer to the true species richness
5,10,What were the considerations in the model selection process?,"The model selection process considered the use of macro-ecological models and stacking species distribution models (S-SDMs) to estimate species richness. The S-SDMs approach was chosen because it combines the predictions of each species’ SDM to estimate species richness, and probability-based stacking produced unbiased richness that is closer to the true species richness. The model was then validated using independent tree plot datasets from the Korea Forest Service. ",Consideration,https://w3id.org/dlprovenance#Consideration_3,validated using independent tree plot datasets from the Korea Forest Service
5,11,How many models are used in the pipeline?,The pipeline uses two models: a deep learning (DL) model and a species distribution model (SDM). The DL model is used to estimate the plant species richness for both North and South Korea from the original MODIS-driven NDVI and LAI images (15-arcseconds). The SDM model is used to estimate the potential plant species richness of South Korea by combining the probability-based SDM results of the 1574 species. ,NumberOfModels,https://w3id.org/dlprovenance#NumberOfModels_1,two models: a deep learning (DL) model and a species distribution model (SDM)
5,12,Are the models considered state-of-the-art?,"The models used in the study are not explicitly stated to be state-of-the-art. The study uses Random Forest, Support Vector Machine, and Deep Learning models, which are commonly used methods in species distribution modeling. However, the study does not mention any specific innovations or improvements in these methods that would make them state-of-the-art. ",StateOfTheArt,https://w3id.org/dlprovenance#StateOfTheArt_1,not explicitly stated
5,12,Are the models considered state-of-the-art?,"The models used in the study are not explicitly stated to be state-of-the-art. The study uses Random Forest, Support Vector Machine, and Deep Learning models, which are commonly used methods in species distribution modeling. However, the study does not mention any specific innovations or improvements in these methods that would make them state-of-the-art. ",Model,https://w3id.org/dlprovenance#Model_1,multilayer perceptron (MLP)
5,13,How is the model initialized?,The model is initialized by using the first 10% of the data for training and the remaining 90% for testing. This is a common practice in machine learning to ensure that the model is able to generalize well to new data. ,Model,https://w3id.org/dlprovenance#Model_1,multilayer perceptron (MLP)
5,14,Are there specific weight configurations used during initialization?,The text does not provide information about specific weight configurations used during initialization. ,WeightConfiguration,https://w3id.org/dlprovenance#WeightConfiguration_1,not specified
5,14,Are there specific weight configurations used during initialization?,The text does not provide information about specific weight configurations used during initialization. ,WeightConfiguration,https://w3id.org/dlprovenance#WeightConfiguration_2,not specified
5,15,Are there optimization algorithms or learning rate schedules used during training?,The text does not provide information about optimization algorithms or learning rate schedules used during training. ,OptimizationAlgorithm,https://w3id.org/dlprovenance#OptimizationAlgorithm_1,not specified
5,15,Are there optimization algorithms or learning rate schedules used during training?,The text does not provide information about optimization algorithms or learning rate schedules used during training. ,LearningRateSchedule,https://w3id.org/dlprovenance#LearningRateSchedule_1,not specified
5,16,What is the convergence criteria or stopping condition for the training process?,The convergence criteria or stopping condition for the training process is not specified in the given context. It is not possible to answer this question without additional information. Confidence: 85%,ConvergenceCriteria,https://w3id.org/dlprovenance#ConvergenceCriteria_1,not specified
5,17,Which software frameworks or libraries are used to build the model?,"The provided context does not explicitly state which software frameworks or libraries were used to build the model. However, it is mentioned that the model was built using Python. Therefore, it can be inferred that Python libraries or frameworks were used to build the model. ",SoftwareFrameworkLibrary,https://w3id.org/dlprovenance#SoftwareFrameworkLibrary_1,Python
5,18,What hardware infrastructures are used for model training?,The provided context does not contain information about the hardware infrastructures used for model training. ,HardwareInfrastructure,https://w3id.org/dlprovenance#HardwareInfrastructure_1,not specified
5,19,What hyperparameters are used in the model?,"The provided context does not explicitly state the hyperparameters used in the model. However, it does mention that the model is a deep learning model, and deep learning models typically have hyperparameters such as learning rate, batch size, number of layers, and number of neurons per layer. Without more information, it is not possible to provide a specific answer to this query. ",Hyperparameter,https://w3id.org/dlprovenance#Hyperparameter_1,first 10% of the data for training and the remaining 90% for testing
5,19,What hyperparameters are used in the model?,"The provided context does not explicitly state the hyperparameters used in the model. However, it does mention that the model is a deep learning model, and deep learning models typically have hyperparameters such as learning rate, batch size, number of layers, and number of neurons per layer. Without more information, it is not possible to provide a specific answer to this query. ",Hyperparameter,https://w3id.org/dlprovenance#Hyperparameter_2,root mean square error (RMSE)
5,19,What hyperparameters are used in the model?,"The provided context does not explicitly state the hyperparameters used in the model. However, it does mention that the model is a deep learning model, and deep learning models typically have hyperparameters such as learning rate, batch size, number of layers, and number of neurons per layer. Without more information, it is not possible to provide a specific answer to this query. ",Hyperparameter,https://w3id.org/dlprovenance#Hyperparameter_3,not specified
5,20,Why were those specific hyperparameters selected?,"The specific hyperparameters were selected based on a grid search, where the model was trained and validated with different combinations of hyperparameters. The combination that resulted in the best performance, as measured by the root mean square error (RMSE), was selected as the final set of hyperparameters. ",Hyperparameter,https://w3id.org/dlprovenance#Hyperparameter_1,first 10% of the data for training and the remaining 90% for testing
5,20,Why were those specific hyperparameters selected?,"The specific hyperparameters were selected based on a grid search, where the model was trained and validated with different combinations of hyperparameters. The combination that resulted in the best performance, as measured by the root mean square error (RMSE), was selected as the final set of hyperparameters. ",Hyperparameter,https://w3id.org/dlprovenance#Hyperparameter_2,root mean square error (RMSE)
5,20,Why were those specific hyperparameters selected?,"The specific hyperparameters were selected based on a grid search, where the model was trained and validated with different combinations of hyperparameters. The combination that resulted in the best performance, as measured by the root mean square error (RMSE), was selected as the final set of hyperparameters. ",Hyperparameter,https://w3id.org/dlprovenance#Hyperparameter_3,not specified
5,21,Are the provided hyperparameters fine-tuned?,"The provided context does not mention any fine-tuning of the hyperparameters. The hyperparameters used in the study are mentioned in the text, but there is no information about whether they were fine-tuned or not. Therefore, the answer is ""No, the provided context does not mention any fine- tuning of the hyperparameters. """,FineTuning,https://w3id.org/dlprovenance#FineTuning_1,not specified
5,24,Is there sufficient information to reproduce the deep learning pipeline?,"No, there is not sufficient information to reproduce the deep learning pipeline. The paper does not provide enough details about the deep learning pipeline, such as the architecture of the neural network, the training procedure, and the evaluation metrics used. Additionally, the code and data used in the study are not publicly available. ",Reproducibility,https://w3id.org/dlprovenance#Reproducibility_1,not sufficient information to reproduce the deep learning pipeline
5,25,What measures are taken to explain model predictions?,"To explain model predictions, a statistical feature importance test (SFIT) is performed. In this test, a single feature is randomly shuffled, while all the other features are kept constant. The feature importance shows the extent to which the model performance decreases with random shuffling. In this study, the root mean square error (RMSE) is used as the performance metric. ",Explanation,https://w3id.org/dlprovenance#Explanation_1,statistical feature importance test (SFIT)
5,25,What measures are taken to explain model predictions?,"To explain model predictions, a statistical feature importance test (SFIT) is performed. In this test, a single feature is randomly shuffled, while all the other features are kept constant. The feature importance shows the extent to which the model performance decreases with random shuffling. In this study, the root mean square error (RMSE) is used as the performance metric. ",PredictionClassification,https://w3id.org/dlprovenance#PredictionClassification_1,"potential plant species richness for the Korean Peninsula, including North Korea"
5,26,What is the versioning strategy for trained models?,The provided context does not contain information about the versioning strategy for trained models. ,VersioningStrategy,https://w3id.org/dlprovenance#VersioningStrategy_1,not specified
5,27,How are different versions of datasets managed?,"The text does not provide specific information on how different versions of datasets are managed. It mainly focuses on the use of deep learning to estimate plant species richness in the Korean Peninsula, including North Korea, by combining species distribution models and remote sensing data. ",DatasetVersion,https://w3id.org/dlprovenance#DatasetVersion_1,not specified
5,28,How are updates to datasets documented?,"In the given context, there is no explicit mention of how updates to datasets are documented. It is possible that the method for documenting updates is not specified in the provided text. ",UpdateFrequency,https://w3id.org/dlprovenance#UpdateFrequency_1,not specified
5,28,How are updates to datasets documented?,"In the given context, there is no explicit mention of how updates to datasets are documented. It is possible that the method for documenting updates is not specified in the provided text. ",UpdateFrequency,https://w3id.org/dlprovenance#UpdateFrequency_2,not specified
5,29,What annotations or labels are associated with the data?,"The data is not directly labeled or annotated in the provided context. However, the data is used to train and test models for estimating plant species richness. The models are evaluated based on their ability to predict species richness in independent datasets. The data is also used to identify which variables at which time periods are more important for estimating plant species richness. ",PredictionClassification,https://w3id.org/dlprovenance#PredictionClassification_1,"potential plant species richness for the Korean Peninsula, including North Korea"
5,31,What predictions or classifications are generated by the deep learning model?,"The deep learning model generates predictions of potential plant species richness for the Korean Peninsula, including North Korea, which has limited survey data. It does this by combining the suitability predictions of 1574 species using species distribution models and multitemporal remote sensing data. The model is able to estimate potential plant species richness over the entire Korean Peninsula at a higher resolution than in previous efforts and identify which variables at which time periods are more important for estimating plant species richness. The deep learning model used in this study is a pixel-wise multilayer perceptron (MLP) which is a type of feedforward neural network that is effective for solving regression problems. ",PredictionClassification,https://w3id.org/dlprovenance#PredictionClassification_1,"potential plant species richness for the Korean Peninsula, including North Korea"
5,32,How is uncertainty or confidence in model predictions captured?,"The uncertainty or confidence in model predictions is not explicitly mentioned in the provided context. However, the authors do mention that they used k-fold cross-validation with k = 5 to fit the models and averaged the 5 results for the final suitability result for each species. This approach can help to reduce uncertainty and increase the robustness of the model predictions. Additionally, the authors mention that they used probability-based stacking to combine the predictions of each species’ SDM to estimate species richness, which can also help to capture uncertainty in the model predictions. However, the specific methods used to capture uncertainty or confidence in the model predictions are not provided in the context. ",UncertaintyConfidence,https://w3id.org/dlprovenance#UncertaintyConfidence_1,not specified
5,32,How is uncertainty or confidence in model predictions captured?,"The uncertainty or confidence in model predictions is not explicitly mentioned in the provided context. However, the authors do mention that they used k-fold cross-validation with k = 5 to fit the models and averaged the 5 results for the final suitability result for each species. This approach can help to reduce uncertainty and increase the robustness of the model predictions. Additionally, the authors mention that they used probability-based stacking to combine the predictions of each species’ SDM to estimate species richness, which can also help to capture uncertainty in the model predictions. However, the specific methods used to capture uncertainty or confidence in the model predictions are not provided in the context. ",UncertaintyConfidence,https://w3id.org/dlprovenance#UncertaintyConfidence_2,not specified
5,33,Are there post-processing steps applied to the model's output?,The text does not mention any post-processing steps applied to the model's output. ,PostProcessing,https://w3id.org/dlprovenance#PostProcessing_1,not specified
5,34,"Is the trained model deployed, and if not, what is the reason?","The provided context does not contain information about whether the trained model is deployed or not, and it does not provide any information about the reason why it might not be deployed. Therefore, it is not possible to answer this question without additional information. ",Deployment,https://w3id.org/dlprovenance#Deployment_1,not specified
5,35,What hardware and software are used for model deployment?,The provided context does not specify the hardware and software used for model deployment. ,SoftwareFrameworkLibrary,https://w3id.org/dlprovenance#SoftwareFrameworkLibrary_1,Python
5,35,What hardware and software are used for model deployment?,The provided context does not specify the hardware and software used for model deployment. ,HardwareInfrastructure,https://w3id.org/dlprovenance#HardwareInfrastructure_1,not specified
5,37,What ethical considerations are taken into account during development and deployment?,"The ethical considerations taken into account during development and deployment of the system are not specified in the provided context. However, the context does mention that the system is designed to help mitigate climate change and conserve biodiversity, which suggests that ethical considerations related to environmental sustainability were taken into account. Additionally, the system is designed to be transparent and explainable, which can help ensure that the system is used ethically and responsibly. ",EthicalImplication,https://w3id.org/dlprovenance#EthicalImplication_1,not discussed
5,38,How is bias in the data addressed?,"The authors address bias in the data by using probability-based stacking, which has been found to produce unbiased richness that is closer to the true species richness. This method combines the predictions of each species' species distribution model (SDM) to estimate species richness. The authors also use MODIS products, Normalized Difference Vegetation Index (NDVI) and Leaf Area Index (LAI), as input variables to estimate the potential plant species richness of South Korea. These products are known to have high temporal and spatial resolution, making them suitable for monitoring vegetation dynamics and estimating species richness. However, the authors do not explicitly mention how they address bias in the MODIS products. ",BiasAddressing,https://w3id.org/dlprovenance#BiasAddressing_1,not specified
5,39,Is there transparency in the decision-making process regarding bias?,"The provided context does not directly address the query about transparency in the decision-making process regarding bias. However, it does mention that the study used a method called ""stacking species distribution models"" to estimate species richness. This method combines the predictions of each species' distribution model to estimate species richness. While the study does not explicitly discuss transparency in the decision-making process regarding bias, it does mention that probability-based stacking produced unbiased richness that is closer to the true species richness. This suggests that the study took steps to minimize bias in the estimation of species richness. However, without further information, it is not possible to determine whether the decision-making process regarding bias was transparent. ",Transparency,https://w3id.org/dlprovenance#Transparency_1,not specified
5,40,Are privacy and security measures implemented in handling sensitive data?,"The text does not provide explicit information about whether privacy and security measures are implemented in handling sensitive data. However, it does mention that the study used the Global Biodiversity Information Facility (GBIF) dataset, which is a public database that provides open access to biodiversity data. Therefore, it can be inferred that the study followed the data handling and privacy policies of GBIF. However, the text does not provide any specific information about the measures taken to ensure data privacy and security. ",PrivacySecurityMeasure,https://w3id.org/dlprovenance#PrivacySecurityMeasure_1,not specified
5,40,Are privacy and security measures implemented in handling sensitive data?,"The text does not provide explicit information about whether privacy and security measures are implemented in handling sensitive data. However, it does mention that the study used the Global Biodiversity Information Facility (GBIF) dataset, which is a public database that provides open access to biodiversity data. Therefore, it can be inferred that the study followed the data handling and privacy policies of GBIF. However, the text does not provide any specific information about the measures taken to ensure data privacy and security. ",SensitiveData,https://w3id.org/dlprovenance#SensitiveData_1,not specified
