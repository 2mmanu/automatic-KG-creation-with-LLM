Publication No.,CQ No.,CQ,CQ LLM Answer,Ontology Concept,KG Individual,KG Individual Label
8,1,What data formats are used in the deep learning pipeline?,The data formats used in the deep learning pipeline are images and bounding boxes. The images are the input to the model and the bounding boxes are the annotations used for training and evaluating the model.,DataFormat,https://w3id.org/dlprovenance#DataFormat_1,images
8,1,What data formats are used in the deep learning pipeline?,The data formats used in the deep learning pipeline are images and bounding boxes. The images are the input to the model and the bounding boxes are the annotations used for training and evaluating the model.,DataFormat,https://w3id.org/dlprovenance#DataFormat_2,bounding boxes
8,2,What are the sources of input data for the deep learning pipeline?,The sources of input data for the deep learning pipeline are the herbarium scans.,Source,https://w3id.org/dlprovenance#Source_1,herbarium scans
8,3,How was raw data collected in terms of methods and tools?,"cted by manually localizing and labeling plant organs from herbarium specimens. The process of localizing and labeling encountered difficulties such as distinguishing between buds, flowers, and fruits, separating different plant organs in some taxa, and differentiating between roots and stolons or other stem structures.",Method,https://w3id.org/dlprovenance#Method_1,manual localization and labeling
8,3,How was raw data collected in terms of methods and tools?,"cted by manually localizing and labeling plant organs from herbarium specimens. The process of localizing and labeling encountered difficulties such as distinguishing between buds, flowers, and fruits, separating different plant organs in some taxa, and differentiating between roots and stolons or other stem structures.",Method,https://w3id.org/dlprovenance#Method_2,herbarium scans
8,3,How was raw data collected in terms of methods and tools?,"cted by manually localizing and labeling plant organs from herbarium specimens. The process of localizing and labeling encountered difficulties such as distinguishing between buds, flowers, and fruits, separating different plant organs in some taxa, and differentiating between roots and stolons or other stem structures.",Tool,https://w3id.org/dlprovenance#Tool_1,LabelImg
8,4,"Is the source code openly accessible, and if so, what is the repository link?",The source code is openly accessible in the GitHub repository.,RepositoryLink,https://w3id.org/dlprovenance#RepositoryLink_1,GitHub repository
8,5,What preprocessing steps are involved before training the deep learning model?,"The herbarium scans were rescaled to 1200 by 800 pixels, and manually annotated for six different types of organs using LabelImg. The annotated images were then divided into a validated subset of 155 images for testing and 498 images for training.",PreprocessingStep,https://w3id.org/dlprovenance#PreprocessingStep_1,rescaling to 1200 by 800 pixels
8,7,Does the paper discuss data bias or ethical implications?,The paper does not discuss data bias or ethical implications.,EthicalImplication,https://w3id.org/dlprovenance#EthicalImplication_1,"bounding boxes for six types of plant organs: leaves, flowers, fruits, seeds, stems, and roots"
8,8,What is the architecture of the deep learning model in the pipeline?,"The deep learning model in the pipeline is a Convolutional Neural Network (CNN) architecture called Faster R-CNN, which consists of three modules: a deep CNN image feature extraction network based on the ResNet-50 architecture, a Region Proposal Network (RPN) used for detection of Regions of Interests (RoIs), and Fast R-CNN, which computes a classification score along with class-specific bounding box regression for each of these regions.",Architecture,https://w3id.org/dlprovenance#Architecture_1,Faster R-CNN
8,8,What is the architecture of the deep learning model in the pipeline?,"The deep learning model in the pipeline is a Convolutional Neural Network (CNN) architecture called Faster R-CNN, which consists of three modules: a deep CNN image feature extraction network based on the ResNet-50 architecture, a Region Proposal Network (RPN) used for detection of Regions of Interests (RoIs), and Fast R-CNN, which computes a classification score along with class-specific bounding box regression for each of these regions.",Model,https://w3id.org/dlprovenance#Model_1,Faster R-CNN
8,9,How was the model selected for a specific task?,The model was selected based on its performance on the test subset of the MNHN Paris Herbarium dataset and the model with the highest average precision was chosen for the task of organ detection on the Herbarium Senckenbergianum dataset.,Model,https://w3id.org/dlprovenance#Model_1,Faster R-CNN
8,10,What were the considerations in the model selection process?,"The model selection process was not explicitly described in the text, but the authors used a deep learning model for organ detection and tested it on a subset of annotated scans.",Consideration,https://w3id.org/dlprovenance#Consideration_1,performance on the test subset of the MNHN Paris Herbarium dataset
8,11,How many models are used in the pipeline?,The pipeline uses a single model for organ detection.,NumberOfModels,https://w3id.org/dlprovenance#NumberOfModels_1,single model
8,12,Are the models considered state-of-the-art?,The models used in the study are not considered state-of-the-art.,Model,https://w3id.org/dlprovenance#Model_1,Faster R-CNN
8,13,How is the model initialized?,The model is initialized using a pre-trained model on the COCO dataset and then fine-tuned on the annotated herbarium dataset.,Model,https://w3id.org/dlprovenance#Model_1,Faster R-CNN
8,15,Are there optimization algorithms or learning rate schedules used during training?,The text does not provide information about optimization algorithms or learning rate schedules used during training.,OptimizationAlgorithm,https://w3id.org/dlprovenance#OptimizationAlgorithm_1,Stochastic Gradient Descent
8,16,What is the convergence criteria or stopping condition for the training process?,The stopping condition for the training process is a fixed number of iterations or epochs.,ConvergenceCriteria,https://w3id.org/dlprovenance#ConvergenceCriteria_1,fixed number of iterations or epochs
8,17,Which software frameworks or libraries are used to build the model?,The Faster R-CNN model was built using TensorFlow and trained using the TensorFlow Object Detection API.,SoftwareFrameworkLibrary,https://w3id.org/dlprovenance#SoftwareFrameworkLibrary_1,TensorFlow and TensorFlow Object Detection API
8,18,What hardware infrastructures are used for model training?,The model was trained on a single GPU (TITAN Xp) and on three GPUs for the final training.,HardwareInfrastructure,https://w3id.org/dlprovenance#HardwareInfrastructure_1,single GPU (TITAN Xp) and three GPUs
8,19,What hyperparameters are used in the model?,"The hyperparameters used in the model are Stochastic Gradient Descent optimizer with a learning rate of 0.0025 and momentum of 0.9, Anchor generator in the Region Proposal Network with six anchor scales and three aspect ratios, thresholds for non-maximum suppression (NMS) of 0.6 for training and 0.25 for testing, and minibatch size of four images per GPU.",Hyperparameter,https://w3id.org/dlprovenance#Hyperparameter_1,Stochastic Gradient Descent optimizer with a learning rate of 0.0025 and momentum of 0.9
8,19,What hyperparameters are used in the model?,"The hyperparameters used in the model are Stochastic Gradient Descent optimizer with a learning rate of 0.0025 and momentum of 0.9, Anchor generator in the Region Proposal Network with six anchor scales and three aspect ratios, thresholds for non-maximum suppression (NMS) of 0.6 for training and 0.25 for testing, and minibatch size of four images per GPU.",Hyperparameter,https://w3id.org/dlprovenance#Hyperparameter_2,"Anchor generator in the Region Proposal Network with six anchor scales and three aspect ratios, thresholds for non-maximum suppression (NMS) of 0.6 for training and 0.25 for testing, and minibatch size of four images per GPU"
8,20,Why were those specific hyperparameters selected?,parameters were selected based on the results of a grid search. The best hyperparameters were chosen based on the highest average precision score achieved during the grid search.,Hyperparameter,https://w3id.org/dlprovenance#Hyperparameter_1,Stochastic Gradient Descent optimizer with a learning rate of 0.0025 and momentum of 0.9
8,20,Why were those specific hyperparameters selected?,parameters were selected based on the results of a grid search. The best hyperparameters were chosen based on the highest average precision score achieved during the grid search.,Hyperparameter,https://w3id.org/dlprovenance#Hyperparameter_2,"Anchor generator in the Region Proposal Network with six anchor scales and three aspect ratios, thresholds for non-maximum suppression (NMS) of 0.6 for training and 0.25 for testing, and minibatch size of four images per GPU"
8,32,How is uncertainty or confidence in model predictions captured?,"The uncertainty or confidence in model predictions is captured through the confidence score (probability) of the predictions, and the COCO method calculates average precision (with values from 0 to 100) for the entire predictions and each class of organs at different levels of Intersection over Union (IoU).",UncertaintyConfidence,https://w3id.org/dlprovenance#UncertaintyConfidence_1,"COCO evaluation metric, which calculates average precision for the entire predictions and each class of organs at different levels of Intersection over Union (IoU)"
8,32,How is uncertainty or confidence in model predictions captured?,"The uncertainty or confidence in model predictions is captured through the confidence score (probability) of the predictions, and the COCO method calculates average precision (with values from 0 to 100) for the entire predictions and each class of organs at different levels of Intersection over Union (IoU).",UncertaintyConfidence,https://w3id.org/dlprovenance#UncertaintyConfidence_2,confidence score (probability) of the predictions
8,33,Are there post-processing steps applied to the model's output?,"Yes, there are post-processing steps applied to the model's output, including manual verification and correction of a subset of the predictions, and annotation of an un-annotated dataset based on the model's predictions.",PostProcessing,https://w3id.org/dlprovenance#PostProcessing_1,"manual verification and correction of a subset of the predictions, and annotation of an un-annotated dataset based on the model's predictions"
8,35,What hardware and software are used for model deployment?,The model was implemented using the Detectron2 library in the PyTorch framework and trained using Stochastic Gradient Descent optimizer with a learning rate of 0.0025 and momentum of 0.9. The model was trained on a single TITAN Xp GPU and three GPUs for different iterations.,SoftwareFrameworkLibrary,https://w3id.org/dlprovenance#SoftwareFrameworkLibrary_1,TensorFlow and TensorFlow Object Detection API
8,35,What hardware and software are used for model deployment?,The model was implemented using the Detectron2 library in the PyTorch framework and trained using Stochastic Gradient Descent optimizer with a learning rate of 0.0025 and momentum of 0.9. The model was trained on a single TITAN Xp GPU and three GPUs for different iterations.,HardwareInfrastructure,https://w3id.org/dlprovenance#HardwareInfrastructure_1,single GPU (TITAN Xp) and three GPUs
8,37,What ethical considerations are taken into account during development and deployment?,The study does not provide information on ethical considerations taken into account during development and deployment.,EthicalImplication,https://w3id.org/dlprovenance#EthicalImplication_1,"bounding boxes for six types of plant organs: leaves, flowers, fruits, seeds, stems, and roots"
