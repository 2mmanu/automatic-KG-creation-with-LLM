Publication No.,CQ No.,CQ,CQ LLM Answer,Ontology Concept,KG Individual,KG Individual Label
5,1,What data formats are used in the deep learning pipeline?,"The data formats used in the deep learning pipeline include multitemporal remote sensing data, such as MODIS-derived NDVI and LAI images collected in 2009, and plant species richness data from South Korea. These data are co-registered, resampled, and used to estimate potential plant species richness patterns for North Korea using a state-of-the-art DL approach.",DataFormat,https://w3id.org/dlprovenance#DataFormat_1,multitemporal remote sensing data
5,1,What data formats are used in the deep learning pipeline?,"The data formats used in the deep learning pipeline include multitemporal remote sensing data, such as MODIS-derived NDVI and LAI images collected in 2009, and plant species richness data from South Korea. These data are co-registered, resampled, and used to estimate potential plant species richness patterns for North Korea using a state-of-the-art DL approach.",DataFormat,https://w3id.org/dlprovenance#DataFormat_2,plant species richness data from South Korea
5,2,What are the sources of input data for the deep learning pipeline?,"The sources of input data for the deep learning pipeline are MODIS products, including the normalized difference vegetation index (NDVI) and leaf area index (LAI).",Source,https://w3id.org/dlprovenance#Source_1,"MODIS products, including the normalized difference vegetation index (NDVI) and leaf area index (LAI)"
5,2,What are the sources of input data for the deep learning pipeline?,"The sources of input data for the deep learning pipeline are MODIS products, including the normalized difference vegetation index (NDVI) and leaf area index (LAI).",InputData,https://w3id.org/dlprovenance#InputData_1,multitemporal Landsat 8 images
5,2,What are the sources of input data for the deep learning pipeline?,"The sources of input data for the deep learning pipeline are MODIS products, including the normalized difference vegetation index (NDVI) and leaf area index (LAI).",InputData,https://w3id.org/dlprovenance#InputData_2,"plant species occurrence records from the Korea National Arboretum, the National Institute of Biological Resources, and the Korea Forest Service"
5,3,How was raw data collected in terms of methods and tools?,"The raw data for this study was collected using multitemporal Landsat 8 images and plant species occurrence records from the Korea National Arboretum, the National Institute of Biological Resources, and the Korea Forest Service. The remote sensing data was preprocessed using the Google Earth Engine platform.",Method,https://w3id.org/dlprovenance#Method_1,Google Earth Engine platform
5,3,How was raw data collected in terms of methods and tools?,"The raw data for this study was collected using multitemporal Landsat 8 images and plant species occurrence records from the Korea National Arboretum, the National Institute of Biological Resources, and the Korea Forest Service. The remote sensing data was preprocessed using the Google Earth Engine platform.",Method,https://w3id.org/dlprovenance#Method_2,Google Earth Engine platform
5,3,How was raw data collected in terms of methods and tools?,"The raw data for this study was collected using multitemporal Landsat 8 images and plant species occurrence records from the Korea National Arboretum, the National Institute of Biological Resources, and the Korea Forest Service. The remote sensing data was preprocessed using the Google Earth Engine platform.",Tool,https://w3id.org/dlprovenance#Tool_1,Google Earth Engine platform
5,4,"Is the source code openly accessible, and if so, what is the repository link?",The source code is not available for access.,RepositoryLink,https://w3id.org/dlprovenance#RepositoryLink_1,not available for access
5,5,What preprocessing steps are involved before training the deep learning model?,"steps involved before training the deep learning model were co-registering MODIS-derived NDVI and LAI images collected in 2009, and using pixel-wise MLP to estimate species richness and handle missing values due to high cloud cover.",PreprocessingStep,https://w3id.org/dlprovenance#PreprocessingStep_1,co-registering MODIS-derived NDVI and LAI images collected in 2009
5,5,What preprocessing steps are involved before training the deep learning model?,"steps involved before training the deep learning model were co-registering MODIS-derived NDVI and LAI images collected in 2009, and using pixel-wise MLP to estimate species richness and handle missing values due to high cloud cover.",PreprocessingStep,https://w3id.org/dlprovenance#PreprocessingStep_2,using pixel-wise MLP to estimate species richness and handle missing values due to high cloud cover
5,6,Are there transformations or augmentations applied to the input data?,The provided context does not mention any transformations or augmentations applied to the input data.,TransformationAugmentation,https://w3id.org/dlprovenance#TransformationAugmentation_1,not mentioned
5,7,Does the paper discuss data bias or ethical implications?,The paper does not discuss data bias or ethical implications.,Bias,https://w3id.org/dlprovenance#Bias_1,not discussed
5,7,Does the paper discuss data bias or ethical implications?,The paper does not discuss data bias or ethical implications.,EthicalImplication,https://w3id.org/dlprovenance#EthicalImplication_1,related to environmental sustainability and transparency
5,8,What is the architecture of the deep learning model in the pipeline?,The deep learning model used in the pipeline is a multilayer perceptron (MLP) architecture. The network architecture of MLP used in this study is illustrated in Figure 3 of the document.,Architecture,https://w3id.org/dlprovenance#Architecture_1,multilayer perceptron (MLP) architecture
5,8,What is the architecture of the deep learning model in the pipeline?,The deep learning model used in the pipeline is a multilayer perceptron (MLP) architecture. The network architecture of MLP used in this study is illustrated in Figure 3 of the document.,Model,https://w3id.org/dlprovenance#Model_1,multilayer perceptron (MLP) architecture
5,9,How was the model selected for a specific task?,cted based on the root mean square error (RMSE) as the performance metric. The feature with the greatest significance in the species richness retrievals was determined using a statistical feature importance test (SFIT).,ModelSelectionProcess,https://w3id.org/dlprovenance#ModelSelectionProcess_1,based on the root mean square error (RMSE) as the performance metric and the feature with the greatest significance in the species richness retrievals determined using a statistical feature importance test (SFIT)
5,9,How was the model selected for a specific task?,cted based on the root mean square error (RMSE) as the performance metric. The feature with the greatest significance in the species richness retrievals was determined using a statistical feature importance test (SFIT).,Model,https://w3id.org/dlprovenance#Model_1,multilayer perceptron (MLP) architecture
5,10,What were the considerations in the model selection process?,"The model selection process considered the use of macro-ecological models and stacking species distribution models (S-SDMs) to estimate species richness, and the S-SDMs approach was chosen because it combines the predictions of each species’ SDM to estimate species richness.",Consideration,https://w3id.org/dlprovenance#Consideration_1,"the use of macro-ecological models and stacking species distribution models (S-SDMs) to estimate species richness, and the S-SDMs approach was chosen because it combines the predictions of each species’ SDM to estimate species richness"
5,11,How many models are used in the pipeline?,"The pipeline uses two models: a deep learning (DL) model and a species distribution model (SDM). The DL model is used for both North and South Korea, while the SDM model is used only for South Korea.",NumberOfModels,https://w3id.org/dlprovenance#NumberOfModels_1,two models: a deep learning (DL) model and a species distribution model (SDM)
5,12,Are the models considered state-of-the-art?,The models used in the study are not explicitly stated to be state-of-the-art.,StateOfTheArt,https://w3id.org/dlprovenance#StateOfTheArt_1,not explicitly stated
5,12,Are the models considered state-of-the-art?,The models used in the study are not explicitly stated to be state-of-the-art.,Model,https://w3id.org/dlprovenance#Model_1,multilayer perceptron (MLP) architecture
5,13,How is the model initialized?,"The model is initialized by splitting the data into training and testing sets, using 10% for training and 90% for testing.",Model,https://w3id.org/dlprovenance#Model_1,multilayer perceptron (MLP) architecture
5,14,Are there specific weight configurations used during initialization?,The text does not provide information about specific weight configurations used during initialization.,WeightConfiguration,https://w3id.org/dlprovenance#WeightConfiguration_1,not specified
5,15,Are there optimization algorithms or learning rate schedules used during training?,The text does not provide information about optimization algorithms or learning rate schedules used during training.,OptimizationAlgorithm,https://w3id.org/dlprovenance#OptimizationAlgorithm_1,not specified
5,15,Are there optimization algorithms or learning rate schedules used during training?,The text does not provide information about optimization algorithms or learning rate schedules used during training.,LearningRateSchedule,https://w3id.org/dlprovenance#LearningRateSchedule_1,not specified
5,16,What is the convergence criteria or stopping condition for the training process?,The convergence criteria or stopping condition for the training process is not specified in the given context.,ConvergenceCriteria,https://w3id.org/dlprovenance#ConvergenceCriteria_1,not specified
5,17,Which software frameworks or libraries are used to build the model?,Python libraries or frameworks were used to build the model.,SoftwareFrameworkLibrary,https://w3id.org/dlprovenance#SoftwareFrameworkLibrary_1,Python libraries or frameworks
5,18,What hardware infrastructures are used for model training?,The provided context does not contain information about the hardware infrastructures used for model training.,HardwareInfrastructure,https://w3id.org/dlprovenance#HardwareInfrastructure_1,not specified
5,19,What hyperparameters are used in the model?,The provided context does not explicitly state the hyperparameters used in the model.,Hyperparameter,https://w3id.org/dlprovenance#Hyperparameter_1,not specified
5,19,What hyperparameters are used in the model?,The provided context does not explicitly state the hyperparameters used in the model.,Hyperparameter,https://w3id.org/dlprovenance#Hyperparameter_2,not specified
5,19,What hyperparameters are used in the model?,The provided context does not explicitly state the hyperparameters used in the model.,Hyperparameter,https://w3id.org/dlprovenance#Hyperparameter_3,not specified
5,20,Why were those specific hyperparameters selected?,"parameters were selected based on a grid search method. The combination of hyperparameters that resulted in the best performance, as measured by the root mean square error (RMSE), was chosen as the final set of hyperparameters.",Hyperparameter,https://w3id.org/dlprovenance#Hyperparameter_1,not specified
5,20,Why were those specific hyperparameters selected?,"parameters were selected based on a grid search method. The combination of hyperparameters that resulted in the best performance, as measured by the root mean square error (RMSE), was chosen as the final set of hyperparameters.",Hyperparameter,https://w3id.org/dlprovenance#Hyperparameter_2,not specified
5,20,Why were those specific hyperparameters selected?,"parameters were selected based on a grid search method. The combination of hyperparameters that resulted in the best performance, as measured by the root mean square error (RMSE), was chosen as the final set of hyperparameters.",Hyperparameter,https://w3id.org/dlprovenance#Hyperparameter_3,not specified
5,21,Are the provided hyperparameters fine-tuned?,The provided context does not mention any fine-tuning of the hyperparameters.,FineTuning,https://w3id.org/dlprovenance#FineTuning_1,not mentioned
5,24,Is there sufficient information to reproduce the deep learning pipeline?,The paper does not provide enough details about the deep learning pipeline and the code and data used in the study are not publicly available.,Reproducibility,https://w3id.org/dlprovenance#Reproducibility_1,not enough details about the deep learning pipeline
5,25,What measures are taken to explain model predictions?,"To explain model predictions, a statistical feature importance test (SFIT) is performed, where a single feature is randomly shuffled, and the feature importance is measured by the decrease in model performance.",Explanation,https://w3id.org/dlprovenance#Explanation_1,using a statistical feature importance test (SFIT) to explain model predictions
5,25,What measures are taken to explain model predictions?,"To explain model predictions, a statistical feature importance test (SFIT) is performed, where a single feature is randomly shuffled, and the feature importance is measured by the decrease in model performance.",PredictionClassification,https://w3id.org/dlprovenance#PredictionClassification_1,"potential plant species richness for the Korean Peninsula, including North Korea"
5,26,What is the versioning strategy for trained models?,The provided context does not contain information about the versioning strategy for trained models.,VersioningStrategy,https://w3id.org/dlprovenance#VersioningStrategy_1,not specified
5,27,How are different versions of datasets managed?,The text does not provide specific information on how different versions of datasets are managed.,DatasetVersion,https://w3id.org/dlprovenance#DatasetVersion_1,not specified
5,28,How are updates to datasets documented?,The provided text does not specify how updates to datasets are documented.,UpdateFrequency,https://w3id.org/dlprovenance#UpdateFrequency_1,not specified
5,28,How are updates to datasets documented?,The provided text does not specify how updates to datasets are documented.,UpdateFrequency,https://w3id.org/dlprovenance#UpdateFrequency_2,not specified
5,29,What annotations or labels are associated with the data?,"The data is not directly labeled or annotated, but it is used to train and test models for estimating plant species richness. The models are evaluated based on their ability to predict species richness in independent datasets and to identify important variables and time periods.",PredictionClassification,https://w3id.org/dlprovenance#PredictionClassification_1,"potential plant species richness for the Korean Peninsula, including North Korea"
5,31,What predictions or classifications are generated by the deep learning model?,"The deep learning model predicts potential plant species richness for the Korean Peninsula, including North Korea, by combining the suitability predictions of 1574 species using species distribution models and multitemporal remote sensing data. It identifies which variables at which time periods are more important for estimating plant species richness.",PredictionClassification,https://w3id.org/dlprovenance#PredictionClassification_1,"potential plant species richness for the Korean Peninsula, including North Korea"
5,32,How is uncertainty or confidence in model predictions captured?,"The uncertainty or confidence in model predictions is captured by using k-fold cross-validation with k = 5 to fit the models and averaging the 5 results for the final suitability result for each species, and by using probability-based stacking to combine the predictions of each species’ SDM to estimate species richness.",UncertaintyConfidence,https://w3id.org/dlprovenance#UncertaintyConfidence_1,not specified
5,32,How is uncertainty or confidence in model predictions captured?,"The uncertainty or confidence in model predictions is captured by using k-fold cross-validation with k = 5 to fit the models and averaging the 5 results for the final suitability result for each species, and by using probability-based stacking to combine the predictions of each species’ SDM to estimate species richness.",UncertaintyConfidence,https://w3id.org/dlprovenance#UncertaintyConfidence_2,not specified
5,33,Are there post-processing steps applied to the model's output?,The text does not mention any post-processing steps applied to the model's output.,PostProcessing,https://w3id.org/dlprovenance#PostProcessing_1,not mentioned
5,34,"Is the trained model deployed, and if not, what is the reason?","The provided context does not contain information about whether the trained model is deployed or not, and it does not provide any information about the reason why it might not be deployed.",Deployment,https://w3id.org/dlprovenance#Deployment_1,not specified
5,35,What hardware and software are used for model deployment?,The provided context does not specify the hardware and software used for model deployment.,SoftwareFrameworkLibrary,https://w3id.org/dlprovenance#SoftwareFrameworkLibrary_1,Python libraries or frameworks
5,35,What hardware and software are used for model deployment?,The provided context does not specify the hardware and software used for model deployment.,HardwareInfrastructure,https://w3id.org/dlprovenance#HardwareInfrastructure_1,not specified
5,37,What ethical considerations are taken into account during development and deployment?,The ethical considerations taken into account during development and deployment of the system are related to environmental sustainability and transparency.,EthicalImplication,https://w3id.org/dlprovenance#EthicalImplication_1,related to environmental sustainability and transparency
5,38,How is bias in the data addressed?,"The authors address bias in the data by using probability-based stacking, which combines the predictions of each species' species distribution model (SDM) to estimate species richness. They also use MODIS products, Normalized Difference Vegetation Index (NDVI) and Leaf Area Index (LAI), as input variables to estimate potential plant species richness of South Korea.",BiasAddressing,https://w3id.org/dlprovenance#BiasAddressing_1,"addressed by using probability-based stacking and MODIS products, Normalized Difference Vegetation Index (NDVI) and Leaf Area Index (LAI), as input variables to estimate potential plant species richness of South Korea"
5,39,Is there transparency in the decision-making process regarding bias?,"The study used a method called ""stacking species distribution models"" to estimate species richness, which produced unbiased richness. However, the study does not explicitly discuss transparency in the decision-making process regarding bias.",Transparency,https://w3id.org/dlprovenance#Transparency_1,not specified
5,40,Are privacy and security measures implemented in handling sensitive data?,"The text does not explicitly mention if privacy and security measures are implemented in handling sensitive data, but it can be inferred that the study followed the data handling and privacy policies of GBIF, a public database that provides open access to biodiversity data.",PrivacySecurityMeasure,https://w3id.org/dlprovenance#PrivacySecurityMeasure_1,not specified
5,40,Are privacy and security measures implemented in handling sensitive data?,"The text does not explicitly mention if privacy and security measures are implemented in handling sensitive data, but it can be inferred that the study followed the data handling and privacy policies of GBIF, a public database that provides open access to biodiversity data.",SensitiveData,https://w3id.org/dlprovenance#SensitiveData_1,not specified
