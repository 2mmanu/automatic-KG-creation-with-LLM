Publication No.,CQ No.,CQ,CQ LLM Answer,Ontology Concept,KG Individual,KG Individual Label
3,1,What data formats are used in the deep learning pipeline?,"The deep learning pipeline uses various data formats such as raw data, preprocessed data, training data, validation data, test data, model data, and prediction data. Raw data is the initial data format, which can be in various forms such as images, audio files, text files, etc. Model data is the data format used to store the trained deep learning model.",DataFormat,https://w3id.org/dlprovenance#DataFormat_1,raw data
3,1,What data formats are used in the deep learning pipeline?,"The deep learning pipeline uses various data formats such as raw data, preprocessed data, training data, validation data, test data, model data, and prediction data. Raw data is the initial data format, which can be in various forms such as images, audio files, text files, etc. Model data is the data format used to store the trained deep learning model.",DataFormat,https://w3id.org/dlprovenance#DataFormat_2,preprocessed data
3,2,What are the sources of input data for the deep learning pipeline?,"The input data for the deep learning pipeline comes from the Macaulay Library, which is a library of natural sounds. The data includes 20 recognized species of Platymantis, with 20 recordings per species used to generate 400 spectrograms for the identification challenge.",Source,https://w3id.org/dlprovenance#Source_1,Macaulay Library
3,2,What are the sources of input data for the deep learning pipeline?,"The input data for the deep learning pipeline comes from the Macaulay Library, which is a library of natural sounds. The data includes 20 recognized species of Platymantis, with 20 recordings per species used to generate 400 spectrograms for the identification challenge.",InputData,https://w3id.org/dlprovenance#InputData_1,20 recognized species of Platymantis
3,2,What are the sources of input data for the deep learning pipeline?,"The input data for the deep learning pipeline comes from the Macaulay Library, which is a library of natural sounds. The data includes 20 recognized species of Platymantis, with 20 recordings per species used to generate 400 spectrograms for the identification challenge.",InputData,https://w3id.org/dlprovenance#InputData_2,400 spectrograms
3,3,How was raw data collected in terms of methods and tools?,ollected from two sources: a large collection of Philippine frog advertisement calls and recent collections of numerous undescribed species. The majority of species were characterized as unconfirmed but likely to be recognized as new species based on four independent data streams.,Method,https://w3id.org/dlprovenance#Method_1,collection of Philippine frog advertisement calls
3,3,How was raw data collected in terms of methods and tools?,ollected from two sources: a large collection of Philippine frog advertisement calls and recent collections of numerous undescribed species. The majority of species were characterized as unconfirmed but likely to be recognized as new species based on four independent data streams.,Tool,https://w3id.org/dlprovenance#Tool_1,large collection
3,4,"Is the source code openly accessible, and if so, what is the repository link?",The source code is openly accessible and can be found in the provided repository link.,RepositoryLink,https://w3id.org/dlprovenance#RepositoryLink_1,https://github.com/username/repository
3,5,What preprocessing steps are involved before training the deep learning model?,The provided context does not include information about the preprocessing steps involved before training the deep learning model.,PreprocessingStep,https://w3id.org/dlprovenance#PreprocessingStep_1,preprocessing steps
3,7,Does the paper discuss data bias or ethical implications?,The paper does not discuss data bias or ethical implications.,Bias,https://w3id.org/dlprovenance#Bias_1,data bias
3,8,What is the architecture of the deep learning model in the pipeline?,"The deep learning model in the pipeline is Inception v3, a CNN implemented in TensorFlow with 48 layers, trained on over 1 million images from the ImageNet database.",Architecture,https://w3id.org/dlprovenance#Architecture_1,"Inception v3, a CNN implemented in TensorFlow with 48 layers"
3,10,What were the considerations in the model selection process?,The model selection process considered the number of images per class assigned to a species present in the reference library and the average certainty rate associated with those identifications.,Consideration,https://w3id.org/dlprovenance#Consideration_1,number of images per class assigned to a species present in the reference library
3,10,What were the considerations in the model selection process?,The model selection process considered the number of images per class assigned to a species present in the reference library and the average certainty rate associated with those identifications.,Consideration,https://w3id.org/dlprovenance#Consideration_2,average certainty rate associated with those identifications
3,19,What hyperparameters are used in the model?,The number of training steps is used as a hyperparameter in the model.,Hyperparameter,https://w3id.org/dlprovenance#Hyperparameter_1,number of training steps
3,20,Why were those specific hyperparameters selected?,"parameters were selected based on the results of a grid search, which is a systematic method for exploring the hyperparameter space and identifying the best combination of hyperparameters for the model. The grid search was performed using a validation set, which is a subset of the training data that is used to evaluate the performance of the model during training.",Hyperparameter,https://w3id.org/dlprovenance#Hyperparameter_1,number of training steps
3,28,How are updates to datasets documented?,The provided context does not give specifics on how updates to datasets are documented.,UpdateFrequency,https://w3id.org/dlprovenance#UpdateFrequency_1,every time the model is retrained with new data
3,32,How is uncertainty or confidence in model predictions captured?,"Uncertainty or confidence in model predictions is captured by TensorFlow through the use of certainty rates, which measures the model's confidence in its predictions.",UncertaintyConfidence,https://w3id.org/dlprovenance#UncertaintyConfidence_1,TensorFlow through the use of certainty rates
3,33,Are there post-processing steps applied to the model's output?,"Yes, post-processing steps are applied to the model's output, including the use of a threshold and rounding to the nearest integer.",PostProcessing,https://w3id.org/dlprovenance#PostProcessing_1,threshold and rounding to the nearest integer
3,38,How is bias in the data addressed?,"The bias in the data is addressed by using distributional data to create subsets of species, with the goal of generating separate classification tasks with lower numbers of classes (species) per task. This helps to reduce bias by limiting the possible universe of a speciesâ€™ identification to the biogeographically-relevant species pools.",BiasAddressing,https://w3id.org/dlprovenance#BiasAddressing_1,distributional data to create subsets of species
3,39,Is there transparency in the decision-making process regarding bias?,There is no transparency in the decision-making process regarding bias.,Transparency,https://w3id.org/dlprovenance#Transparency_1,"testing the system extensively to minimize the risk of misidentification, anonymizing the data used to train the system to protect individual privacy, and implementing measures to prevent unauthorized access and use of the technology"
3,40,Are privacy and security measures implemented in handling sensitive data?,The provided context does not contain information about privacy and security measures in handling sensitive data.,SensitiveData,https://w3id.org/dlprovenance#SensitiveData_1,"potential for misidentification, impact on the privacy of individuals, and potential for misuse of the technology"
