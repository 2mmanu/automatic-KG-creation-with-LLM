Publication No.,CQ No.,CQ,CQ LLM Answer,Ontology Concept,KG Individual,KG Individual Label
8,1,What data formats are used in the deep learning pipeline?,The data formats used in the deep learning pipeline are images and bounding boxes. The images are the input to the model and the bounding boxes are the annotations used for training and evaluating the model.,DataFormat,https://w3id.org/dlprovenance#DataFormat_1,images
8,1,What data formats are used in the deep learning pipeline?,The data formats used in the deep learning pipeline are images and bounding boxes. The images are the input to the model and the bounding boxes are the annotations used for training and evaluating the model.,DataFormat,https://w3id.org/dlprovenance#DataFormat_2,bounding boxes
8,2,What are the sources of input data for the deep learning pipeline?,The sources of input data for the deep learning pipeline are the herbarium scans.,Source,https://w3id.org/dlprovenance#Source_1,herbarium scans
8,3,How was raw data collected in terms of methods and tools?,"cted by manually localizing and labeling plant organs from herbarium specimens. The process of localizing and labeling encountered difficulties such as distinguishing between buds, flowers, and fruits, separating different plant organs in some taxa, and differentiating between roots and stolons or other stem structures.",Method,https://w3id.org/dlprovenance#Method_1,manually localizing and labeling plant organs from herbarium specimens
8,3,How was raw data collected in terms of methods and tools?,"cted by manually localizing and labeling plant organs from herbarium specimens. The process of localizing and labeling encountered difficulties such as distinguishing between buds, flowers, and fruits, separating different plant organs in some taxa, and differentiating between roots and stolons or other stem structures.",Method,https://w3id.org/dlprovenance#Method_2,manually localizing and labeling plant organs from herbarium specimens using LabelImg
8,3,How was raw data collected in terms of methods and tools?,"cted by manually localizing and labeling plant organs from herbarium specimens. The process of localizing and labeling encountered difficulties such as distinguishing between buds, flowers, and fruits, separating different plant organs in some taxa, and differentiating between roots and stolons or other stem structures.",Method,https://w3id.org/dlprovenance#Method_3,manually localizing and labeling plant organs from herbarium specimens using LabelImg
8,3,How was raw data collected in terms of methods and tools?,"cted by manually localizing and labeling plant organs from herbarium specimens. The process of localizing and labeling encountered difficulties such as distinguishing between buds, flowers, and fruits, separating different plant organs in some taxa, and differentiating between roots and stolons or other stem structures.",Method,https://w3id.org/dlprovenance#Method_4,manually localizing and labeling plant organs from herbarium specimens using LabelImg
8,3,How was raw data collected in terms of methods and tools?,"cted by manually localizing and labeling plant organs from herbarium specimens. The process of localizing and labeling encountered difficulties such as distinguishing between buds, flowers, and fruits, separating different plant organs in some taxa, and differentiating between roots and stolons or other stem structures.",Method,https://w3id.org/dlprovenance#Method_5,manually localizing and labeling plant organs from herbarium specimens using LabelImg
8,3,How was raw data collected in terms of methods and tools?,"cted by manually localizing and labeling plant organs from herbarium specimens. The process of localizing and labeling encountered difficulties such as distinguishing between buds, flowers, and fruits, separating different plant organs in some taxa, and differentiating between roots and stolons or other stem structures.",Method,https://w3id.org/dlprovenance#Method_6,manually localizing and labeling plant organs from herbarium specimens using LabelImg
8,3,How was raw data collected in terms of methods and tools?,"cted by manually localizing and labeling plant organs from herbarium specimens. The process of localizing and labeling encountered difficulties such as distinguishing between buds, flowers, and fruits, separating different plant organs in some taxa, and differentiating between roots and stolons or other stem structures.",Method,https://w3id.org/dlprovenance#Method_7,manually localizing and labeling plant organs from herbarium specimens using LabelImg
8,3,How was raw data collected in terms of methods and tools?,"cted by manually localizing and labeling plant organs from herbarium specimens. The process of localizing and labeling encountered difficulties such as distinguishing between buds, flowers, and fruits, separating different plant organs in some taxa, and differentiating between roots and stolons or other stem structures.",Method,https://w3id.org/dlprovenance#Method_8,manually localizing and labeling plant organs from herbarium specimens using LabelImg
8,3,How was raw data collected in terms of methods and tools?,"cted by manually localizing and labeling plant organs from herbarium specimens. The process of localizing and labeling encountered difficulties such as distinguishing between buds, flowers, and fruits, separating different plant organs in some taxa, and differentiating between roots and stolons or other stem structures.",Method,https://w3id.org/dlprovenance#Method_9,manually localizing and labeling plant organs from herbarium specimens using LabelImg
8,3,How was raw data collected in terms of methods and tools?,"cted by manually localizing and labeling plant organs from herbarium specimens. The process of localizing and labeling encountered difficulties such as distinguishing between buds, flowers, and fruits, separating different plant organs in some taxa, and differentiating between roots and stolons or other stem structures.",Method,https://w3id.org/dlprovenance#Method_10,manually localizing and labeling plant organs from herbarium specimens using LabelImg
8,3,How was raw data collected in terms of methods and tools?,"cted by manually localizing and labeling plant organs from herbarium specimens. The process of localizing and labeling encountered difficulties such as distinguishing between buds, flowers, and fruits, separating different plant organs in some taxa, and differentiating between roots and stolons or other stem structures.",Method,https://w3id.org/dlprovenance#Method_11,manually localizing and labeling plant organs from herbarium specimens using LabelImg
8,3,How was raw data collected in terms of methods and tools?,"cted by manually localizing and labeling plant organs from herbarium specimens. The process of localizing and labeling encountered difficulties such as distinguishing between buds, flowers, and fruits, separating different plant organs in some taxa, and differentiating between roots and stolons or other stem structures.",Method,https://w3id.org/dlprovenance#Method_12,manually localizing and labeling plant organs from herbarium specimens using LabelImg
8,3,How was raw data collected in terms of methods and tools?,"cted by manually localizing and labeling plant organs from herbarium specimens. The process of localizing and labeling encountered difficulties such as distinguishing between buds, flowers, and fruits, separating different plant organs in some taxa, and differentiating between roots and stolons or other stem structures.",Method,https://w3id.org/dlprovenance#Method_13,manually localizing and labeling plant organs from herbarium specimens using LabelImg
8,3,How was raw data collected in terms of methods and tools?,"cted by manually localizing and labeling plant organs from herbarium specimens. The process of localizing and labeling encountered difficulties such as distinguishing between buds, flowers, and fruits, separating different plant organs in some taxa, and differentiating between roots and stolons or other stem structures.",Method,https://w3id.org/dlprovenance#Method_14,manually localizing and labeling plant organs from herbarium specimens using LabelImg
8,3,How was raw data collected in terms of methods and tools?,"cted by manually localizing and labeling plant organs from herbarium specimens. The process of localizing and labeling encountered difficulties such as distinguishing between buds, flowers, and fruits, separating different plant organs in some taxa, and differentiating between roots and stolons or other stem structures.",Method,https://w3id.org/dlprovenance#Method_15,manually localizing and labeling plant organs from herbarium specimens using LabelImg
8,3,How was raw data collected in terms of methods and tools?,"cted by manually localizing and labeling plant organs from herbarium specimens. The process of localizing and labeling encountered difficulties such as distinguishing between buds, flowers, and fruits, separating different plant organs in some taxa, and differentiating between roots and stolons or other stem structures.",Method,https://w3id.org/dlprovenance#Method_16,manually localizing and labeling plant organs from herbarium specimens using LabelImg
8,3,How was raw data collected in terms of methods and tools?,"cted by manually localizing and labeling plant organs from herbarium specimens. The process of localizing and labeling encountered difficulties such as distinguishing between buds, flowers, and fruits, separating different plant organs in some taxa, and differentiating between roots and stolons or other stem structures.",Method,https://w3id.org/dlprovenance#Method_17,manually localizing and labeling plant organs from herbarium specimens using LabelImg
8,3,How was raw data collected in terms of methods and tools?,"cted by manually localizing and labeling plant organs from herbarium specimens. The process of localizing and labeling encountered difficulties such as distinguishing between buds, flowers, and fruits, separating different plant organs in some taxa, and differentiating between roots and stolons or other stem structures.",Method,https://w3id.org/dlprovenance#Method_18,manually localizing and labeling plant organs from herbarium specimens using LabelImg
8,3,How was raw data collected in terms of methods and tools?,"cted by manually localizing and labeling plant organs from herbarium specimens. The process of localizing and labeling encountered difficulties such as distinguishing between buds, flowers, and fruits, separating different plant organs in some taxa, and differentiating between roots and stolons or other stem structures.",Method,https://w3id.org/dlprovenance#Method_19,manually localizing and labeling plant organs from herbarium specimens using LabelImg
8,3,How was raw data collected in terms of methods and tools?,"cted by manually localizing and labeling plant organs from herbarium specimens. The process of localizing and labeling encountered difficulties such as distinguishing between buds, flowers, and fruits, separating different plant organs in some taxa, and differentiating between roots and stolons or other stem structures.",Method,https://w3id.org/dlprovenance#Method_20,manually localizing and labeling plant organs from herbarium specimens using LabelImg
8,3,How was raw data collected in terms of methods and tools?,"cted by manually localizing and labeling plant organs from herbarium specimens. The process of localizing and labeling encountered difficulties such as distinguishing between buds, flowers, and fruits, separating different plant organs in some taxa, and differentiating between roots and stolons or other stem structures.",Method,https://w3id.org/dlprovenance#Method_21,manually localizing and labeling plant organs from herbarium specimens using LabelImg
8,3,How was raw data collected in terms of methods and tools?,"cted by manually localizing and labeling plant organs from herbarium specimens. The process of localizing and labeling encountered difficulties such as distinguishing between buds, flowers, and fruits, separating different plant organs in some taxa, and differentiating between roots and stolons or other stem structures.",Method,https://w3id.org/dlprovenance#Method_22,manually localizing and labeling plant organs from herbarium specimens using LabelImg
8,3,How was raw data collected in terms of methods and tools?,"cted by manually localizing and labeling plant organs from herbarium specimens. The process of localizing and labeling encountered difficulties such as distinguishing between buds, flowers, and fruits, separating different plant organs in some taxa, and differentiating between roots and stolons or other stem structures.",Method,https://w3id.org/dlprovenance#Method_23,manually localizing and labeling plant organs from herbarium specimens using LabelImg
8,3,How was raw data collected in terms of methods and tools?,"cted by manually localizing and labeling plant organs from herbarium specimens. The process of localizing and labeling encountered difficulties such as distinguishing between buds, flowers, and fruits, separating different plant organs in some taxa, and differentiating between roots and stolons or other stem structures.",Method,https://w3id.org/dlprovenance#Method_24,manually localizing and labeling plant organs from herbarium specimens using LabelImg
8,3,How was raw data collected in terms of methods and tools?,"cted by manually localizing and labeling plant organs from herbarium specimens. The process of localizing and labeling encountered difficulties such as distinguishing between buds, flowers, and fruits, separating different plant organs in some taxa, and differentiating between roots and stolons or other stem structures.",Tool,https://w3id.org/dlprovenance#Tool_1,LabelImg
8,4,"Is the source code openly accessible, and if so, what is the repository link?",The source code is openly accessible in the GitHub repository.,RepositoryLink,https://w3id.org/dlprovenance#RepositoryLink_1,GitHub repository
8,5,What preprocessing steps are involved before training the deep learning model?,"The herbarium scans were rescaled to 1200 by 800 pixels, and manually annotated for six different types of organs using LabelImg. The annotated images were then divided into a validated subset of 155 images for testing and 498 images for training.",PreprocessingStep,https://w3id.org/dlprovenance#PreprocessingStep_1,rescaling herbarium scans to 1200 by 800 pixels
8,5,What preprocessing steps are involved before training the deep learning model?,"The herbarium scans were rescaled to 1200 by 800 pixels, and manually annotated for six different types of organs using LabelImg. The annotated images were then divided into a validated subset of 155 images for testing and 498 images for training.",PreprocessingStep,https://w3id.org/dlprovenance#PreprocessingStep_2,manually annotating herbarium scans for six different types of organs using LabelImg
8,5,What preprocessing steps are involved before training the deep learning model?,"The herbarium scans were rescaled to 1200 by 800 pixels, and manually annotated for six different types of organs using LabelImg. The annotated images were then divided into a validated subset of 155 images for testing and 498 images for training.",PreprocessingStep,https://w3id.org/dlprovenance#PreprocessingStep_3,dividing annotated images into a validated subset of 155 images for testing and 498 images for training
8,7,Does the paper discuss data bias or ethical implications?,The paper does not discuss data bias or ethical implications.,Bias,https://w3id.org/dlprovenance#Bias_1,data bias
8,7,Does the paper discuss data bias or ethical implications?,The paper does not discuss data bias or ethical implications.,EthicalImplication,https://w3id.org/dlprovenance#EthicalImplication_1,ethical implications
8,8,What is the architecture of the deep learning model in the pipeline?,"The deep learning model in the pipeline is a Convolutional Neural Network (CNN) architecture called Faster R-CNN, which consists of three modules: a deep CNN image feature extraction network based on the ResNet-50 architecture, a Region Proposal Network (RPN) used for detection of Regions of Interests (RoIs), and Fast R-CNN, which computes a classification score along with class-specific bounding box regression for each of these regions.",Architecture,https://w3id.org/dlprovenance#Architecture_1,Faster R-CNN
8,8,What is the architecture of the deep learning model in the pipeline?,"The deep learning model in the pipeline is a Convolutional Neural Network (CNN) architecture called Faster R-CNN, which consists of three modules: a deep CNN image feature extraction network based on the ResNet-50 architecture, a Region Proposal Network (RPN) used for detection of Regions of Interests (RoIs), and Fast R-CNN, which computes a classification score along with class-specific bounding box regression for each of these regions.",Model,https://w3id.org/dlprovenance#Model_1,organ detection model
8,8,What is the architecture of the deep learning model in the pipeline?,"The deep learning model in the pipeline is a Convolutional Neural Network (CNN) architecture called Faster R-CNN, which consists of three modules: a deep CNN image feature extraction network based on the ResNet-50 architecture, a Region Proposal Network (RPN) used for detection of Regions of Interests (RoIs), and Fast R-CNN, which computes a classification score along with class-specific bounding box regression for each of these regions.",Model,https://w3id.org/dlprovenance#Model_2,organ detection model
8,8,What is the architecture of the deep learning model in the pipeline?,"The deep learning model in the pipeline is a Convolutional Neural Network (CNN) architecture called Faster R-CNN, which consists of three modules: a deep CNN image feature extraction network based on the ResNet-50 architecture, a Region Proposal Network (RPN) used for detection of Regions of Interests (RoIs), and Fast R-CNN, which computes a classification score along with class-specific bounding box regression for each of these regions.",Model,https://w3id.org/dlprovenance#Model_3,organ detection model
8,8,What is the architecture of the deep learning model in the pipeline?,"The deep learning model in the pipeline is a Convolutional Neural Network (CNN) architecture called Faster R-CNN, which consists of three modules: a deep CNN image feature extraction network based on the ResNet-50 architecture, a Region Proposal Network (RPN) used for detection of Regions of Interests (RoIs), and Fast R-CNN, which computes a classification score along with class-specific bounding box regression for each of these regions.",Model,https://w3id.org/dlprovenance#Model_4,organ detection model
8,8,What is the architecture of the deep learning model in the pipeline?,"The deep learning model in the pipeline is a Convolutional Neural Network (CNN) architecture called Faster R-CNN, which consists of three modules: a deep CNN image feature extraction network based on the ResNet-50 architecture, a Region Proposal Network (RPN) used for detection of Regions of Interests (RoIs), and Fast R-CNN, which computes a classification score along with class-specific bounding box regression for each of these regions.",Model,https://w3id.org/dlprovenance#Model_5,organ detection model
8,8,What is the architecture of the deep learning model in the pipeline?,"The deep learning model in the pipeline is a Convolutional Neural Network (CNN) architecture called Faster R-CNN, which consists of three modules: a deep CNN image feature extraction network based on the ResNet-50 architecture, a Region Proposal Network (RPN) used for detection of Regions of Interests (RoIs), and Fast R-CNN, which computes a classification score along with class-specific bounding box regression for each of these regions.",Model,https://w3id.org/dlprovenance#Model_6,organ detection model
8,8,What is the architecture of the deep learning model in the pipeline?,"The deep learning model in the pipeline is a Convolutional Neural Network (CNN) architecture called Faster R-CNN, which consists of three modules: a deep CNN image feature extraction network based on the ResNet-50 architecture, a Region Proposal Network (RPN) used for detection of Regions of Interests (RoIs), and Fast R-CNN, which computes a classification score along with class-specific bounding box regression for each of these regions.",Model,https://w3id.org/dlprovenance#Model_7,organ detection model
8,8,What is the architecture of the deep learning model in the pipeline?,"The deep learning model in the pipeline is a Convolutional Neural Network (CNN) architecture called Faster R-CNN, which consists of three modules: a deep CNN image feature extraction network based on the ResNet-50 architecture, a Region Proposal Network (RPN) used for detection of Regions of Interests (RoIs), and Fast R-CNN, which computes a classification score along with class-specific bounding box regression for each of these regions.",Model,https://w3id.org/dlprovenance#Model_8,organ detection model
8,8,What is the architecture of the deep learning model in the pipeline?,"The deep learning model in the pipeline is a Convolutional Neural Network (CNN) architecture called Faster R-CNN, which consists of three modules: a deep CNN image feature extraction network based on the ResNet-50 architecture, a Region Proposal Network (RPN) used for detection of Regions of Interests (RoIs), and Fast R-CNN, which computes a classification score along with class-specific bounding box regression for each of these regions.",Model,https://w3id.org/dlprovenance#Model_9,organ detection model
8,8,What is the architecture of the deep learning model in the pipeline?,"The deep learning model in the pipeline is a Convolutional Neural Network (CNN) architecture called Faster R-CNN, which consists of three modules: a deep CNN image feature extraction network based on the ResNet-50 architecture, a Region Proposal Network (RPN) used for detection of Regions of Interests (RoIs), and Fast R-CNN, which computes a classification score along with class-specific bounding box regression for each of these regions.",Model,https://w3id.org/dlprovenance#Model_10,organ detection model
8,8,What is the architecture of the deep learning model in the pipeline?,"The deep learning model in the pipeline is a Convolutional Neural Network (CNN) architecture called Faster R-CNN, which consists of three modules: a deep CNN image feature extraction network based on the ResNet-50 architecture, a Region Proposal Network (RPN) used for detection of Regions of Interests (RoIs), and Fast R-CNN, which computes a classification score along with class-specific bounding box regression for each of these regions.",Model,https://w3id.org/dlprovenance#Model_11,organ detection model
8,8,What is the architecture of the deep learning model in the pipeline?,"The deep learning model in the pipeline is a Convolutional Neural Network (CNN) architecture called Faster R-CNN, which consists of three modules: a deep CNN image feature extraction network based on the ResNet-50 architecture, a Region Proposal Network (RPN) used for detection of Regions of Interests (RoIs), and Fast R-CNN, which computes a classification score along with class-specific bounding box regression for each of these regions.",Model,https://w3id.org/dlprovenance#Model_12,organ detection model
8,8,What is the architecture of the deep learning model in the pipeline?,"The deep learning model in the pipeline is a Convolutional Neural Network (CNN) architecture called Faster R-CNN, which consists of three modules: a deep CNN image feature extraction network based on the ResNet-50 architecture, a Region Proposal Network (RPN) used for detection of Regions of Interests (RoIs), and Fast R-CNN, which computes a classification score along with class-specific bounding box regression for each of these regions.",Model,https://w3id.org/dlprovenance#Model_13,organ detection model
8,8,What is the architecture of the deep learning model in the pipeline?,"The deep learning model in the pipeline is a Convolutional Neural Network (CNN) architecture called Faster R-CNN, which consists of three modules: a deep CNN image feature extraction network based on the ResNet-50 architecture, a Region Proposal Network (RPN) used for detection of Regions of Interests (RoIs), and Fast R-CNN, which computes a classification score along with class-specific bounding box regression for each of these regions.",Model,https://w3id.org/dlprovenance#Model_14,organ detection model
8,8,What is the architecture of the deep learning model in the pipeline?,"The deep learning model in the pipeline is a Convolutional Neural Network (CNN) architecture called Faster R-CNN, which consists of three modules: a deep CNN image feature extraction network based on the ResNet-50 architecture, a Region Proposal Network (RPN) used for detection of Regions of Interests (RoIs), and Fast R-CNN, which computes a classification score along with class-specific bounding box regression for each of these regions.",Model,https://w3id.org/dlprovenance#Model_15,organ detection model
8,8,What is the architecture of the deep learning model in the pipeline?,"The deep learning model in the pipeline is a Convolutional Neural Network (CNN) architecture called Faster R-CNN, which consists of three modules: a deep CNN image feature extraction network based on the ResNet-50 architecture, a Region Proposal Network (RPN) used for detection of Regions of Interests (RoIs), and Fast R-CNN, which computes a classification score along with class-specific bounding box regression for each of these regions.",Model,https://w3id.org/dlprovenance#Model_16,organ detection model
8,8,What is the architecture of the deep learning model in the pipeline?,"The deep learning model in the pipeline is a Convolutional Neural Network (CNN) architecture called Faster R-CNN, which consists of three modules: a deep CNN image feature extraction network based on the ResNet-50 architecture, a Region Proposal Network (RPN) used for detection of Regions of Interests (RoIs), and Fast R-CNN, which computes a classification score along with class-specific bounding box regression for each of these regions.",Model,https://w3id.org/dlprovenance#Model_17,organ detection model
8,8,What is the architecture of the deep learning model in the pipeline?,"The deep learning model in the pipeline is a Convolutional Neural Network (CNN) architecture called Faster R-CNN, which consists of three modules: a deep CNN image feature extraction network based on the ResNet-50 architecture, a Region Proposal Network (RPN) used for detection of Regions of Interests (RoIs), and Fast R-CNN, which computes a classification score along with class-specific bounding box regression for each of these regions.",Model,https://w3id.org/dlprovenance#Model_18,organ detection model
8,8,What is the architecture of the deep learning model in the pipeline?,"The deep learning model in the pipeline is a Convolutional Neural Network (CNN) architecture called Faster R-CNN, which consists of three modules: a deep CNN image feature extraction network based on the ResNet-50 architecture, a Region Proposal Network (RPN) used for detection of Regions of Interests (RoIs), and Fast R-CNN, which computes a classification score along with class-specific bounding box regression for each of these regions.",Model,https://w3id.org/dlprovenance#Model_19,organ detection model
8,8,What is the architecture of the deep learning model in the pipeline?,"The deep learning model in the pipeline is a Convolutional Neural Network (CNN) architecture called Faster R-CNN, which consists of three modules: a deep CNN image feature extraction network based on the ResNet-50 architecture, a Region Proposal Network (RPN) used for detection of Regions of Interests (RoIs), and Fast R-CNN, which computes a classification score along with class-specific bounding box regression for each of these regions.",Model,https://w3id.org/dlprovenance#Model_20,organ detection model
8,8,What is the architecture of the deep learning model in the pipeline?,"The deep learning model in the pipeline is a Convolutional Neural Network (CNN) architecture called Faster R-CNN, which consists of three modules: a deep CNN image feature extraction network based on the ResNet-50 architecture, a Region Proposal Network (RPN) used for detection of Regions of Interests (RoIs), and Fast R-CNN, which computes a classification score along with class-specific bounding box regression for each of these regions.",Model,https://w3id.org/dlprovenance#Model_21,organ detection model
8,8,What is the architecture of the deep learning model in the pipeline?,"The deep learning model in the pipeline is a Convolutional Neural Network (CNN) architecture called Faster R-CNN, which consists of three modules: a deep CNN image feature extraction network based on the ResNet-50 architecture, a Region Proposal Network (RPN) used for detection of Regions of Interests (RoIs), and Fast R-CNN, which computes a classification score along with class-specific bounding box regression for each of these regions.",Model,https://w3id.org/dlprovenance#Model_22,organ detection model
8,8,What is the architecture of the deep learning model in the pipeline?,"The deep learning model in the pipeline is a Convolutional Neural Network (CNN) architecture called Faster R-CNN, which consists of three modules: a deep CNN image feature extraction network based on the ResNet-50 architecture, a Region Proposal Network (RPN) used for detection of Regions of Interests (RoIs), and Fast R-CNN, which computes a classification score along with class-specific bounding box regression for each of these regions.",Model,https://w3id.org/dlprovenance#Model_23,organ detection model
8,8,What is the architecture of the deep learning model in the pipeline?,"The deep learning model in the pipeline is a Convolutional Neural Network (CNN) architecture called Faster R-CNN, which consists of three modules: a deep CNN image feature extraction network based on the ResNet-50 architecture, a Region Proposal Network (RPN) used for detection of Regions of Interests (RoIs), and Fast R-CNN, which computes a classification score along with class-specific bounding box regression for each of these regions.",Model,https://w3id.org/dlprovenance#Model_24,organ detection model
8,9,How was the model selected for a specific task?,The model was selected based on its performance on the test subset of the MNHN Paris Herbarium dataset and the model with the highest average precision was chosen for the task of organ detection on the Herbarium Senckenbergianum dataset.,Model,https://w3id.org/dlprovenance#Model_1,organ detection model
8,9,How was the model selected for a specific task?,The model was selected based on its performance on the test subset of the MNHN Paris Herbarium dataset and the model with the highest average precision was chosen for the task of organ detection on the Herbarium Senckenbergianum dataset.,Model,https://w3id.org/dlprovenance#Model_2,organ detection model
8,9,How was the model selected for a specific task?,The model was selected based on its performance on the test subset of the MNHN Paris Herbarium dataset and the model with the highest average precision was chosen for the task of organ detection on the Herbarium Senckenbergianum dataset.,Model,https://w3id.org/dlprovenance#Model_3,organ detection model
8,9,How was the model selected for a specific task?,The model was selected based on its performance on the test subset of the MNHN Paris Herbarium dataset and the model with the highest average precision was chosen for the task of organ detection on the Herbarium Senckenbergianum dataset.,Model,https://w3id.org/dlprovenance#Model_4,organ detection model
8,9,How was the model selected for a specific task?,The model was selected based on its performance on the test subset of the MNHN Paris Herbarium dataset and the model with the highest average precision was chosen for the task of organ detection on the Herbarium Senckenbergianum dataset.,Model,https://w3id.org/dlprovenance#Model_5,organ detection model
8,9,How was the model selected for a specific task?,The model was selected based on its performance on the test subset of the MNHN Paris Herbarium dataset and the model with the highest average precision was chosen for the task of organ detection on the Herbarium Senckenbergianum dataset.,Model,https://w3id.org/dlprovenance#Model_6,organ detection model
8,9,How was the model selected for a specific task?,The model was selected based on its performance on the test subset of the MNHN Paris Herbarium dataset and the model with the highest average precision was chosen for the task of organ detection on the Herbarium Senckenbergianum dataset.,Model,https://w3id.org/dlprovenance#Model_7,organ detection model
8,9,How was the model selected for a specific task?,The model was selected based on its performance on the test subset of the MNHN Paris Herbarium dataset and the model with the highest average precision was chosen for the task of organ detection on the Herbarium Senckenbergianum dataset.,Model,https://w3id.org/dlprovenance#Model_8,organ detection model
8,9,How was the model selected for a specific task?,The model was selected based on its performance on the test subset of the MNHN Paris Herbarium dataset and the model with the highest average precision was chosen for the task of organ detection on the Herbarium Senckenbergianum dataset.,Model,https://w3id.org/dlprovenance#Model_9,organ detection model
8,9,How was the model selected for a specific task?,The model was selected based on its performance on the test subset of the MNHN Paris Herbarium dataset and the model with the highest average precision was chosen for the task of organ detection on the Herbarium Senckenbergianum dataset.,Model,https://w3id.org/dlprovenance#Model_10,organ detection model
8,9,How was the model selected for a specific task?,The model was selected based on its performance on the test subset of the MNHN Paris Herbarium dataset and the model with the highest average precision was chosen for the task of organ detection on the Herbarium Senckenbergianum dataset.,Model,https://w3id.org/dlprovenance#Model_11,organ detection model
8,9,How was the model selected for a specific task?,The model was selected based on its performance on the test subset of the MNHN Paris Herbarium dataset and the model with the highest average precision was chosen for the task of organ detection on the Herbarium Senckenbergianum dataset.,Model,https://w3id.org/dlprovenance#Model_12,organ detection model
8,9,How was the model selected for a specific task?,The model was selected based on its performance on the test subset of the MNHN Paris Herbarium dataset and the model with the highest average precision was chosen for the task of organ detection on the Herbarium Senckenbergianum dataset.,Model,https://w3id.org/dlprovenance#Model_13,organ detection model
8,9,How was the model selected for a specific task?,The model was selected based on its performance on the test subset of the MNHN Paris Herbarium dataset and the model with the highest average precision was chosen for the task of organ detection on the Herbarium Senckenbergianum dataset.,Model,https://w3id.org/dlprovenance#Model_14,organ detection model
8,9,How was the model selected for a specific task?,The model was selected based on its performance on the test subset of the MNHN Paris Herbarium dataset and the model with the highest average precision was chosen for the task of organ detection on the Herbarium Senckenbergianum dataset.,Model,https://w3id.org/dlprovenance#Model_15,organ detection model
8,9,How was the model selected for a specific task?,The model was selected based on its performance on the test subset of the MNHN Paris Herbarium dataset and the model with the highest average precision was chosen for the task of organ detection on the Herbarium Senckenbergianum dataset.,Model,https://w3id.org/dlprovenance#Model_16,organ detection model
8,9,How was the model selected for a specific task?,The model was selected based on its performance on the test subset of the MNHN Paris Herbarium dataset and the model with the highest average precision was chosen for the task of organ detection on the Herbarium Senckenbergianum dataset.,Model,https://w3id.org/dlprovenance#Model_17,organ detection model
8,9,How was the model selected for a specific task?,The model was selected based on its performance on the test subset of the MNHN Paris Herbarium dataset and the model with the highest average precision was chosen for the task of organ detection on the Herbarium Senckenbergianum dataset.,Model,https://w3id.org/dlprovenance#Model_18,organ detection model
8,9,How was the model selected for a specific task?,The model was selected based on its performance on the test subset of the MNHN Paris Herbarium dataset and the model with the highest average precision was chosen for the task of organ detection on the Herbarium Senckenbergianum dataset.,Model,https://w3id.org/dlprovenance#Model_19,organ detection model
8,9,How was the model selected for a specific task?,The model was selected based on its performance on the test subset of the MNHN Paris Herbarium dataset and the model with the highest average precision was chosen for the task of organ detection on the Herbarium Senckenbergianum dataset.,Model,https://w3id.org/dlprovenance#Model_20,organ detection model
8,9,How was the model selected for a specific task?,The model was selected based on its performance on the test subset of the MNHN Paris Herbarium dataset and the model with the highest average precision was chosen for the task of organ detection on the Herbarium Senckenbergianum dataset.,Model,https://w3id.org/dlprovenance#Model_21,organ detection model
8,9,How was the model selected for a specific task?,The model was selected based on its performance on the test subset of the MNHN Paris Herbarium dataset and the model with the highest average precision was chosen for the task of organ detection on the Herbarium Senckenbergianum dataset.,Model,https://w3id.org/dlprovenance#Model_22,organ detection model
8,9,How was the model selected for a specific task?,The model was selected based on its performance on the test subset of the MNHN Paris Herbarium dataset and the model with the highest average precision was chosen for the task of organ detection on the Herbarium Senckenbergianum dataset.,Model,https://w3id.org/dlprovenance#Model_23,organ detection model
8,9,How was the model selected for a specific task?,The model was selected based on its performance on the test subset of the MNHN Paris Herbarium dataset and the model with the highest average precision was chosen for the task of organ detection on the Herbarium Senckenbergianum dataset.,Model,https://w3id.org/dlprovenance#Model_24,organ detection model
8,10,What were the considerations in the model selection process?,"The model selection process was not explicitly described in the text, but the authors used a deep learning model for organ detection and tested it on a subset of annotated scans.",Consideration,https://w3id.org/dlprovenance#Consideration_1,performance on the test subset of the MNHN Paris Herbarium dataset
8,12,Are the models considered state-of-the-art?,The models used in the study are not considered state-of-the-art.,StateOfTheArt,https://w3id.org/dlprovenance#StateOfTheArt_1,not considered state-of-the-art
8,12,Are the models considered state-of-the-art?,The models used in the study are not considered state-of-the-art.,Model,https://w3id.org/dlprovenance#Model_1,organ detection model
8,12,Are the models considered state-of-the-art?,The models used in the study are not considered state-of-the-art.,Model,https://w3id.org/dlprovenance#Model_2,organ detection model
8,12,Are the models considered state-of-the-art?,The models used in the study are not considered state-of-the-art.,Model,https://w3id.org/dlprovenance#Model_3,organ detection model
8,12,Are the models considered state-of-the-art?,The models used in the study are not considered state-of-the-art.,Model,https://w3id.org/dlprovenance#Model_4,organ detection model
8,12,Are the models considered state-of-the-art?,The models used in the study are not considered state-of-the-art.,Model,https://w3id.org/dlprovenance#Model_5,organ detection model
8,12,Are the models considered state-of-the-art?,The models used in the study are not considered state-of-the-art.,Model,https://w3id.org/dlprovenance#Model_6,organ detection model
8,12,Are the models considered state-of-the-art?,The models used in the study are not considered state-of-the-art.,Model,https://w3id.org/dlprovenance#Model_7,organ detection model
8,12,Are the models considered state-of-the-art?,The models used in the study are not considered state-of-the-art.,Model,https://w3id.org/dlprovenance#Model_8,organ detection model
8,12,Are the models considered state-of-the-art?,The models used in the study are not considered state-of-the-art.,Model,https://w3id.org/dlprovenance#Model_9,organ detection model
8,12,Are the models considered state-of-the-art?,The models used in the study are not considered state-of-the-art.,Model,https://w3id.org/dlprovenance#Model_10,organ detection model
8,12,Are the models considered state-of-the-art?,The models used in the study are not considered state-of-the-art.,Model,https://w3id.org/dlprovenance#Model_11,organ detection model
8,12,Are the models considered state-of-the-art?,The models used in the study are not considered state-of-the-art.,Model,https://w3id.org/dlprovenance#Model_12,organ detection model
8,12,Are the models considered state-of-the-art?,The models used in the study are not considered state-of-the-art.,Model,https://w3id.org/dlprovenance#Model_13,organ detection model
8,12,Are the models considered state-of-the-art?,The models used in the study are not considered state-of-the-art.,Model,https://w3id.org/dlprovenance#Model_14,organ detection model
8,12,Are the models considered state-of-the-art?,The models used in the study are not considered state-of-the-art.,Model,https://w3id.org/dlprovenance#Model_15,organ detection model
8,12,Are the models considered state-of-the-art?,The models used in the study are not considered state-of-the-art.,Model,https://w3id.org/dlprovenance#Model_16,organ detection model
8,12,Are the models considered state-of-the-art?,The models used in the study are not considered state-of-the-art.,Model,https://w3id.org/dlprovenance#Model_17,organ detection model
8,12,Are the models considered state-of-the-art?,The models used in the study are not considered state-of-the-art.,Model,https://w3id.org/dlprovenance#Model_18,organ detection model
8,12,Are the models considered state-of-the-art?,The models used in the study are not considered state-of-the-art.,Model,https://w3id.org/dlprovenance#Model_19,organ detection model
8,12,Are the models considered state-of-the-art?,The models used in the study are not considered state-of-the-art.,Model,https://w3id.org/dlprovenance#Model_20,organ detection model
8,12,Are the models considered state-of-the-art?,The models used in the study are not considered state-of-the-art.,Model,https://w3id.org/dlprovenance#Model_21,organ detection model
8,12,Are the models considered state-of-the-art?,The models used in the study are not considered state-of-the-art.,Model,https://w3id.org/dlprovenance#Model_22,organ detection model
8,12,Are the models considered state-of-the-art?,The models used in the study are not considered state-of-the-art.,Model,https://w3id.org/dlprovenance#Model_23,organ detection model
8,12,Are the models considered state-of-the-art?,The models used in the study are not considered state-of-the-art.,Model,https://w3id.org/dlprovenance#Model_24,organ detection model
8,13,How is the model initialized?,The model is initialized using a pre-trained model on the COCO dataset and then fine-tuned on the annotated herbarium dataset.,Model,https://w3id.org/dlprovenance#Model_1,organ detection model
8,13,How is the model initialized?,The model is initialized using a pre-trained model on the COCO dataset and then fine-tuned on the annotated herbarium dataset.,Model,https://w3id.org/dlprovenance#Model_2,organ detection model
8,13,How is the model initialized?,The model is initialized using a pre-trained model on the COCO dataset and then fine-tuned on the annotated herbarium dataset.,Model,https://w3id.org/dlprovenance#Model_3,organ detection model
8,13,How is the model initialized?,The model is initialized using a pre-trained model on the COCO dataset and then fine-tuned on the annotated herbarium dataset.,Model,https://w3id.org/dlprovenance#Model_4,organ detection model
8,13,How is the model initialized?,The model is initialized using a pre-trained model on the COCO dataset and then fine-tuned on the annotated herbarium dataset.,Model,https://w3id.org/dlprovenance#Model_5,organ detection model
8,13,How is the model initialized?,The model is initialized using a pre-trained model on the COCO dataset and then fine-tuned on the annotated herbarium dataset.,Model,https://w3id.org/dlprovenance#Model_6,organ detection model
8,13,How is the model initialized?,The model is initialized using a pre-trained model on the COCO dataset and then fine-tuned on the annotated herbarium dataset.,Model,https://w3id.org/dlprovenance#Model_7,organ detection model
8,13,How is the model initialized?,The model is initialized using a pre-trained model on the COCO dataset and then fine-tuned on the annotated herbarium dataset.,Model,https://w3id.org/dlprovenance#Model_8,organ detection model
8,13,How is the model initialized?,The model is initialized using a pre-trained model on the COCO dataset and then fine-tuned on the annotated herbarium dataset.,Model,https://w3id.org/dlprovenance#Model_9,organ detection model
8,13,How is the model initialized?,The model is initialized using a pre-trained model on the COCO dataset and then fine-tuned on the annotated herbarium dataset.,Model,https://w3id.org/dlprovenance#Model_10,organ detection model
8,13,How is the model initialized?,The model is initialized using a pre-trained model on the COCO dataset and then fine-tuned on the annotated herbarium dataset.,Model,https://w3id.org/dlprovenance#Model_11,organ detection model
8,13,How is the model initialized?,The model is initialized using a pre-trained model on the COCO dataset and then fine-tuned on the annotated herbarium dataset.,Model,https://w3id.org/dlprovenance#Model_12,organ detection model
8,13,How is the model initialized?,The model is initialized using a pre-trained model on the COCO dataset and then fine-tuned on the annotated herbarium dataset.,Model,https://w3id.org/dlprovenance#Model_13,organ detection model
8,13,How is the model initialized?,The model is initialized using a pre-trained model on the COCO dataset and then fine-tuned on the annotated herbarium dataset.,Model,https://w3id.org/dlprovenance#Model_14,organ detection model
8,13,How is the model initialized?,The model is initialized using a pre-trained model on the COCO dataset and then fine-tuned on the annotated herbarium dataset.,Model,https://w3id.org/dlprovenance#Model_15,organ detection model
8,13,How is the model initialized?,The model is initialized using a pre-trained model on the COCO dataset and then fine-tuned on the annotated herbarium dataset.,Model,https://w3id.org/dlprovenance#Model_16,organ detection model
8,13,How is the model initialized?,The model is initialized using a pre-trained model on the COCO dataset and then fine-tuned on the annotated herbarium dataset.,Model,https://w3id.org/dlprovenance#Model_17,organ detection model
8,13,How is the model initialized?,The model is initialized using a pre-trained model on the COCO dataset and then fine-tuned on the annotated herbarium dataset.,Model,https://w3id.org/dlprovenance#Model_18,organ detection model
8,13,How is the model initialized?,The model is initialized using a pre-trained model on the COCO dataset and then fine-tuned on the annotated herbarium dataset.,Model,https://w3id.org/dlprovenance#Model_19,organ detection model
8,13,How is the model initialized?,The model is initialized using a pre-trained model on the COCO dataset and then fine-tuned on the annotated herbarium dataset.,Model,https://w3id.org/dlprovenance#Model_20,organ detection model
8,13,How is the model initialized?,The model is initialized using a pre-trained model on the COCO dataset and then fine-tuned on the annotated herbarium dataset.,Model,https://w3id.org/dlprovenance#Model_21,organ detection model
8,13,How is the model initialized?,The model is initialized using a pre-trained model on the COCO dataset and then fine-tuned on the annotated herbarium dataset.,Model,https://w3id.org/dlprovenance#Model_22,organ detection model
8,13,How is the model initialized?,The model is initialized using a pre-trained model on the COCO dataset and then fine-tuned on the annotated herbarium dataset.,Model,https://w3id.org/dlprovenance#Model_23,organ detection model
8,13,How is the model initialized?,The model is initialized using a pre-trained model on the COCO dataset and then fine-tuned on the annotated herbarium dataset.,Model,https://w3id.org/dlprovenance#Model_24,organ detection model
8,14,Are there specific weight configurations used during initialization?,The provided context does not mention any specific weight configurations used during initialization.,WeightConfiguration,https://w3id.org/dlprovenance#WeightConfiguration_1,pre-trained model on the COCO dataset
8,15,Are there optimization algorithms or learning rate schedules used during training?,The text does not provide information about optimization algorithms or learning rate schedules used during training.,OptimizationAlgorithm,https://w3id.org/dlprovenance#OptimizationAlgorithm_1,Stochastic Gradient Descent
8,15,Are there optimization algorithms or learning rate schedules used during training?,The text does not provide information about optimization algorithms or learning rate schedules used during training.,LearningRateSchedule,https://w3id.org/dlprovenance#LearningRateSchedule_1,fixed number of iterations or epochs
8,17,Which software frameworks or libraries are used to build the model?,The Faster R-CNN model was built using TensorFlow and trained using the TensorFlow Object Detection API.,SoftwareFrameworkLibrary,https://w3id.org/dlprovenance#SoftwareFrameworkLibrary_1,TensorFlow and TensorFlow Object Detection API
8,18,What hardware infrastructures are used for model training?,The model was trained on a single GPU (TITAN Xp) and on three GPUs for the final training.,HardwareInfrastructure,https://w3id.org/dlprovenance#HardwareInfrastructure_1,single GPU (TITAN Xp) and three GPUs
8,19,What hyperparameters are used in the model?,"The hyperparameters used in the model are Stochastic Gradient Descent optimizer with a learning rate of 0.0025 and momentum of 0.9, Anchor generator in the Region Proposal Network with six anchor scales and three aspect ratios, thresholds for non-maximum suppression (NMS) of 0.6 for training and 0.25 for testing, and minibatch size of four images per GPU.",Hyperparameter,https://w3id.org/dlprovenance#Hyperparameter_1,Stochastic Gradient Descent optimizer with a learning rate of 0.0025 and momentum of 0.9
8,19,What hyperparameters are used in the model?,"The hyperparameters used in the model are Stochastic Gradient Descent optimizer with a learning rate of 0.0025 and momentum of 0.9, Anchor generator in the Region Proposal Network with six anchor scales and three aspect ratios, thresholds for non-maximum suppression (NMS) of 0.6 for training and 0.25 for testing, and minibatch size of four images per GPU.",Hyperparameter,https://w3id.org/dlprovenance#Hyperparameter_2,"Stochastic Gradient Descent optimizer with a learning rate of 0.0025 and momentum of 0.9, Anchor generator in the Region Proposal Network with six anchor scales and three aspect ratios, thresholds for non-maximum suppression (NMS) of 0.6 for training and 0.25 for testing, and minibatch size of four images per GPU"
8,19,What hyperparameters are used in the model?,"The hyperparameters used in the model are Stochastic Gradient Descent optimizer with a learning rate of 0.0025 and momentum of 0.9, Anchor generator in the Region Proposal Network with six anchor scales and three aspect ratios, thresholds for non-maximum suppression (NMS) of 0.6 for training and 0.25 for testing, and minibatch size of four images per GPU.",Hyperparameter,https://w3id.org/dlprovenance#Hyperparameter_3,"Stochastic Gradient Descent optimizer with a learning rate of 0.0025 and momentum of 0.9, Anchor generator in the Region Proposal Network with six anchor scales and three aspect ratios, thresholds for non-maximum suppression (NMS) of 0.6 for training and 0.25 for testing, and minibatch size of four images per GPU"
8,19,What hyperparameters are used in the model?,"The hyperparameters used in the model are Stochastic Gradient Descent optimizer with a learning rate of 0.0025 and momentum of 0.9, Anchor generator in the Region Proposal Network with six anchor scales and three aspect ratios, thresholds for non-maximum suppression (NMS) of 0.6 for training and 0.25 for testing, and minibatch size of four images per GPU.",Hyperparameter,https://w3id.org/dlprovenance#Hyperparameter_4,"Stochastic Gradient Descent optimizer with a learning rate of 0.0025 and momentum of 0.9, Anchor generator in the Region Proposal Network with six anchor scales and three aspect ratios, thresholds for non-maximum suppression (NMS) of 0.6 for training and 0.25 for testing, and minibatch size of four images per GPU"
8,19,What hyperparameters are used in the model?,"The hyperparameters used in the model are Stochastic Gradient Descent optimizer with a learning rate of 0.0025 and momentum of 0.9, Anchor generator in the Region Proposal Network with six anchor scales and three aspect ratios, thresholds for non-maximum suppression (NMS) of 0.6 for training and 0.25 for testing, and minibatch size of four images per GPU.",Hyperparameter,https://w3id.org/dlprovenance#Hyperparameter_5,"Stochastic Gradient Descent optimizer with a learning rate of 0.0025 and momentum of 0.9, Anchor generator in the Region Proposal Network with six anchor scales and three aspect ratios, thresholds for non-maximum suppression (NMS) of 0.6 for training and 0.25 for testing, and minibatch size of four images per GPU"
8,19,What hyperparameters are used in the model?,"The hyperparameters used in the model are Stochastic Gradient Descent optimizer with a learning rate of 0.0025 and momentum of 0.9, Anchor generator in the Region Proposal Network with six anchor scales and three aspect ratios, thresholds for non-maximum suppression (NMS) of 0.6 for training and 0.25 for testing, and minibatch size of four images per GPU.",Hyperparameter,https://w3id.org/dlprovenance#Hyperparameter_6,"Stochastic Gradient Descent optimizer with a learning rate of 0.0025 and momentum of 0.9, Anchor generator in the Region Proposal Network with six anchor scales and three aspect ratios, thresholds for non-maximum suppression (NMS) of 0.6 for training and 0.25 for testing, and minibatch size of four images per GPU"
8,19,What hyperparameters are used in the model?,"The hyperparameters used in the model are Stochastic Gradient Descent optimizer with a learning rate of 0.0025 and momentum of 0.9, Anchor generator in the Region Proposal Network with six anchor scales and three aspect ratios, thresholds for non-maximum suppression (NMS) of 0.6 for training and 0.25 for testing, and minibatch size of four images per GPU.",Hyperparameter,https://w3id.org/dlprovenance#Hyperparameter_7,"Stochastic Gradient Descent optimizer with a learning rate of 0.0025 and momentum of 0.9, Anchor generator in the Region Proposal Network with six anchor scales and three aspect ratios, thresholds for non-maximum suppression (NMS) of 0.6 for training and 0.25 for testing, and minibatch size of four images per GPU"
8,19,What hyperparameters are used in the model?,"The hyperparameters used in the model are Stochastic Gradient Descent optimizer with a learning rate of 0.0025 and momentum of 0.9, Anchor generator in the Region Proposal Network with six anchor scales and three aspect ratios, thresholds for non-maximum suppression (NMS) of 0.6 for training and 0.25 for testing, and minibatch size of four images per GPU.",Hyperparameter,https://w3id.org/dlprovenance#Hyperparameter_8,"Stochastic Gradient Descent optimizer with a learning rate of 0.0025 and momentum of 0.9, Anchor generator in the Region Proposal Network with six anchor scales and three aspect ratios, thresholds for non-maximum suppression (NMS) of 0.6 for training and 0.25 for testing, and minibatch size of four images per GPU"
8,19,What hyperparameters are used in the model?,"The hyperparameters used in the model are Stochastic Gradient Descent optimizer with a learning rate of 0.0025 and momentum of 0.9, Anchor generator in the Region Proposal Network with six anchor scales and three aspect ratios, thresholds for non-maximum suppression (NMS) of 0.6 for training and 0.25 for testing, and minibatch size of four images per GPU.",Hyperparameter,https://w3id.org/dlprovenance#Hyperparameter_9,"Stochastic Gradient Descent optimizer with a learning rate of 0.0025 and momentum of 0.9, Anchor generator in the Region Proposal Network with six anchor scales and three aspect ratios, thresholds for non-maximum suppression (NMS) of 0.6 for training and 0.25 for testing, and minibatch size of four images per GPU"
8,19,What hyperparameters are used in the model?,"The hyperparameters used in the model are Stochastic Gradient Descent optimizer with a learning rate of 0.0025 and momentum of 0.9, Anchor generator in the Region Proposal Network with six anchor scales and three aspect ratios, thresholds for non-maximum suppression (NMS) of 0.6 for training and 0.25 for testing, and minibatch size of four images per GPU.",Hyperparameter,https://w3id.org/dlprovenance#Hyperparameter_10,"Stochastic Gradient Descent optimizer with a learning rate of 0.0025 and momentum of 0.9, Anchor generator in the Region Proposal Network with six anchor scales and three aspect ratios, thresholds for non-maximum suppression (NMS) of 0.6 for training and 0.25 for testing, and minibatch size of four images per GPU"
8,19,What hyperparameters are used in the model?,"The hyperparameters used in the model are Stochastic Gradient Descent optimizer with a learning rate of 0.0025 and momentum of 0.9, Anchor generator in the Region Proposal Network with six anchor scales and three aspect ratios, thresholds for non-maximum suppression (NMS) of 0.6 for training and 0.25 for testing, and minibatch size of four images per GPU.",Hyperparameter,https://w3id.org/dlprovenance#Hyperparameter_11,"Stochastic Gradient Descent optimizer with a learning rate of 0.0025 and momentum of 0.9, Anchor generator in the Region Proposal Network with six anchor scales and three aspect ratios, thresholds for non-maximum suppression (NMS) of 0.6 for training and 0.25 for testing, and minibatch size of four images per GPU"
8,19,What hyperparameters are used in the model?,"The hyperparameters used in the model are Stochastic Gradient Descent optimizer with a learning rate of 0.0025 and momentum of 0.9, Anchor generator in the Region Proposal Network with six anchor scales and three aspect ratios, thresholds for non-maximum suppression (NMS) of 0.6 for training and 0.25 for testing, and minibatch size of four images per GPU.",Hyperparameter,https://w3id.org/dlprovenance#Hyperparameter_12,"Stochastic Gradient Descent optimizer with a learning rate of 0.0025 and momentum of 0.9, Anchor generator in the Region Proposal Network with six anchor scales and three aspect ratios, thresholds for non-maximum suppression (NMS) of 0.6 for training and 0.25 for testing, and minibatch size of four images per GPU"
8,19,What hyperparameters are used in the model?,"The hyperparameters used in the model are Stochastic Gradient Descent optimizer with a learning rate of 0.0025 and momentum of 0.9, Anchor generator in the Region Proposal Network with six anchor scales and three aspect ratios, thresholds for non-maximum suppression (NMS) of 0.6 for training and 0.25 for testing, and minibatch size of four images per GPU.",Hyperparameter,https://w3id.org/dlprovenance#Hyperparameter_13,"Stochastic Gradient Descent optimizer with a learning rate of 0.0025 and momentum of 0.9, Anchor generator in the Region Proposal Network with six anchor scales and three aspect ratios, thresholds for non-maximum suppression (NMS) of 0.6 for training and 0.25 for testing, and minibatch size of four images per GPU"
8,19,What hyperparameters are used in the model?,"The hyperparameters used in the model are Stochastic Gradient Descent optimizer with a learning rate of 0.0025 and momentum of 0.9, Anchor generator in the Region Proposal Network with six anchor scales and three aspect ratios, thresholds for non-maximum suppression (NMS) of 0.6 for training and 0.25 for testing, and minibatch size of four images per GPU.",Hyperparameter,https://w3id.org/dlprovenance#Hyperparameter_14,"Stochastic Gradient Descent optimizer with a learning rate of 0.0025 and momentum of 0.9, Anchor generator in the Region Proposal Network with six anchor scales and three aspect ratios, thresholds for non-maximum suppression (NMS) of 0.6 for training and 0.25 for testing, and minibatch size of four images per GPU"
8,19,What hyperparameters are used in the model?,"The hyperparameters used in the model are Stochastic Gradient Descent optimizer with a learning rate of 0.0025 and momentum of 0.9, Anchor generator in the Region Proposal Network with six anchor scales and three aspect ratios, thresholds for non-maximum suppression (NMS) of 0.6 for training and 0.25 for testing, and minibatch size of four images per GPU.",Hyperparameter,https://w3id.org/dlprovenance#Hyperparameter_15,"Stochastic Gradient Descent optimizer with a learning rate of 0.0025 and momentum of 0.9, Anchor generator in the Region Proposal Network with six anchor scales and three aspect ratios, thresholds for non-maximum suppression (NMS) of 0.6 for training and 0.25 for testing, and minibatch size of four images per GPU"
8,19,What hyperparameters are used in the model?,"The hyperparameters used in the model are Stochastic Gradient Descent optimizer with a learning rate of 0.0025 and momentum of 0.9, Anchor generator in the Region Proposal Network with six anchor scales and three aspect ratios, thresholds for non-maximum suppression (NMS) of 0.6 for training and 0.25 for testing, and minibatch size of four images per GPU.",Hyperparameter,https://w3id.org/dlprovenance#Hyperparameter_16,"Stochastic Gradient Descent optimizer with a learning rate of 0.0025 and momentum of 0.9, Anchor generator in the Region Proposal Network with six anchor scales and three aspect ratios, thresholds for non-maximum suppression (NMS) of 0.6 for training and 0.25 for testing, and minibatch size of four images per GPU"
8,19,What hyperparameters are used in the model?,"The hyperparameters used in the model are Stochastic Gradient Descent optimizer with a learning rate of 0.0025 and momentum of 0.9, Anchor generator in the Region Proposal Network with six anchor scales and three aspect ratios, thresholds for non-maximum suppression (NMS) of 0.6 for training and 0.25 for testing, and minibatch size of four images per GPU.",Hyperparameter,https://w3id.org/dlprovenance#Hyperparameter_17,"Stochastic Gradient Descent optimizer with a learning rate of 0.0025 and momentum of 0.9, Anchor generator in the Region Proposal Network with six anchor scales and three aspect ratios, thresholds for non-maximum suppression (NMS) of 0.6 for training and 0.25 for testing, and minibatch size of four images per GPU"
8,19,What hyperparameters are used in the model?,"The hyperparameters used in the model are Stochastic Gradient Descent optimizer with a learning rate of 0.0025 and momentum of 0.9, Anchor generator in the Region Proposal Network with six anchor scales and three aspect ratios, thresholds for non-maximum suppression (NMS) of 0.6 for training and 0.25 for testing, and minibatch size of four images per GPU.",Hyperparameter,https://w3id.org/dlprovenance#Hyperparameter_18,"Stochastic Gradient Descent optimizer with a learning rate of 0.0025 and momentum of 0.9, Anchor generator in the Region Proposal Network with six anchor scales and three aspect ratios, thresholds for non-maximum suppression (NMS) of 0.6 for training and 0.25 for testing, and minibatch size of four images per GPU"
8,19,What hyperparameters are used in the model?,"The hyperparameters used in the model are Stochastic Gradient Descent optimizer with a learning rate of 0.0025 and momentum of 0.9, Anchor generator in the Region Proposal Network with six anchor scales and three aspect ratios, thresholds for non-maximum suppression (NMS) of 0.6 for training and 0.25 for testing, and minibatch size of four images per GPU.",Hyperparameter,https://w3id.org/dlprovenance#Hyperparameter_19,"Stochastic Gradient Descent optimizer with a learning rate of 0.0025 and momentum of 0.9, Anchor generator in the Region Proposal Network with six anchor scales and three aspect ratios, thresholds for non-maximum suppression (NMS) of 0.6 for training and 0.25 for testing, and minibatch size of four images per GPU"
8,19,What hyperparameters are used in the model?,"The hyperparameters used in the model are Stochastic Gradient Descent optimizer with a learning rate of 0.0025 and momentum of 0.9, Anchor generator in the Region Proposal Network with six anchor scales and three aspect ratios, thresholds for non-maximum suppression (NMS) of 0.6 for training and 0.25 for testing, and minibatch size of four images per GPU.",Hyperparameter,https://w3id.org/dlprovenance#Hyperparameter_20,"Stochastic Gradient Descent optimizer with a learning rate of 0.0025 and momentum of 0.9, Anchor generator in the Region Proposal Network with six anchor scales and three aspect ratios, thresholds for non-maximum suppression (NMS) of 0.6 for training and 0.25 for testing, and minibatch size of four images per GPU"
8,19,What hyperparameters are used in the model?,"The hyperparameters used in the model are Stochastic Gradient Descent optimizer with a learning rate of 0.0025 and momentum of 0.9, Anchor generator in the Region Proposal Network with six anchor scales and three aspect ratios, thresholds for non-maximum suppression (NMS) of 0.6 for training and 0.25 for testing, and minibatch size of four images per GPU.",Hyperparameter,https://w3id.org/dlprovenance#Hyperparameter_21,"Stochastic Gradient Descent optimizer with a learning rate of 0.0025 and momentum of 0.9, Anchor generator in the Region Proposal Network with six anchor scales and three aspect ratios, thresholds for non-maximum suppression (NMS) of 0.6 for training and 0.25 for testing, and minibatch size of four images per GPU"
8,19,What hyperparameters are used in the model?,"The hyperparameters used in the model are Stochastic Gradient Descent optimizer with a learning rate of 0.0025 and momentum of 0.9, Anchor generator in the Region Proposal Network with six anchor scales and three aspect ratios, thresholds for non-maximum suppression (NMS) of 0.6 for training and 0.25 for testing, and minibatch size of four images per GPU.",Hyperparameter,https://w3id.org/dlprovenance#Hyperparameter_22,"Stochastic Gradient Descent optimizer with a learning rate of 0.0025 and momentum of 0.9, Anchor generator in the Region Proposal Network with six anchor scales and three aspect ratios, thresholds for non-maximum suppression (NMS) of 0.6 for training and 0.25 for testing, and minibatch size of four images per GPU"
8,19,What hyperparameters are used in the model?,"The hyperparameters used in the model are Stochastic Gradient Descent optimizer with a learning rate of 0.0025 and momentum of 0.9, Anchor generator in the Region Proposal Network with six anchor scales and three aspect ratios, thresholds for non-maximum suppression (NMS) of 0.6 for training and 0.25 for testing, and minibatch size of four images per GPU.",Hyperparameter,https://w3id.org/dlprovenance#Hyperparameter_23,"Stochastic Gradient Descent optimizer with a learning rate of 0.0025 and momentum of 0.9, Anchor generator in the Region Proposal Network with six anchor scales and three aspect ratios, thresholds for non-maximum suppression (NMS) of 0.6 for training and 0.25 for testing, and minibatch size of four images per GPU"
8,19,What hyperparameters are used in the model?,"The hyperparameters used in the model are Stochastic Gradient Descent optimizer with a learning rate of 0.0025 and momentum of 0.9, Anchor generator in the Region Proposal Network with six anchor scales and three aspect ratios, thresholds for non-maximum suppression (NMS) of 0.6 for training and 0.25 for testing, and minibatch size of four images per GPU.",Hyperparameter,https://w3id.org/dlprovenance#Hyperparameter_24,"Stochastic Gradient Descent optimizer with a learning rate of 0.0025 and momentum of 0.9, Anchor generator in the Region Proposal Network with six anchor scales and three aspect ratios, thresholds for non-maximum suppression (NMS) of 0.6 for training and 0.25 for testing, and minibatch size of four images per GPU"
8,19,What hyperparameters are used in the model?,"The hyperparameters used in the model are Stochastic Gradient Descent optimizer with a learning rate of 0.0025 and momentum of 0.9, Anchor generator in the Region Proposal Network with six anchor scales and three aspect ratios, thresholds for non-maximum suppression (NMS) of 0.6 for training and 0.25 for testing, and minibatch size of four images per GPU.",Hyperparameter,https://w3id.org/dlprovenance#Hyperparameter_25,"Stochastic Gradient Descent optimizer with a learning rate of 0.0025 and momentum of 0.9, Anchor generator in the Region Proposal Network with six anchor scales and three aspect ratios, thresholds for non-maximum suppression (NMS) of 0.6 for training and 0.25 for testing, and minibatch size of four images per GPU"
8,19,What hyperparameters are used in the model?,"The hyperparameters used in the model are Stochastic Gradient Descent optimizer with a learning rate of 0.0025 and momentum of 0.9, Anchor generator in the Region Proposal Network with six anchor scales and three aspect ratios, thresholds for non-maximum suppression (NMS) of 0.6 for training and 0.25 for testing, and minibatch size of four images per GPU.",Hyperparameter,https://w3id.org/dlprovenance#Hyperparameter_26,"Stochastic Gradient Descent optimizer with a learning rate of 0.0025 and momentum of 0.9, Anchor generator in the Region Proposal Network with six anchor scales and three aspect ratios, thresholds for non-maximum suppression (NMS) of 0.6 for training and 0.25 for testing, and minibatch size of four images per GPU"
8,20,Why were those specific hyperparameters selected?,parameters were selected based on the results of a grid search. The best hyperparameters were chosen based on the highest average precision score achieved during the grid search.,Hyperparameter,https://w3id.org/dlprovenance#Hyperparameter_1,Stochastic Gradient Descent optimizer with a learning rate of 0.0025 and momentum of 0.9
8,20,Why were those specific hyperparameters selected?,parameters were selected based on the results of a grid search. The best hyperparameters were chosen based on the highest average precision score achieved during the grid search.,Hyperparameter,https://w3id.org/dlprovenance#Hyperparameter_2,"Stochastic Gradient Descent optimizer with a learning rate of 0.0025 and momentum of 0.9, Anchor generator in the Region Proposal Network with six anchor scales and three aspect ratios, thresholds for non-maximum suppression (NMS) of 0.6 for training and 0.25 for testing, and minibatch size of four images per GPU"
8,20,Why were those specific hyperparameters selected?,parameters were selected based on the results of a grid search. The best hyperparameters were chosen based on the highest average precision score achieved during the grid search.,Hyperparameter,https://w3id.org/dlprovenance#Hyperparameter_3,"Stochastic Gradient Descent optimizer with a learning rate of 0.0025 and momentum of 0.9, Anchor generator in the Region Proposal Network with six anchor scales and three aspect ratios, thresholds for non-maximum suppression (NMS) of 0.6 for training and 0.25 for testing, and minibatch size of four images per GPU"
8,20,Why were those specific hyperparameters selected?,parameters were selected based on the results of a grid search. The best hyperparameters were chosen based on the highest average precision score achieved during the grid search.,Hyperparameter,https://w3id.org/dlprovenance#Hyperparameter_4,"Stochastic Gradient Descent optimizer with a learning rate of 0.0025 and momentum of 0.9, Anchor generator in the Region Proposal Network with six anchor scales and three aspect ratios, thresholds for non-maximum suppression (NMS) of 0.6 for training and 0.25 for testing, and minibatch size of four images per GPU"
8,20,Why were those specific hyperparameters selected?,parameters were selected based on the results of a grid search. The best hyperparameters were chosen based on the highest average precision score achieved during the grid search.,Hyperparameter,https://w3id.org/dlprovenance#Hyperparameter_5,"Stochastic Gradient Descent optimizer with a learning rate of 0.0025 and momentum of 0.9, Anchor generator in the Region Proposal Network with six anchor scales and three aspect ratios, thresholds for non-maximum suppression (NMS) of 0.6 for training and 0.25 for testing, and minibatch size of four images per GPU"
8,20,Why were those specific hyperparameters selected?,parameters were selected based on the results of a grid search. The best hyperparameters were chosen based on the highest average precision score achieved during the grid search.,Hyperparameter,https://w3id.org/dlprovenance#Hyperparameter_6,"Stochastic Gradient Descent optimizer with a learning rate of 0.0025 and momentum of 0.9, Anchor generator in the Region Proposal Network with six anchor scales and three aspect ratios, thresholds for non-maximum suppression (NMS) of 0.6 for training and 0.25 for testing, and minibatch size of four images per GPU"
8,20,Why were those specific hyperparameters selected?,parameters were selected based on the results of a grid search. The best hyperparameters were chosen based on the highest average precision score achieved during the grid search.,Hyperparameter,https://w3id.org/dlprovenance#Hyperparameter_7,"Stochastic Gradient Descent optimizer with a learning rate of 0.0025 and momentum of 0.9, Anchor generator in the Region Proposal Network with six anchor scales and three aspect ratios, thresholds for non-maximum suppression (NMS) of 0.6 for training and 0.25 for testing, and minibatch size of four images per GPU"
8,20,Why were those specific hyperparameters selected?,parameters were selected based on the results of a grid search. The best hyperparameters were chosen based on the highest average precision score achieved during the grid search.,Hyperparameter,https://w3id.org/dlprovenance#Hyperparameter_8,"Stochastic Gradient Descent optimizer with a learning rate of 0.0025 and momentum of 0.9, Anchor generator in the Region Proposal Network with six anchor scales and three aspect ratios, thresholds for non-maximum suppression (NMS) of 0.6 for training and 0.25 for testing, and minibatch size of four images per GPU"
8,20,Why were those specific hyperparameters selected?,parameters were selected based on the results of a grid search. The best hyperparameters were chosen based on the highest average precision score achieved during the grid search.,Hyperparameter,https://w3id.org/dlprovenance#Hyperparameter_9,"Stochastic Gradient Descent optimizer with a learning rate of 0.0025 and momentum of 0.9, Anchor generator in the Region Proposal Network with six anchor scales and three aspect ratios, thresholds for non-maximum suppression (NMS) of 0.6 for training and 0.25 for testing, and minibatch size of four images per GPU"
8,20,Why were those specific hyperparameters selected?,parameters were selected based on the results of a grid search. The best hyperparameters were chosen based on the highest average precision score achieved during the grid search.,Hyperparameter,https://w3id.org/dlprovenance#Hyperparameter_10,"Stochastic Gradient Descent optimizer with a learning rate of 0.0025 and momentum of 0.9, Anchor generator in the Region Proposal Network with six anchor scales and three aspect ratios, thresholds for non-maximum suppression (NMS) of 0.6 for training and 0.25 for testing, and minibatch size of four images per GPU"
8,20,Why were those specific hyperparameters selected?,parameters were selected based on the results of a grid search. The best hyperparameters were chosen based on the highest average precision score achieved during the grid search.,Hyperparameter,https://w3id.org/dlprovenance#Hyperparameter_11,"Stochastic Gradient Descent optimizer with a learning rate of 0.0025 and momentum of 0.9, Anchor generator in the Region Proposal Network with six anchor scales and three aspect ratios, thresholds for non-maximum suppression (NMS) of 0.6 for training and 0.25 for testing, and minibatch size of four images per GPU"
8,20,Why were those specific hyperparameters selected?,parameters were selected based on the results of a grid search. The best hyperparameters were chosen based on the highest average precision score achieved during the grid search.,Hyperparameter,https://w3id.org/dlprovenance#Hyperparameter_12,"Stochastic Gradient Descent optimizer with a learning rate of 0.0025 and momentum of 0.9, Anchor generator in the Region Proposal Network with six anchor scales and three aspect ratios, thresholds for non-maximum suppression (NMS) of 0.6 for training and 0.25 for testing, and minibatch size of four images per GPU"
8,20,Why were those specific hyperparameters selected?,parameters were selected based on the results of a grid search. The best hyperparameters were chosen based on the highest average precision score achieved during the grid search.,Hyperparameter,https://w3id.org/dlprovenance#Hyperparameter_13,"Stochastic Gradient Descent optimizer with a learning rate of 0.0025 and momentum of 0.9, Anchor generator in the Region Proposal Network with six anchor scales and three aspect ratios, thresholds for non-maximum suppression (NMS) of 0.6 for training and 0.25 for testing, and minibatch size of four images per GPU"
8,20,Why were those specific hyperparameters selected?,parameters were selected based on the results of a grid search. The best hyperparameters were chosen based on the highest average precision score achieved during the grid search.,Hyperparameter,https://w3id.org/dlprovenance#Hyperparameter_14,"Stochastic Gradient Descent optimizer with a learning rate of 0.0025 and momentum of 0.9, Anchor generator in the Region Proposal Network with six anchor scales and three aspect ratios, thresholds for non-maximum suppression (NMS) of 0.6 for training and 0.25 for testing, and minibatch size of four images per GPU"
8,20,Why were those specific hyperparameters selected?,parameters were selected based on the results of a grid search. The best hyperparameters were chosen based on the highest average precision score achieved during the grid search.,Hyperparameter,https://w3id.org/dlprovenance#Hyperparameter_15,"Stochastic Gradient Descent optimizer with a learning rate of 0.0025 and momentum of 0.9, Anchor generator in the Region Proposal Network with six anchor scales and three aspect ratios, thresholds for non-maximum suppression (NMS) of 0.6 for training and 0.25 for testing, and minibatch size of four images per GPU"
8,20,Why were those specific hyperparameters selected?,parameters were selected based on the results of a grid search. The best hyperparameters were chosen based on the highest average precision score achieved during the grid search.,Hyperparameter,https://w3id.org/dlprovenance#Hyperparameter_16,"Stochastic Gradient Descent optimizer with a learning rate of 0.0025 and momentum of 0.9, Anchor generator in the Region Proposal Network with six anchor scales and three aspect ratios, thresholds for non-maximum suppression (NMS) of 0.6 for training and 0.25 for testing, and minibatch size of four images per GPU"
8,20,Why were those specific hyperparameters selected?,parameters were selected based on the results of a grid search. The best hyperparameters were chosen based on the highest average precision score achieved during the grid search.,Hyperparameter,https://w3id.org/dlprovenance#Hyperparameter_17,"Stochastic Gradient Descent optimizer with a learning rate of 0.0025 and momentum of 0.9, Anchor generator in the Region Proposal Network with six anchor scales and three aspect ratios, thresholds for non-maximum suppression (NMS) of 0.6 for training and 0.25 for testing, and minibatch size of four images per GPU"
8,20,Why were those specific hyperparameters selected?,parameters were selected based on the results of a grid search. The best hyperparameters were chosen based on the highest average precision score achieved during the grid search.,Hyperparameter,https://w3id.org/dlprovenance#Hyperparameter_18,"Stochastic Gradient Descent optimizer with a learning rate of 0.0025 and momentum of 0.9, Anchor generator in the Region Proposal Network with six anchor scales and three aspect ratios, thresholds for non-maximum suppression (NMS) of 0.6 for training and 0.25 for testing, and minibatch size of four images per GPU"
8,20,Why were those specific hyperparameters selected?,parameters were selected based on the results of a grid search. The best hyperparameters were chosen based on the highest average precision score achieved during the grid search.,Hyperparameter,https://w3id.org/dlprovenance#Hyperparameter_19,"Stochastic Gradient Descent optimizer with a learning rate of 0.0025 and momentum of 0.9, Anchor generator in the Region Proposal Network with six anchor scales and three aspect ratios, thresholds for non-maximum suppression (NMS) of 0.6 for training and 0.25 for testing, and minibatch size of four images per GPU"
8,20,Why were those specific hyperparameters selected?,parameters were selected based on the results of a grid search. The best hyperparameters were chosen based on the highest average precision score achieved during the grid search.,Hyperparameter,https://w3id.org/dlprovenance#Hyperparameter_20,"Stochastic Gradient Descent optimizer with a learning rate of 0.0025 and momentum of 0.9, Anchor generator in the Region Proposal Network with six anchor scales and three aspect ratios, thresholds for non-maximum suppression (NMS) of 0.6 for training and 0.25 for testing, and minibatch size of four images per GPU"
8,20,Why were those specific hyperparameters selected?,parameters were selected based on the results of a grid search. The best hyperparameters were chosen based on the highest average precision score achieved during the grid search.,Hyperparameter,https://w3id.org/dlprovenance#Hyperparameter_21,"Stochastic Gradient Descent optimizer with a learning rate of 0.0025 and momentum of 0.9, Anchor generator in the Region Proposal Network with six anchor scales and three aspect ratios, thresholds for non-maximum suppression (NMS) of 0.6 for training and 0.25 for testing, and minibatch size of four images per GPU"
8,20,Why were those specific hyperparameters selected?,parameters were selected based on the results of a grid search. The best hyperparameters were chosen based on the highest average precision score achieved during the grid search.,Hyperparameter,https://w3id.org/dlprovenance#Hyperparameter_22,"Stochastic Gradient Descent optimizer with a learning rate of 0.0025 and momentum of 0.9, Anchor generator in the Region Proposal Network with six anchor scales and three aspect ratios, thresholds for non-maximum suppression (NMS) of 0.6 for training and 0.25 for testing, and minibatch size of four images per GPU"
8,20,Why were those specific hyperparameters selected?,parameters were selected based on the results of a grid search. The best hyperparameters were chosen based on the highest average precision score achieved during the grid search.,Hyperparameter,https://w3id.org/dlprovenance#Hyperparameter_23,"Stochastic Gradient Descent optimizer with a learning rate of 0.0025 and momentum of 0.9, Anchor generator in the Region Proposal Network with six anchor scales and three aspect ratios, thresholds for non-maximum suppression (NMS) of 0.6 for training and 0.25 for testing, and minibatch size of four images per GPU"
8,20,Why were those specific hyperparameters selected?,parameters were selected based on the results of a grid search. The best hyperparameters were chosen based on the highest average precision score achieved during the grid search.,Hyperparameter,https://w3id.org/dlprovenance#Hyperparameter_24,"Stochastic Gradient Descent optimizer with a learning rate of 0.0025 and momentum of 0.9, Anchor generator in the Region Proposal Network with six anchor scales and three aspect ratios, thresholds for non-maximum suppression (NMS) of 0.6 for training and 0.25 for testing, and minibatch size of four images per GPU"
8,20,Why were those specific hyperparameters selected?,parameters were selected based on the results of a grid search. The best hyperparameters were chosen based on the highest average precision score achieved during the grid search.,Hyperparameter,https://w3id.org/dlprovenance#Hyperparameter_25,"Stochastic Gradient Descent optimizer with a learning rate of 0.0025 and momentum of 0.9, Anchor generator in the Region Proposal Network with six anchor scales and three aspect ratios, thresholds for non-maximum suppression (NMS) of 0.6 for training and 0.25 for testing, and minibatch size of four images per GPU"
8,20,Why were those specific hyperparameters selected?,parameters were selected based on the results of a grid search. The best hyperparameters were chosen based on the highest average precision score achieved during the grid search.,Hyperparameter,https://w3id.org/dlprovenance#Hyperparameter_26,"Stochastic Gradient Descent optimizer with a learning rate of 0.0025 and momentum of 0.9, Anchor generator in the Region Proposal Network with six anchor scales and three aspect ratios, thresholds for non-maximum suppression (NMS) of 0.6 for training and 0.25 for testing, and minibatch size of four images per GPU"
8,21,Are the provided hyperparameters fine-tuned?,The provided hyperparameters are not fine-tuned.,FineTuning,https://w3id.org/dlprovenance#FineTuning_1,not fine-tuned
8,24,Is there sufficient information to reproduce the deep learning pipeline?,"The paper does not provide enough details about the training and testing of the model, such as the number of epochs, the learning rate, the batch size, the optimiser used, the loss function used, the training and testing dataset, the number of images used for training and testing, the number of bounding boxes used for training and testing, the type of pre-processing used on the images, the type of hardware used for training and testing, the type of software used for training and testing, the type of data augmentation used, the type of transfer learning used, the type of fine-tuning used, the type of hyperparameter tuning used, the type of evaluation metrics used, the type of post-processing used, the type of pre-trained model used, the type of backbone used, the type of feature extractor used, the type of region proposal network used, the type of region of interest pooling used, the type of classifier used, the type of non-maximum suppression used, the type of bounding box regressor used, the type of anchor boxes used, the type of image normalisation used, the type of image resizing used, the type of image cropping used, the type of image padding used, the type of image rotation used, the type of image flipping used, the type of image brightness adjustment used, the type of image contrast adjustment used, the type of image hue adjustment used, the type of image saturation adjustment used, the type of image sharpness adjustment used, the type of image blurring used, the type of image noise addition used, the type of image erosion used, the type of image dilation used, the type of image thresholding used, the type of image morphological operations used, the type of image histogram equalisation used, the type of image gamma correction used, the type of image grayscale conversion used, the type of image channel shuffling used, the type of image random cropping used, the type of image random flipping used, the type of image random rotation used, the type of image random brightness adjustment used, the type of image random contrast adjustment used, the type of image random hue adjustment used, the type of image random saturation adjustment used, the type of image random sharpness adjustment used, the type o",Reproducibility,https://w3id.org/dlprovenance#Reproducibility_1,"not enough details about the training and testing of the model, such as the number of epochs, the learning rate, the batch size, the optimiser used, the loss function used, the training and testing dataset, the number of images used for training and testing, the number of bounding boxes used for training and testing, the type of pre-processing used on the images, the type of hardware used for training and testing, the type of software used for training and testing, the type of data augmentation used, the type of transfer learning used, the type of fine-tuning used, the type of hyperparameter tuning used, the type of evaluation metrics used, the type of post-processing used, the type of pre-trained model used, the type of backbone used, the type of feature extractor used, the type of region proposal network used, the type of region of interest pooling used, the type of classifier used, the type of non-maximum suppression used, the type of bounding box regressor used, the type of anchor boxes used, the type of image normalisation used, the type of image resizing used, the type of image cropping used, the type of image padding used, the type of image rotation used, the type of image flipping used, the type of image brightness adjustment used, the type of image contrast adjustment used, the type of image hue adjustment used, the type of image saturation adjustment used, the type of image sharpness adjustment used, the type of image blurring used, the type of image noise addition used, the type of image erosion used, the type of image dilation used, the type of image thresholding used, the type of image morphological operations used, the type of image histogram equalisation used, the type of image gamma correction used, the type of image grayscale conversion used, the type of image channel shuffling used, the type of image random cropping used, the type of image random flipping used, the type of image random rotation used, the type of image random brightness adjustment used, the type of image random contrast adjustment used, the type of image random hue adjustment used, the type of image random saturation adjustment used, the type of image random sharpness adjustment used, the type"
8,25,What measures are taken to explain model predictions?,"The paper does not explicitly mention any measures taken to explain model predictions, but the model was manually verified and corrected to evaluate the predictions on the Herbarium Senckenbergianum dataset, and the annotations for the Herbarium Senckenbergianum dataset were done based on the predictions of organs on scans.",Explanation,https://w3id.org/dlprovenance#Explanation_1,"manual verification and correction of a subset of the predictions, and annotation of an un-annotated dataset based on the models predictions"
8,25,What measures are taken to explain model predictions?,"The paper does not explicitly mention any measures taken to explain model predictions, but the model was manually verified and corrected to evaluate the predictions on the Herbarium Senckenbergianum dataset, and the annotations for the Herbarium Senckenbergianum dataset were done based on the predictions of organs on scans.",PredictionClassification,https://w3id.org/dlprovenance#PredictionClassification_1,organ detection
8,26,What is the versioning strategy for trained models?,The versioning strategy for trained models is not specified in the provided text.,VersioningStrategy,https://w3id.org/dlprovenance#VersioningStrategy_1,not specified
8,27,How are different versions of datasets managed?,"The different versions of datasets are managed by using a version control system, which allows for tracking changes made to the datasets, comparing different versions, and reverting to previous versions if necessary. It also enables collaboration among multiple users.",DatasetVersion,https://w3id.org/dlprovenance#DatasetVersion_1,annotated scans
8,28,How are updates to datasets documented?,"The context does not directly mention how updates to datasets are documented, but it can be inferred that updates are likely documented through the version control system on GitHub.",UpdateFrequency,https://w3id.org/dlprovenance#UpdateFrequency_1,not specified
8,28,How are updates to datasets documented?,"The context does not directly mention how updates to datasets are documented, but it can be inferred that updates are likely documented through the version control system on GitHub.",UpdateFrequency,https://w3id.org/dlprovenance#UpdateFrequency_2,not specified
8,28,How are updates to datasets documented?,"The context does not directly mention how updates to datasets are documented, but it can be inferred that updates are likely documented through the version control system on GitHub.",UpdateFrequency,https://w3id.org/dlprovenance#UpdateFrequency_3,not specified
8,28,How are updates to datasets documented?,"The context does not directly mention how updates to datasets are documented, but it can be inferred that updates are likely documented through the version control system on GitHub.",UpdateFrequency,https://w3id.org/dlprovenance#UpdateFrequency_4,not specified
8,28,How are updates to datasets documented?,"The context does not directly mention how updates to datasets are documented, but it can be inferred that updates are likely documented through the version control system on GitHub.",UpdateFrequency,https://w3id.org/dlprovenance#UpdateFrequency_5,not specified
8,28,How are updates to datasets documented?,"The context does not directly mention how updates to datasets are documented, but it can be inferred that updates are likely documented through the version control system on GitHub.",UpdateFrequency,https://w3id.org/dlprovenance#UpdateFrequency_6,not specified
8,28,How are updates to datasets documented?,"The context does not directly mention how updates to datasets are documented, but it can be inferred that updates are likely documented through the version control system on GitHub.",UpdateFrequency,https://w3id.org/dlprovenance#UpdateFrequency_7,not specified
8,28,How are updates to datasets documented?,"The context does not directly mention how updates to datasets are documented, but it can be inferred that updates are likely documented through the version control system on GitHub.",UpdateFrequency,https://w3id.org/dlprovenance#UpdateFrequency_8,not specified
8,28,How are updates to datasets documented?,"The context does not directly mention how updates to datasets are documented, but it can be inferred that updates are likely documented through the version control system on GitHub.",UpdateFrequency,https://w3id.org/dlprovenance#UpdateFrequency_9,not specified
8,28,How are updates to datasets documented?,"The context does not directly mention how updates to datasets are documented, but it can be inferred that updates are likely documented through the version control system on GitHub.",UpdateFrequency,https://w3id.org/dlprovenance#UpdateFrequency_10,not specified
8,28,How are updates to datasets documented?,"The context does not directly mention how updates to datasets are documented, but it can be inferred that updates are likely documented through the version control system on GitHub.",UpdateFrequency,https://w3id.org/dlprovenance#UpdateFrequency_11,not specified
8,28,How are updates to datasets documented?,"The context does not directly mention how updates to datasets are documented, but it can be inferred that updates are likely documented through the version control system on GitHub.",UpdateFrequency,https://w3id.org/dlprovenance#UpdateFrequency_12,not specified
8,28,How are updates to datasets documented?,"The context does not directly mention how updates to datasets are documented, but it can be inferred that updates are likely documented through the version control system on GitHub.",UpdateFrequency,https://w3id.org/dlprovenance#UpdateFrequency_13,not specified
8,28,How are updates to datasets documented?,"The context does not directly mention how updates to datasets are documented, but it can be inferred that updates are likely documented through the version control system on GitHub.",UpdateFrequency,https://w3id.org/dlprovenance#UpdateFrequency_14,not specified
8,28,How are updates to datasets documented?,"The context does not directly mention how updates to datasets are documented, but it can be inferred that updates are likely documented through the version control system on GitHub.",UpdateFrequency,https://w3id.org/dlprovenance#UpdateFrequency_15,not specified
8,28,How are updates to datasets documented?,"The context does not directly mention how updates to datasets are documented, but it can be inferred that updates are likely documented through the version control system on GitHub.",UpdateFrequency,https://w3id.org/dlprovenance#UpdateFrequency_16,not specified
8,28,How are updates to datasets documented?,"The context does not directly mention how updates to datasets are documented, but it can be inferred that updates are likely documented through the version control system on GitHub.",UpdateFrequency,https://w3id.org/dlprovenance#UpdateFrequency_17,not specified
8,28,How are updates to datasets documented?,"The context does not directly mention how updates to datasets are documented, but it can be inferred that updates are likely documented through the version control system on GitHub.",UpdateFrequency,https://w3id.org/dlprovenance#UpdateFrequency_18,not specified
8,28,How are updates to datasets documented?,"The context does not directly mention how updates to datasets are documented, but it can be inferred that updates are likely documented through the version control system on GitHub.",UpdateFrequency,https://w3id.org/dlprovenance#UpdateFrequency_19,not specified
8,28,How are updates to datasets documented?,"The context does not directly mention how updates to datasets are documented, but it can be inferred that updates are likely documented through the version control system on GitHub.",UpdateFrequency,https://w3id.org/dlprovenance#UpdateFrequency_20,not specified
8,28,How are updates to datasets documented?,"The context does not directly mention how updates to datasets are documented, but it can be inferred that updates are likely documented through the version control system on GitHub.",UpdateFrequency,https://w3id.org/dlprovenance#UpdateFrequency_21,not specified
8,28,How are updates to datasets documented?,"The context does not directly mention how updates to datasets are documented, but it can be inferred that updates are likely documented through the version control system on GitHub.",UpdateFrequency,https://w3id.org/dlprovenance#UpdateFrequency_22,not specified
8,28,How are updates to datasets documented?,"The context does not directly mention how updates to datasets are documented, but it can be inferred that updates are likely documented through the version control system on GitHub.",UpdateFrequency,https://w3id.org/dlprovenance#UpdateFrequency_23,not specified
8,28,How are updates to datasets documented?,"The context does not directly mention how updates to datasets are documented, but it can be inferred that updates are likely documented through the version control system on GitHub.",UpdateFrequency,https://w3id.org/dlprovenance#UpdateFrequency_24,not specified
8,28,How are updates to datasets documented?,"The context does not directly mention how updates to datasets are documented, but it can be inferred that updates are likely documented through the version control system on GitHub.",UpdateFrequency,https://w3id.org/dlprovenance#UpdateFrequency_25,not specified
8,29,What annotations or labels are associated with the data?,"ted with bounding boxes for six types of plant organs: leaves, flowers, fruits, seeds, stems, and roots. These annotations were made manually on hundreds of herbarium scans, with thousands of bounding boxes used for training and evaluating the plant organ detection model.",PredictionClassification,https://w3id.org/dlprovenance#PredictionClassification_1,organ detection
8,31,What predictions or classifications are generated by the deep learning model?,The deep learning model generates bounding boxes around the detected plant organs and classifies them into one of the six categories.,PredictionClassification,https://w3id.org/dlprovenance#PredictionClassification_1,organ detection
8,32,How is uncertainty or confidence in model predictions captured?,"The uncertainty or confidence in model predictions is captured through the confidence score (probability) of the predictions, and the COCO method calculates average precision (with values from 0 to 100) for the entire predictions and each class of organs at different levels of Intersection over Union (IoU).",UncertaintyConfidence,https://w3id.org/dlprovenance#UncertaintyConfidence_1,"COCO evaluation metric, which calculates average precision for the entire predictions and each class of organs at different levels of Intersection over Union (IoU)"
8,32,How is uncertainty or confidence in model predictions captured?,"The uncertainty or confidence in model predictions is captured through the confidence score (probability) of the predictions, and the COCO method calculates average precision (with values from 0 to 100) for the entire predictions and each class of organs at different levels of Intersection over Union (IoU).",UncertaintyConfidence,https://w3id.org/dlprovenance#UncertaintyConfidence_2,confidence score (probability) of the predictions
8,32,How is uncertainty or confidence in model predictions captured?,"The uncertainty or confidence in model predictions is captured through the confidence score (probability) of the predictions, and the COCO method calculates average precision (with values from 0 to 100) for the entire predictions and each class of organs at different levels of Intersection over Union (IoU).",UncertaintyConfidence,https://w3id.org/dlprovenance#UncertaintyConfidence_3,confidence score (probability) of the predictions
8,32,How is uncertainty or confidence in model predictions captured?,"The uncertainty or confidence in model predictions is captured through the confidence score (probability) of the predictions, and the COCO method calculates average precision (with values from 0 to 100) for the entire predictions and each class of organs at different levels of Intersection over Union (IoU).",UncertaintyConfidence,https://w3id.org/dlprovenance#UncertaintyConfidence_4,confidence score (probability) of the predictions
8,32,How is uncertainty or confidence in model predictions captured?,"The uncertainty or confidence in model predictions is captured through the confidence score (probability) of the predictions, and the COCO method calculates average precision (with values from 0 to 100) for the entire predictions and each class of organs at different levels of Intersection over Union (IoU).",UncertaintyConfidence,https://w3id.org/dlprovenance#UncertaintyConfidence_5,confidence score (probability) of the predictions
8,32,How is uncertainty or confidence in model predictions captured?,"The uncertainty or confidence in model predictions is captured through the confidence score (probability) of the predictions, and the COCO method calculates average precision (with values from 0 to 100) for the entire predictions and each class of organs at different levels of Intersection over Union (IoU).",UncertaintyConfidence,https://w3id.org/dlprovenance#UncertaintyConfidence_6,confidence score (probability) of the predictions
8,32,How is uncertainty or confidence in model predictions captured?,"The uncertainty or confidence in model predictions is captured through the confidence score (probability) of the predictions, and the COCO method calculates average precision (with values from 0 to 100) for the entire predictions and each class of organs at different levels of Intersection over Union (IoU).",UncertaintyConfidence,https://w3id.org/dlprovenance#UncertaintyConfidence_7,confidence score (probability) of the predictions
8,32,How is uncertainty or confidence in model predictions captured?,"The uncertainty or confidence in model predictions is captured through the confidence score (probability) of the predictions, and the COCO method calculates average precision (with values from 0 to 100) for the entire predictions and each class of organs at different levels of Intersection over Union (IoU).",UncertaintyConfidence,https://w3id.org/dlprovenance#UncertaintyConfidence_8,confidence score (probability) of the predictions
8,32,How is uncertainty or confidence in model predictions captured?,"The uncertainty or confidence in model predictions is captured through the confidence score (probability) of the predictions, and the COCO method calculates average precision (with values from 0 to 100) for the entire predictions and each class of organs at different levels of Intersection over Union (IoU).",UncertaintyConfidence,https://w3id.org/dlprovenance#UncertaintyConfidence_9,confidence score (probability) of the predictions
8,32,How is uncertainty or confidence in model predictions captured?,"The uncertainty or confidence in model predictions is captured through the confidence score (probability) of the predictions, and the COCO method calculates average precision (with values from 0 to 100) for the entire predictions and each class of organs at different levels of Intersection over Union (IoU).",UncertaintyConfidence,https://w3id.org/dlprovenance#UncertaintyConfidence_10,confidence score (probability) of the predictions
8,32,How is uncertainty or confidence in model predictions captured?,"The uncertainty or confidence in model predictions is captured through the confidence score (probability) of the predictions, and the COCO method calculates average precision (with values from 0 to 100) for the entire predictions and each class of organs at different levels of Intersection over Union (IoU).",UncertaintyConfidence,https://w3id.org/dlprovenance#UncertaintyConfidence_11,confidence score (probability) of the predictions
8,32,How is uncertainty or confidence in model predictions captured?,"The uncertainty or confidence in model predictions is captured through the confidence score (probability) of the predictions, and the COCO method calculates average precision (with values from 0 to 100) for the entire predictions and each class of organs at different levels of Intersection over Union (IoU).",UncertaintyConfidence,https://w3id.org/dlprovenance#UncertaintyConfidence_12,confidence score (probability) of the predictions
8,32,How is uncertainty or confidence in model predictions captured?,"The uncertainty or confidence in model predictions is captured through the confidence score (probability) of the predictions, and the COCO method calculates average precision (with values from 0 to 100) for the entire predictions and each class of organs at different levels of Intersection over Union (IoU).",UncertaintyConfidence,https://w3id.org/dlprovenance#UncertaintyConfidence_13,confidence score (probability) of the predictions
8,32,How is uncertainty or confidence in model predictions captured?,"The uncertainty or confidence in model predictions is captured through the confidence score (probability) of the predictions, and the COCO method calculates average precision (with values from 0 to 100) for the entire predictions and each class of organs at different levels of Intersection over Union (IoU).",UncertaintyConfidence,https://w3id.org/dlprovenance#UncertaintyConfidence_14,confidence score (probability) of the predictions
8,32,How is uncertainty or confidence in model predictions captured?,"The uncertainty or confidence in model predictions is captured through the confidence score (probability) of the predictions, and the COCO method calculates average precision (with values from 0 to 100) for the entire predictions and each class of organs at different levels of Intersection over Union (IoU).",UncertaintyConfidence,https://w3id.org/dlprovenance#UncertaintyConfidence_15,confidence score (probability) of the predictions
8,32,How is uncertainty or confidence in model predictions captured?,"The uncertainty or confidence in model predictions is captured through the confidence score (probability) of the predictions, and the COCO method calculates average precision (with values from 0 to 100) for the entire predictions and each class of organs at different levels of Intersection over Union (IoU).",UncertaintyConfidence,https://w3id.org/dlprovenance#UncertaintyConfidence_16,confidence score (probability) of the predictions
8,32,How is uncertainty or confidence in model predictions captured?,"The uncertainty or confidence in model predictions is captured through the confidence score (probability) of the predictions, and the COCO method calculates average precision (with values from 0 to 100) for the entire predictions and each class of organs at different levels of Intersection over Union (IoU).",UncertaintyConfidence,https://w3id.org/dlprovenance#UncertaintyConfidence_17,confidence score (probability) of the predictions
8,32,How is uncertainty or confidence in model predictions captured?,"The uncertainty or confidence in model predictions is captured through the confidence score (probability) of the predictions, and the COCO method calculates average precision (with values from 0 to 100) for the entire predictions and each class of organs at different levels of Intersection over Union (IoU).",UncertaintyConfidence,https://w3id.org/dlprovenance#UncertaintyConfidence_18,confidence score (probability) of the predictions
8,32,How is uncertainty or confidence in model predictions captured?,"The uncertainty or confidence in model predictions is captured through the confidence score (probability) of the predictions, and the COCO method calculates average precision (with values from 0 to 100) for the entire predictions and each class of organs at different levels of Intersection over Union (IoU).",UncertaintyConfidence,https://w3id.org/dlprovenance#UncertaintyConfidence_19,confidence score (probability) of the predictions
8,32,How is uncertainty or confidence in model predictions captured?,"The uncertainty or confidence in model predictions is captured through the confidence score (probability) of the predictions, and the COCO method calculates average precision (with values from 0 to 100) for the entire predictions and each class of organs at different levels of Intersection over Union (IoU).",UncertaintyConfidence,https://w3id.org/dlprovenance#UncertaintyConfidence_20,confidence score (probability) of the predictions
8,32,How is uncertainty or confidence in model predictions captured?,"The uncertainty or confidence in model predictions is captured through the confidence score (probability) of the predictions, and the COCO method calculates average precision (with values from 0 to 100) for the entire predictions and each class of organs at different levels of Intersection over Union (IoU).",UncertaintyConfidence,https://w3id.org/dlprovenance#UncertaintyConfidence_21,confidence score (probability) of the predictions
8,32,How is uncertainty or confidence in model predictions captured?,"The uncertainty or confidence in model predictions is captured through the confidence score (probability) of the predictions, and the COCO method calculates average precision (with values from 0 to 100) for the entire predictions and each class of organs at different levels of Intersection over Union (IoU).",UncertaintyConfidence,https://w3id.org/dlprovenance#UncertaintyConfidence_22,confidence score (probability) of the predictions
8,32,How is uncertainty or confidence in model predictions captured?,"The uncertainty or confidence in model predictions is captured through the confidence score (probability) of the predictions, and the COCO method calculates average precision (with values from 0 to 100) for the entire predictions and each class of organs at different levels of Intersection over Union (IoU).",UncertaintyConfidence,https://w3id.org/dlprovenance#UncertaintyConfidence_23,confidence score (probability) of the predictions
8,32,How is uncertainty or confidence in model predictions captured?,"The uncertainty or confidence in model predictions is captured through the confidence score (probability) of the predictions, and the COCO method calculates average precision (with values from 0 to 100) for the entire predictions and each class of organs at different levels of Intersection over Union (IoU).",UncertaintyConfidence,https://w3id.org/dlprovenance#UncertaintyConfidence_24,confidence score (probability) of the predictions
8,32,How is uncertainty or confidence in model predictions captured?,"The uncertainty or confidence in model predictions is captured through the confidence score (probability) of the predictions, and the COCO method calculates average precision (with values from 0 to 100) for the entire predictions and each class of organs at different levels of Intersection over Union (IoU).",UncertaintyConfidence,https://w3id.org/dlprovenance#UncertaintyConfidence_25,confidence score (probability) of the predictions
8,33,Are there post-processing steps applied to the model's output?,"Yes, there are post-processing steps applied to the model's output, including manual verification and correction of a subset of the predictions, and annotation of an un-annotated dataset based on the model's predictions.",PostProcessing,https://w3id.org/dlprovenance#PostProcessing_1,"manual verification and correction of a subset of the predictions, and annotation of an un-annotated dataset based on the models predictions"
8,33,Are there post-processing steps applied to the model's output?,"Yes, there are post-processing steps applied to the model's output, including manual verification and correction of a subset of the predictions, and annotation of an un-annotated dataset based on the model's predictions.",PostProcessing,https://w3id.org/dlprovenance#PostProcessing_2,"manual verification and correction of a subset of the predictions, and annotation of an un-annotated dataset based on the models predictions"
8,33,Are there post-processing steps applied to the model's output?,"Yes, there are post-processing steps applied to the model's output, including manual verification and correction of a subset of the predictions, and annotation of an un-annotated dataset based on the model's predictions.",PostProcessing,https://w3id.org/dlprovenance#PostProcessing_3,"manual verification and correction of a subset of the predictions, and annotation of an un-annotated dataset based on the models predictions"
8,33,Are there post-processing steps applied to the model's output?,"Yes, there are post-processing steps applied to the model's output, including manual verification and correction of a subset of the predictions, and annotation of an un-annotated dataset based on the model's predictions.",PostProcessing,https://w3id.org/dlprovenance#PostProcessing_4,"manual verification and correction of a subset of the predictions, and annotation of an un-annotated dataset based on the models predictions"
8,33,Are there post-processing steps applied to the model's output?,"Yes, there are post-processing steps applied to the model's output, including manual verification and correction of a subset of the predictions, and annotation of an un-annotated dataset based on the model's predictions.",PostProcessing,https://w3id.org/dlprovenance#PostProcessing_5,"manual verification and correction of a subset of the predictions, and annotation of an un-annotated dataset based on the models predictions"
8,33,Are there post-processing steps applied to the model's output?,"Yes, there are post-processing steps applied to the model's output, including manual verification and correction of a subset of the predictions, and annotation of an un-annotated dataset based on the model's predictions.",PostProcessing,https://w3id.org/dlprovenance#PostProcessing_6,"manual verification and correction of a subset of the predictions, and annotation of an un-annotated dataset based on the models predictions"
8,33,Are there post-processing steps applied to the model's output?,"Yes, there are post-processing steps applied to the model's output, including manual verification and correction of a subset of the predictions, and annotation of an un-annotated dataset based on the model's predictions.",PostProcessing,https://w3id.org/dlprovenance#PostProcessing_7,"manual verification and correction of a subset of the predictions, and annotation of an un-annotated dataset based on the models predictions"
8,33,Are there post-processing steps applied to the model's output?,"Yes, there are post-processing steps applied to the model's output, including manual verification and correction of a subset of the predictions, and annotation of an un-annotated dataset based on the model's predictions.",PostProcessing,https://w3id.org/dlprovenance#PostProcessing_8,"manual verification and correction of a subset of the predictions, and annotation of an un-annotated dataset based on the models predictions"
8,33,Are there post-processing steps applied to the model's output?,"Yes, there are post-processing steps applied to the model's output, including manual verification and correction of a subset of the predictions, and annotation of an un-annotated dataset based on the model's predictions.",PostProcessing,https://w3id.org/dlprovenance#PostProcessing_9,"manual verification and correction of a subset of the predictions, and annotation of an un-annotated dataset based on the models predictions"
8,33,Are there post-processing steps applied to the model's output?,"Yes, there are post-processing steps applied to the model's output, including manual verification and correction of a subset of the predictions, and annotation of an un-annotated dataset based on the model's predictions.",PostProcessing,https://w3id.org/dlprovenance#PostProcessing_10,"manual verification and correction of a subset of the predictions, and annotation of an un-annotated dataset based on the models predictions"
8,33,Are there post-processing steps applied to the model's output?,"Yes, there are post-processing steps applied to the model's output, including manual verification and correction of a subset of the predictions, and annotation of an un-annotated dataset based on the model's predictions.",PostProcessing,https://w3id.org/dlprovenance#PostProcessing_11,"manual verification and correction of a subset of the predictions, and annotation of an un-annotated dataset based on the models predictions"
8,33,Are there post-processing steps applied to the model's output?,"Yes, there are post-processing steps applied to the model's output, including manual verification and correction of a subset of the predictions, and annotation of an un-annotated dataset based on the model's predictions.",PostProcessing,https://w3id.org/dlprovenance#PostProcessing_12,"manual verification and correction of a subset of the predictions, and annotation of an un-annotated dataset based on the models predictions"
8,33,Are there post-processing steps applied to the model's output?,"Yes, there are post-processing steps applied to the model's output, including manual verification and correction of a subset of the predictions, and annotation of an un-annotated dataset based on the model's predictions.",PostProcessing,https://w3id.org/dlprovenance#PostProcessing_13,"manual verification and correction of a subset of the predictions, and annotation of an un-annotated dataset based on the models predictions"
8,33,Are there post-processing steps applied to the model's output?,"Yes, there are post-processing steps applied to the model's output, including manual verification and correction of a subset of the predictions, and annotation of an un-annotated dataset based on the model's predictions.",PostProcessing,https://w3id.org/dlprovenance#PostProcessing_14,"manual verification and correction of a subset of the predictions, and annotation of an un-annotated dataset based on the models predictions"
8,33,Are there post-processing steps applied to the model's output?,"Yes, there are post-processing steps applied to the model's output, including manual verification and correction of a subset of the predictions, and annotation of an un-annotated dataset based on the model's predictions.",PostProcessing,https://w3id.org/dlprovenance#PostProcessing_15,"manual verification and correction of a subset of the predictions, and annotation of an un-annotated dataset based on the models predictions"
8,33,Are there post-processing steps applied to the model's output?,"Yes, there are post-processing steps applied to the model's output, including manual verification and correction of a subset of the predictions, and annotation of an un-annotated dataset based on the model's predictions.",PostProcessing,https://w3id.org/dlprovenance#PostProcessing_16,"manual verification and correction of a subset of the predictions, and annotation of an un-annotated dataset based on the models predictions"
8,33,Are there post-processing steps applied to the model's output?,"Yes, there are post-processing steps applied to the model's output, including manual verification and correction of a subset of the predictions, and annotation of an un-annotated dataset based on the model's predictions.",PostProcessing,https://w3id.org/dlprovenance#PostProcessing_17,"manual verification and correction of a subset of the predictions, and annotation of an un-annotated dataset based on the models predictions"
8,33,Are there post-processing steps applied to the model's output?,"Yes, there are post-processing steps applied to the model's output, including manual verification and correction of a subset of the predictions, and annotation of an un-annotated dataset based on the model's predictions.",PostProcessing,https://w3id.org/dlprovenance#PostProcessing_18,"manual verification and correction of a subset of the predictions, and annotation of an un-annotated dataset based on the models predictions"
8,33,Are there post-processing steps applied to the model's output?,"Yes, there are post-processing steps applied to the model's output, including manual verification and correction of a subset of the predictions, and annotation of an un-annotated dataset based on the model's predictions.",PostProcessing,https://w3id.org/dlprovenance#PostProcessing_19,"manual verification and correction of a subset of the predictions, and annotation of an un-annotated dataset based on the models predictions"
8,33,Are there post-processing steps applied to the model's output?,"Yes, there are post-processing steps applied to the model's output, including manual verification and correction of a subset of the predictions, and annotation of an un-annotated dataset based on the model's predictions.",PostProcessing,https://w3id.org/dlprovenance#PostProcessing_20,"manual verification and correction of a subset of the predictions, and annotation of an un-annotated dataset based on the models predictions"
8,33,Are there post-processing steps applied to the model's output?,"Yes, there are post-processing steps applied to the model's output, including manual verification and correction of a subset of the predictions, and annotation of an un-annotated dataset based on the model's predictions.",PostProcessing,https://w3id.org/dlprovenance#PostProcessing_21,"manual verification and correction of a subset of the predictions, and annotation of an un-annotated dataset based on the models predictions"
8,33,Are there post-processing steps applied to the model's output?,"Yes, there are post-processing steps applied to the model's output, including manual verification and correction of a subset of the predictions, and annotation of an un-annotated dataset based on the model's predictions.",PostProcessing,https://w3id.org/dlprovenance#PostProcessing_22,"manual verification and correction of a subset of the predictions, and annotation of an un-annotated dataset based on the models predictions"
8,33,Are there post-processing steps applied to the model's output?,"Yes, there are post-processing steps applied to the model's output, including manual verification and correction of a subset of the predictions, and annotation of an un-annotated dataset based on the model's predictions.",PostProcessing,https://w3id.org/dlprovenance#PostProcessing_23,"manual verification and correction of a subset of the predictions, and annotation of an un-annotated dataset based on the models predictions"
8,33,Are there post-processing steps applied to the model's output?,"Yes, there are post-processing steps applied to the model's output, including manual verification and correction of a subset of the predictions, and annotation of an un-annotated dataset based on the model's predictions.",PostProcessing,https://w3id.org/dlprovenance#PostProcessing_24,"manual verification and correction of a subset of the predictions, and annotation of an un-annotated dataset based on the models predictions"
8,34,"Is the trained model deployed, and if not, what is the reason?","is not deployed. The reason for this is not explicitly mentioned in the text, but it is possible that the authors decided to make the model available for others to use and deploy instead.",Deployment,https://w3id.org/dlprovenance#Deployment_1,not deployed
8,34,"Is the trained model deployed, and if not, what is the reason?","is not deployed. The reason for this is not explicitly mentioned in the text, but it is possible that the authors decided to make the model available for others to use and deploy instead.",Deployment,https://w3id.org/dlprovenance#Deployment_2,not deployed
8,34,"Is the trained model deployed, and if not, what is the reason?","is not deployed. The reason for this is not explicitly mentioned in the text, but it is possible that the authors decided to make the model available for others to use and deploy instead.",Deployment,https://w3id.org/dlprovenance#Deployment_3,not deployed
8,34,"Is the trained model deployed, and if not, what is the reason?","is not deployed. The reason for this is not explicitly mentioned in the text, but it is possible that the authors decided to make the model available for others to use and deploy instead.",Deployment,https://w3id.org/dlprovenance#Deployment_4,not deployed
8,34,"Is the trained model deployed, and if not, what is the reason?","is not deployed. The reason for this is not explicitly mentioned in the text, but it is possible that the authors decided to make the model available for others to use and deploy instead.",Deployment,https://w3id.org/dlprovenance#Deployment_5,not deployed
8,34,"Is the trained model deployed, and if not, what is the reason?","is not deployed. The reason for this is not explicitly mentioned in the text, but it is possible that the authors decided to make the model available for others to use and deploy instead.",Deployment,https://w3id.org/dlprovenance#Deployment_6,not deployed
8,34,"Is the trained model deployed, and if not, what is the reason?","is not deployed. The reason for this is not explicitly mentioned in the text, but it is possible that the authors decided to make the model available for others to use and deploy instead.",Deployment,https://w3id.org/dlprovenance#Deployment_7,not deployed
8,34,"Is the trained model deployed, and if not, what is the reason?","is not deployed. The reason for this is not explicitly mentioned in the text, but it is possible that the authors decided to make the model available for others to use and deploy instead.",Deployment,https://w3id.org/dlprovenance#Deployment_8,not deployed
8,34,"Is the trained model deployed, and if not, what is the reason?","is not deployed. The reason for this is not explicitly mentioned in the text, but it is possible that the authors decided to make the model available for others to use and deploy instead.",Deployment,https://w3id.org/dlprovenance#Deployment_9,not deployed
8,34,"Is the trained model deployed, and if not, what is the reason?","is not deployed. The reason for this is not explicitly mentioned in the text, but it is possible that the authors decided to make the model available for others to use and deploy instead.",Deployment,https://w3id.org/dlprovenance#Deployment_10,not deployed
8,34,"Is the trained model deployed, and if not, what is the reason?","is not deployed. The reason for this is not explicitly mentioned in the text, but it is possible that the authors decided to make the model available for others to use and deploy instead.",Deployment,https://w3id.org/dlprovenance#Deployment_11,not deployed
8,34,"Is the trained model deployed, and if not, what is the reason?","is not deployed. The reason for this is not explicitly mentioned in the text, but it is possible that the authors decided to make the model available for others to use and deploy instead.",Deployment,https://w3id.org/dlprovenance#Deployment_12,not deployed
8,34,"Is the trained model deployed, and if not, what is the reason?","is not deployed. The reason for this is not explicitly mentioned in the text, but it is possible that the authors decided to make the model available for others to use and deploy instead.",Deployment,https://w3id.org/dlprovenance#Deployment_13,not deployed
8,34,"Is the trained model deployed, and if not, what is the reason?","is not deployed. The reason for this is not explicitly mentioned in the text, but it is possible that the authors decided to make the model available for others to use and deploy instead.",Deployment,https://w3id.org/dlprovenance#Deployment_14,not deployed
8,34,"Is the trained model deployed, and if not, what is the reason?","is not deployed. The reason for this is not explicitly mentioned in the text, but it is possible that the authors decided to make the model available for others to use and deploy instead.",Deployment,https://w3id.org/dlprovenance#Deployment_15,not deployed
8,34,"Is the trained model deployed, and if not, what is the reason?","is not deployed. The reason for this is not explicitly mentioned in the text, but it is possible that the authors decided to make the model available for others to use and deploy instead.",Deployment,https://w3id.org/dlprovenance#Deployment_16,not deployed
8,34,"Is the trained model deployed, and if not, what is the reason?","is not deployed. The reason for this is not explicitly mentioned in the text, but it is possible that the authors decided to make the model available for others to use and deploy instead.",Deployment,https://w3id.org/dlprovenance#Deployment_17,not deployed
8,34,"Is the trained model deployed, and if not, what is the reason?","is not deployed. The reason for this is not explicitly mentioned in the text, but it is possible that the authors decided to make the model available for others to use and deploy instead.",Deployment,https://w3id.org/dlprovenance#Deployment_18,not deployed
8,34,"Is the trained model deployed, and if not, what is the reason?","is not deployed. The reason for this is not explicitly mentioned in the text, but it is possible that the authors decided to make the model available for others to use and deploy instead.",Deployment,https://w3id.org/dlprovenance#Deployment_19,not deployed
8,34,"Is the trained model deployed, and if not, what is the reason?","is not deployed. The reason for this is not explicitly mentioned in the text, but it is possible that the authors decided to make the model available for others to use and deploy instead.",Deployment,https://w3id.org/dlprovenance#Deployment_20,not deployed
8,34,"Is the trained model deployed, and if not, what is the reason?","is not deployed. The reason for this is not explicitly mentioned in the text, but it is possible that the authors decided to make the model available for others to use and deploy instead.",Deployment,https://w3id.org/dlprovenance#Deployment_21,not deployed
8,34,"Is the trained model deployed, and if not, what is the reason?","is not deployed. The reason for this is not explicitly mentioned in the text, but it is possible that the authors decided to make the model available for others to use and deploy instead.",Deployment,https://w3id.org/dlprovenance#Deployment_22,not deployed
8,34,"Is the trained model deployed, and if not, what is the reason?","is not deployed. The reason for this is not explicitly mentioned in the text, but it is possible that the authors decided to make the model available for others to use and deploy instead.",Deployment,https://w3id.org/dlprovenance#Deployment_23,not deployed
8,34,"Is the trained model deployed, and if not, what is the reason?","is not deployed. The reason for this is not explicitly mentioned in the text, but it is possible that the authors decided to make the model available for others to use and deploy instead.",Deployment,https://w3id.org/dlprovenance#Deployment_24,not deployed
8,35,What hardware and software are used for model deployment?,The model was implemented using the Detectron2 library in the PyTorch framework and trained using Stochastic Gradient Descent optimizer with a learning rate of 0.0025 and momentum of 0.9. The model was trained on a single TITAN Xp GPU and three GPUs for different iterations.,SoftwareFrameworkLibrary,https://w3id.org/dlprovenance#SoftwareFrameworkLibrary_1,TensorFlow and TensorFlow Object Detection API
8,35,What hardware and software are used for model deployment?,The model was implemented using the Detectron2 library in the PyTorch framework and trained using Stochastic Gradient Descent optimizer with a learning rate of 0.0025 and momentum of 0.9. The model was trained on a single TITAN Xp GPU and three GPUs for different iterations.,HardwareInfrastructure,https://w3id.org/dlprovenance#HardwareInfrastructure_1,single GPU (TITAN Xp) and three GPUs
8,37,What ethical considerations are taken into account during development and deployment?,The study does not provide information on ethical considerations taken into account during development and deployment.,EthicalImplication,https://w3id.org/dlprovenance#EthicalImplication_1,ethical implications
8,38,How is bias in the data addressed?,"ta is addressed by acknowledging the inherent biases in the study and the datasets used. The model was trained again on all the annotated scans and tested on a different un-annotated dataset, and the predicted bounding boxes were compared with the hand-annotated scans to evaluate the precision of the organ detection model on this dataset.",BiasAddressing,https://w3id.org/dlprovenance#BiasAddressing_1,acknowledging the inherent biases in the study and the datasets used
8,38,How is bias in the data addressed?,"ta is addressed by acknowledging the inherent biases in the study and the datasets used. The model was trained again on all the annotated scans and tested on a different un-annotated dataset, and the predicted bounding boxes were compared with the hand-annotated scans to evaluate the precision of the organ detection model on this dataset.",BiasAddressing,https://w3id.org/dlprovenance#BiasAddressing_2,acknowledging the inherent biases in the study and the datasets used
8,38,How is bias in the data addressed?,"ta is addressed by acknowledging the inherent biases in the study and the datasets used. The model was trained again on all the annotated scans and tested on a different un-annotated dataset, and the predicted bounding boxes were compared with the hand-annotated scans to evaluate the precision of the organ detection model on this dataset.",BiasAddressing,https://w3id.org/dlprovenance#BiasAddressing_3,acknowledging the inherent biases in the study and the datasets used
8,38,How is bias in the data addressed?,"ta is addressed by acknowledging the inherent biases in the study and the datasets used. The model was trained again on all the annotated scans and tested on a different un-annotated dataset, and the predicted bounding boxes were compared with the hand-annotated scans to evaluate the precision of the organ detection model on this dataset.",BiasAddressing,https://w3id.org/dlprovenance#BiasAddressing_4,acknowledging the inherent biases in the study and the datasets used
8,38,How is bias in the data addressed?,"ta is addressed by acknowledging the inherent biases in the study and the datasets used. The model was trained again on all the annotated scans and tested on a different un-annotated dataset, and the predicted bounding boxes were compared with the hand-annotated scans to evaluate the precision of the organ detection model on this dataset.",BiasAddressing,https://w3id.org/dlprovenance#BiasAddressing_5,acknowledging the inherent biases in the study and the datasets used
8,38,How is bias in the data addressed?,"ta is addressed by acknowledging the inherent biases in the study and the datasets used. The model was trained again on all the annotated scans and tested on a different un-annotated dataset, and the predicted bounding boxes were compared with the hand-annotated scans to evaluate the precision of the organ detection model on this dataset.",BiasAddressing,https://w3id.org/dlprovenance#BiasAddressing_6,acknowledging the inherent biases in the study and the datasets used
8,38,How is bias in the data addressed?,"ta is addressed by acknowledging the inherent biases in the study and the datasets used. The model was trained again on all the annotated scans and tested on a different un-annotated dataset, and the predicted bounding boxes were compared with the hand-annotated scans to evaluate the precision of the organ detection model on this dataset.",BiasAddressing,https://w3id.org/dlprovenance#BiasAddressing_7,acknowledging the inherent biases in the study and the datasets used
8,38,How is bias in the data addressed?,"ta is addressed by acknowledging the inherent biases in the study and the datasets used. The model was trained again on all the annotated scans and tested on a different un-annotated dataset, and the predicted bounding boxes were compared with the hand-annotated scans to evaluate the precision of the organ detection model on this dataset.",BiasAddressing,https://w3id.org/dlprovenance#BiasAddressing_8,acknowledging the inherent biases in the study and the datasets used
8,38,How is bias in the data addressed?,"ta is addressed by acknowledging the inherent biases in the study and the datasets used. The model was trained again on all the annotated scans and tested on a different un-annotated dataset, and the predicted bounding boxes were compared with the hand-annotated scans to evaluate the precision of the organ detection model on this dataset.",BiasAddressing,https://w3id.org/dlprovenance#BiasAddressing_9,acknowledging the inherent biases in the study and the datasets used
8,38,How is bias in the data addressed?,"ta is addressed by acknowledging the inherent biases in the study and the datasets used. The model was trained again on all the annotated scans and tested on a different un-annotated dataset, and the predicted bounding boxes were compared with the hand-annotated scans to evaluate the precision of the organ detection model on this dataset.",BiasAddressing,https://w3id.org/dlprovenance#BiasAddressing_10,acknowledging the inherent biases in the study and the datasets used
8,38,How is bias in the data addressed?,"ta is addressed by acknowledging the inherent biases in the study and the datasets used. The model was trained again on all the annotated scans and tested on a different un-annotated dataset, and the predicted bounding boxes were compared with the hand-annotated scans to evaluate the precision of the organ detection model on this dataset.",BiasAddressing,https://w3id.org/dlprovenance#BiasAddressing_11,acknowledging the inherent biases in the study and the datasets used
8,38,How is bias in the data addressed?,"ta is addressed by acknowledging the inherent biases in the study and the datasets used. The model was trained again on all the annotated scans and tested on a different un-annotated dataset, and the predicted bounding boxes were compared with the hand-annotated scans to evaluate the precision of the organ detection model on this dataset.",BiasAddressing,https://w3id.org/dlprovenance#BiasAddressing_12,acknowledging the inherent biases in the study and the datasets used
8,38,How is bias in the data addressed?,"ta is addressed by acknowledging the inherent biases in the study and the datasets used. The model was trained again on all the annotated scans and tested on a different un-annotated dataset, and the predicted bounding boxes were compared with the hand-annotated scans to evaluate the precision of the organ detection model on this dataset.",BiasAddressing,https://w3id.org/dlprovenance#BiasAddressing_13,acknowledging the inherent biases in the study and the datasets used
8,38,How is bias in the data addressed?,"ta is addressed by acknowledging the inherent biases in the study and the datasets used. The model was trained again on all the annotated scans and tested on a different un-annotated dataset, and the predicted bounding boxes were compared with the hand-annotated scans to evaluate the precision of the organ detection model on this dataset.",BiasAddressing,https://w3id.org/dlprovenance#BiasAddressing_14,acknowledging the inherent biases in the study and the datasets used
8,38,How is bias in the data addressed?,"ta is addressed by acknowledging the inherent biases in the study and the datasets used. The model was trained again on all the annotated scans and tested on a different un-annotated dataset, and the predicted bounding boxes were compared with the hand-annotated scans to evaluate the precision of the organ detection model on this dataset.",BiasAddressing,https://w3id.org/dlprovenance#BiasAddressing_15,acknowledging the inherent biases in the study and the datasets used
8,38,How is bias in the data addressed?,"ta is addressed by acknowledging the inherent biases in the study and the datasets used. The model was trained again on all the annotated scans and tested on a different un-annotated dataset, and the predicted bounding boxes were compared with the hand-annotated scans to evaluate the precision of the organ detection model on this dataset.",BiasAddressing,https://w3id.org/dlprovenance#BiasAddressing_16,acknowledging the inherent biases in the study and the datasets used
8,38,How is bias in the data addressed?,"ta is addressed by acknowledging the inherent biases in the study and the datasets used. The model was trained again on all the annotated scans and tested on a different un-annotated dataset, and the predicted bounding boxes were compared with the hand-annotated scans to evaluate the precision of the organ detection model on this dataset.",BiasAddressing,https://w3id.org/dlprovenance#BiasAddressing_17,acknowledging the inherent biases in the study and the datasets used
8,38,How is bias in the data addressed?,"ta is addressed by acknowledging the inherent biases in the study and the datasets used. The model was trained again on all the annotated scans and tested on a different un-annotated dataset, and the predicted bounding boxes were compared with the hand-annotated scans to evaluate the precision of the organ detection model on this dataset.",BiasAddressing,https://w3id.org/dlprovenance#BiasAddressing_18,acknowledging the inherent biases in the study and the datasets used
8,38,How is bias in the data addressed?,"ta is addressed by acknowledging the inherent biases in the study and the datasets used. The model was trained again on all the annotated scans and tested on a different un-annotated dataset, and the predicted bounding boxes were compared with the hand-annotated scans to evaluate the precision of the organ detection model on this dataset.",BiasAddressing,https://w3id.org/dlprovenance#BiasAddressing_19,acknowledging the inherent biases in the study and the datasets used
8,38,How is bias in the data addressed?,"ta is addressed by acknowledging the inherent biases in the study and the datasets used. The model was trained again on all the annotated scans and tested on a different un-annotated dataset, and the predicted bounding boxes were compared with the hand-annotated scans to evaluate the precision of the organ detection model on this dataset.",BiasAddressing,https://w3id.org/dlprovenance#BiasAddressing_20,acknowledging the inherent biases in the study and the datasets used
8,38,How is bias in the data addressed?,"ta is addressed by acknowledging the inherent biases in the study and the datasets used. The model was trained again on all the annotated scans and tested on a different un-annotated dataset, and the predicted bounding boxes were compared with the hand-annotated scans to evaluate the precision of the organ detection model on this dataset.",BiasAddressing,https://w3id.org/dlprovenance#BiasAddressing_21,acknowledging the inherent biases in the study and the datasets used
8,38,How is bias in the data addressed?,"ta is addressed by acknowledging the inherent biases in the study and the datasets used. The model was trained again on all the annotated scans and tested on a different un-annotated dataset, and the predicted bounding boxes were compared with the hand-annotated scans to evaluate the precision of the organ detection model on this dataset.",BiasAddressing,https://w3id.org/dlprovenance#BiasAddressing_22,acknowledging the inherent biases in the study and the datasets used
8,38,How is bias in the data addressed?,"ta is addressed by acknowledging the inherent biases in the study and the datasets used. The model was trained again on all the annotated scans and tested on a different un-annotated dataset, and the predicted bounding boxes were compared with the hand-annotated scans to evaluate the precision of the organ detection model on this dataset.",BiasAddressing,https://w3id.org/dlprovenance#BiasAddressing_23,acknowledging the inherent biases in the study and the datasets used
8,38,How is bias in the data addressed?,"ta is addressed by acknowledging the inherent biases in the study and the datasets used. The model was trained again on all the annotated scans and tested on a different un-annotated dataset, and the predicted bounding boxes were compared with the hand-annotated scans to evaluate the precision of the organ detection model on this dataset.",BiasAddressing,https://w3id.org/dlprovenance#BiasAddressing_24,acknowledging the inherent biases in the study and the datasets used
8,39,Is there transparency in the decision-making process regarding bias?,"The study acknowledges the inherent biases in the dataset and the decision-making process, but it does not provide specific details about the transparency of the decision-making process regarding bias.",Transparency,https://w3id.org/dlprovenance#Transparency_1,not specified
8,39,Is there transparency in the decision-making process regarding bias?,"The study acknowledges the inherent biases in the dataset and the decision-making process, but it does not provide specific details about the transparency of the decision-making process regarding bias.",Transparency,https://w3id.org/dlprovenance#Transparency_2,not specified
8,39,Is there transparency in the decision-making process regarding bias?,"The study acknowledges the inherent biases in the dataset and the decision-making process, but it does not provide specific details about the transparency of the decision-making process regarding bias.",Transparency,https://w3id.org/dlprovenance#Transparency_3,not specified
8,39,Is there transparency in the decision-making process regarding bias?,"The study acknowledges the inherent biases in the dataset and the decision-making process, but it does not provide specific details about the transparency of the decision-making process regarding bias.",Transparency,https://w3id.org/dlprovenance#Transparency_4,not specified
8,39,Is there transparency in the decision-making process regarding bias?,"The study acknowledges the inherent biases in the dataset and the decision-making process, but it does not provide specific details about the transparency of the decision-making process regarding bias.",Transparency,https://w3id.org/dlprovenance#Transparency_5,not specified
8,39,Is there transparency in the decision-making process regarding bias?,"The study acknowledges the inherent biases in the dataset and the decision-making process, but it does not provide specific details about the transparency of the decision-making process regarding bias.",Transparency,https://w3id.org/dlprovenance#Transparency_6,not specified
8,39,Is there transparency in the decision-making process regarding bias?,"The study acknowledges the inherent biases in the dataset and the decision-making process, but it does not provide specific details about the transparency of the decision-making process regarding bias.",Transparency,https://w3id.org/dlprovenance#Transparency_7,not specified
8,39,Is there transparency in the decision-making process regarding bias?,"The study acknowledges the inherent biases in the dataset and the decision-making process, but it does not provide specific details about the transparency of the decision-making process regarding bias.",Transparency,https://w3id.org/dlprovenance#Transparency_8,not specified
8,39,Is there transparency in the decision-making process regarding bias?,"The study acknowledges the inherent biases in the dataset and the decision-making process, but it does not provide specific details about the transparency of the decision-making process regarding bias.",Transparency,https://w3id.org/dlprovenance#Transparency_9,not specified
8,39,Is there transparency in the decision-making process regarding bias?,"The study acknowledges the inherent biases in the dataset and the decision-making process, but it does not provide specific details about the transparency of the decision-making process regarding bias.",Transparency,https://w3id.org/dlprovenance#Transparency_10,not specified
8,39,Is there transparency in the decision-making process regarding bias?,"The study acknowledges the inherent biases in the dataset and the decision-making process, but it does not provide specific details about the transparency of the decision-making process regarding bias.",Transparency,https://w3id.org/dlprovenance#Transparency_11,not specified
8,39,Is there transparency in the decision-making process regarding bias?,"The study acknowledges the inherent biases in the dataset and the decision-making process, but it does not provide specific details about the transparency of the decision-making process regarding bias.",Transparency,https://w3id.org/dlprovenance#Transparency_12,not specified
8,39,Is there transparency in the decision-making process regarding bias?,"The study acknowledges the inherent biases in the dataset and the decision-making process, but it does not provide specific details about the transparency of the decision-making process regarding bias.",Transparency,https://w3id.org/dlprovenance#Transparency_13,not specified
8,39,Is there transparency in the decision-making process regarding bias?,"The study acknowledges the inherent biases in the dataset and the decision-making process, but it does not provide specific details about the transparency of the decision-making process regarding bias.",Transparency,https://w3id.org/dlprovenance#Transparency_14,not specified
8,39,Is there transparency in the decision-making process regarding bias?,"The study acknowledges the inherent biases in the dataset and the decision-making process, but it does not provide specific details about the transparency of the decision-making process regarding bias.",Transparency,https://w3id.org/dlprovenance#Transparency_15,not specified
8,39,Is there transparency in the decision-making process regarding bias?,"The study acknowledges the inherent biases in the dataset and the decision-making process, but it does not provide specific details about the transparency of the decision-making process regarding bias.",Transparency,https://w3id.org/dlprovenance#Transparency_16,not specified
8,39,Is there transparency in the decision-making process regarding bias?,"The study acknowledges the inherent biases in the dataset and the decision-making process, but it does not provide specific details about the transparency of the decision-making process regarding bias.",Transparency,https://w3id.org/dlprovenance#Transparency_17,not specified
8,39,Is there transparency in the decision-making process regarding bias?,"The study acknowledges the inherent biases in the dataset and the decision-making process, but it does not provide specific details about the transparency of the decision-making process regarding bias.",Transparency,https://w3id.org/dlprovenance#Transparency_18,not specified
8,39,Is there transparency in the decision-making process regarding bias?,"The study acknowledges the inherent biases in the dataset and the decision-making process, but it does not provide specific details about the transparency of the decision-making process regarding bias.",Transparency,https://w3id.org/dlprovenance#Transparency_19,not specified
8,39,Is there transparency in the decision-making process regarding bias?,"The study acknowledges the inherent biases in the dataset and the decision-making process, but it does not provide specific details about the transparency of the decision-making process regarding bias.",Transparency,https://w3id.org/dlprovenance#Transparency_20,not specified
8,39,Is there transparency in the decision-making process regarding bias?,"The study acknowledges the inherent biases in the dataset and the decision-making process, but it does not provide specific details about the transparency of the decision-making process regarding bias.",Transparency,https://w3id.org/dlprovenance#Transparency_21,not specified
8,39,Is there transparency in the decision-making process regarding bias?,"The study acknowledges the inherent biases in the dataset and the decision-making process, but it does not provide specific details about the transparency of the decision-making process regarding bias.",Transparency,https://w3id.org/dlprovenance#Transparency_22,not specified
8,39,Is there transparency in the decision-making process regarding bias?,"The study acknowledges the inherent biases in the dataset and the decision-making process, but it does not provide specific details about the transparency of the decision-making process regarding bias.",Transparency,https://w3id.org/dlprovenance#Transparency_23,not specified
8,39,Is there transparency in the decision-making process regarding bias?,"The study acknowledges the inherent biases in the dataset and the decision-making process, but it does not provide specific details about the transparency of the decision-making process regarding bias.",Transparency,https://w3id.org/dlprovenance#Transparency_24,not specified
8,40,Are privacy and security measures implemented in handling sensitive data?,The text does not provide information about privacy and security measures implemented in handling sensitive data.,PrivacySecurityMeasure,https://w3id.org/dlprovenance#PrivacySecurityMeasure_1,not specified
8,40,Are privacy and security measures implemented in handling sensitive data?,The text does not provide information about privacy and security measures implemented in handling sensitive data.,PrivacySecurityMeasure,https://w3id.org/dlprovenance#PrivacySecurityMeasure_2,not specified
8,40,Are privacy and security measures implemented in handling sensitive data?,The text does not provide information about privacy and security measures implemented in handling sensitive data.,PrivacySecurityMeasure,https://w3id.org/dlprovenance#PrivacySecurityMeasure_3,not specified
8,40,Are privacy and security measures implemented in handling sensitive data?,The text does not provide information about privacy and security measures implemented in handling sensitive data.,PrivacySecurityMeasure,https://w3id.org/dlprovenance#PrivacySecurityMeasure_4,not specified
8,40,Are privacy and security measures implemented in handling sensitive data?,The text does not provide information about privacy and security measures implemented in handling sensitive data.,PrivacySecurityMeasure,https://w3id.org/dlprovenance#PrivacySecurityMeasure_5,not specified
8,40,Are privacy and security measures implemented in handling sensitive data?,The text does not provide information about privacy and security measures implemented in handling sensitive data.,PrivacySecurityMeasure,https://w3id.org/dlprovenance#PrivacySecurityMeasure_6,not specified
8,40,Are privacy and security measures implemented in handling sensitive data?,The text does not provide information about privacy and security measures implemented in handling sensitive data.,PrivacySecurityMeasure,https://w3id.org/dlprovenance#PrivacySecurityMeasure_7,not specified
8,40,Are privacy and security measures implemented in handling sensitive data?,The text does not provide information about privacy and security measures implemented in handling sensitive data.,PrivacySecurityMeasure,https://w3id.org/dlprovenance#PrivacySecurityMeasure_8,not specified
8,40,Are privacy and security measures implemented in handling sensitive data?,The text does not provide information about privacy and security measures implemented in handling sensitive data.,PrivacySecurityMeasure,https://w3id.org/dlprovenance#PrivacySecurityMeasure_9,not specified
8,40,Are privacy and security measures implemented in handling sensitive data?,The text does not provide information about privacy and security measures implemented in handling sensitive data.,PrivacySecurityMeasure,https://w3id.org/dlprovenance#PrivacySecurityMeasure_10,not specified
8,40,Are privacy and security measures implemented in handling sensitive data?,The text does not provide information about privacy and security measures implemented in handling sensitive data.,PrivacySecurityMeasure,https://w3id.org/dlprovenance#PrivacySecurityMeasure_11,not specified
8,40,Are privacy and security measures implemented in handling sensitive data?,The text does not provide information about privacy and security measures implemented in handling sensitive data.,PrivacySecurityMeasure,https://w3id.org/dlprovenance#PrivacySecurityMeasure_12,not specified
8,40,Are privacy and security measures implemented in handling sensitive data?,The text does not provide information about privacy and security measures implemented in handling sensitive data.,PrivacySecurityMeasure,https://w3id.org/dlprovenance#PrivacySecurityMeasure_13,not specified
8,40,Are privacy and security measures implemented in handling sensitive data?,The text does not provide information about privacy and security measures implemented in handling sensitive data.,PrivacySecurityMeasure,https://w3id.org/dlprovenance#PrivacySecurityMeasure_14,not specified
8,40,Are privacy and security measures implemented in handling sensitive data?,The text does not provide information about privacy and security measures implemented in handling sensitive data.,PrivacySecurityMeasure,https://w3id.org/dlprovenance#PrivacySecurityMeasure_15,not specified
8,40,Are privacy and security measures implemented in handling sensitive data?,The text does not provide information about privacy and security measures implemented in handling sensitive data.,PrivacySecurityMeasure,https://w3id.org/dlprovenance#PrivacySecurityMeasure_16,not specified
8,40,Are privacy and security measures implemented in handling sensitive data?,The text does not provide information about privacy and security measures implemented in handling sensitive data.,PrivacySecurityMeasure,https://w3id.org/dlprovenance#PrivacySecurityMeasure_17,not specified
8,40,Are privacy and security measures implemented in handling sensitive data?,The text does not provide information about privacy and security measures implemented in handling sensitive data.,PrivacySecurityMeasure,https://w3id.org/dlprovenance#PrivacySecurityMeasure_18,not specified
8,40,Are privacy and security measures implemented in handling sensitive data?,The text does not provide information about privacy and security measures implemented in handling sensitive data.,PrivacySecurityMeasure,https://w3id.org/dlprovenance#PrivacySecurityMeasure_19,not specified
8,40,Are privacy and security measures implemented in handling sensitive data?,The text does not provide information about privacy and security measures implemented in handling sensitive data.,PrivacySecurityMeasure,https://w3id.org/dlprovenance#PrivacySecurityMeasure_20,not specified
8,40,Are privacy and security measures implemented in handling sensitive data?,The text does not provide information about privacy and security measures implemented in handling sensitive data.,PrivacySecurityMeasure,https://w3id.org/dlprovenance#PrivacySecurityMeasure_21,not specified
8,40,Are privacy and security measures implemented in handling sensitive data?,The text does not provide information about privacy and security measures implemented in handling sensitive data.,PrivacySecurityMeasure,https://w3id.org/dlprovenance#PrivacySecurityMeasure_22,not specified
8,40,Are privacy and security measures implemented in handling sensitive data?,The text does not provide information about privacy and security measures implemented in handling sensitive data.,PrivacySecurityMeasure,https://w3id.org/dlprovenance#PrivacySecurityMeasure_23,not specified
8,40,Are privacy and security measures implemented in handling sensitive data?,The text does not provide information about privacy and security measures implemented in handling sensitive data.,SensitiveData,https://w3id.org/dlprovenance#SensitiveData_1,herbarium scans
8,40,Are privacy and security measures implemented in handling sensitive data?,The text does not provide information about privacy and security measures implemented in handling sensitive data.,SensitiveData,https://w3id.org/dlprovenance#SensitiveData_2,herbarium scans
8,40,Are privacy and security measures implemented in handling sensitive data?,The text does not provide information about privacy and security measures implemented in handling sensitive data.,SensitiveData,https://w3id.org/dlprovenance#SensitiveData_3,herbarium scans
8,40,Are privacy and security measures implemented in handling sensitive data?,The text does not provide information about privacy and security measures implemented in handling sensitive data.,SensitiveData,https://w3id.org/dlprovenance#SensitiveData_4,herbarium scans
8,40,Are privacy and security measures implemented in handling sensitive data?,The text does not provide information about privacy and security measures implemented in handling sensitive data.,SensitiveData,https://w3id.org/dlprovenance#SensitiveData_5,herbarium scans
8,40,Are privacy and security measures implemented in handling sensitive data?,The text does not provide information about privacy and security measures implemented in handling sensitive data.,SensitiveData,https://w3id.org/dlprovenance#SensitiveData_6,herbarium scans
8,40,Are privacy and security measures implemented in handling sensitive data?,The text does not provide information about privacy and security measures implemented in handling sensitive data.,SensitiveData,https://w3id.org/dlprovenance#SensitiveData_7,herbarium scans
8,40,Are privacy and security measures implemented in handling sensitive data?,The text does not provide information about privacy and security measures implemented in handling sensitive data.,SensitiveData,https://w3id.org/dlprovenance#SensitiveData_8,herbarium scans
8,40,Are privacy and security measures implemented in handling sensitive data?,The text does not provide information about privacy and security measures implemented in handling sensitive data.,SensitiveData,https://w3id.org/dlprovenance#SensitiveData_9,herbarium scans
8,40,Are privacy and security measures implemented in handling sensitive data?,The text does not provide information about privacy and security measures implemented in handling sensitive data.,SensitiveData,https://w3id.org/dlprovenance#SensitiveData_10,herbarium scans
8,40,Are privacy and security measures implemented in handling sensitive data?,The text does not provide information about privacy and security measures implemented in handling sensitive data.,SensitiveData,https://w3id.org/dlprovenance#SensitiveData_11,herbarium scans
8,40,Are privacy and security measures implemented in handling sensitive data?,The text does not provide information about privacy and security measures implemented in handling sensitive data.,SensitiveData,https://w3id.org/dlprovenance#SensitiveData_12,herbarium scans
8,40,Are privacy and security measures implemented in handling sensitive data?,The text does not provide information about privacy and security measures implemented in handling sensitive data.,SensitiveData,https://w3id.org/dlprovenance#SensitiveData_13,herbarium scans
8,40,Are privacy and security measures implemented in handling sensitive data?,The text does not provide information about privacy and security measures implemented in handling sensitive data.,SensitiveData,https://w3id.org/dlprovenance#SensitiveData_14,herbarium scans
8,40,Are privacy and security measures implemented in handling sensitive data?,The text does not provide information about privacy and security measures implemented in handling sensitive data.,SensitiveData,https://w3id.org/dlprovenance#SensitiveData_15,herbarium scans
8,40,Are privacy and security measures implemented in handling sensitive data?,The text does not provide information about privacy and security measures implemented in handling sensitive data.,SensitiveData,https://w3id.org/dlprovenance#SensitiveData_16,herbarium scans
8,40,Are privacy and security measures implemented in handling sensitive data?,The text does not provide information about privacy and security measures implemented in handling sensitive data.,SensitiveData,https://w3id.org/dlprovenance#SensitiveData_17,herbarium scans
8,40,Are privacy and security measures implemented in handling sensitive data?,The text does not provide information about privacy and security measures implemented in handling sensitive data.,SensitiveData,https://w3id.org/dlprovenance#SensitiveData_18,herbarium scans
8,40,Are privacy and security measures implemented in handling sensitive data?,The text does not provide information about privacy and security measures implemented in handling sensitive data.,SensitiveData,https://w3id.org/dlprovenance#SensitiveData_19,herbarium scans
8,40,Are privacy and security measures implemented in handling sensitive data?,The text does not provide information about privacy and security measures implemented in handling sensitive data.,SensitiveData,https://w3id.org/dlprovenance#SensitiveData_20,herbarium scans
8,40,Are privacy and security measures implemented in handling sensitive data?,The text does not provide information about privacy and security measures implemented in handling sensitive data.,SensitiveData,https://w3id.org/dlprovenance#SensitiveData_21,herbarium scans
8,40,Are privacy and security measures implemented in handling sensitive data?,The text does not provide information about privacy and security measures implemented in handling sensitive data.,SensitiveData,https://w3id.org/dlprovenance#SensitiveData_22,herbarium scans
8,40,Are privacy and security measures implemented in handling sensitive data?,The text does not provide information about privacy and security measures implemented in handling sensitive data.,SensitiveData,https://w3id.org/dlprovenance#SensitiveData_23,herbarium scans
8,40,Are privacy and security measures implemented in handling sensitive data?,The text does not provide information about privacy and security measures implemented in handling sensitive data.,SensitiveData,https://w3id.org/dlprovenance#SensitiveData_24,herbarium scans
